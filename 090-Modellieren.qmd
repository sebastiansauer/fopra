# Auswerten: Modellieren


```{r}
#| include: false
library(tidyverse)
library(dagitty)
```


```{r}
#| echo: false
library(ggplot2)
theme_set(theme_minimal())
```

## Lernsteuerung


### Lernziele


- Sie k√∂nnen die Modellformel Ihrer Forschungsfrage nennen.
- Sie k√∂nnen Ihre Modellformel (korrekt) in R spezifizieren.
- Sie k√∂nnen Ihr Modell in R berechnen und die Ausgabe interpretieren.
- Sie k√∂nnen die G√ºltigkeit bzw. die Grenzen der Aussagen Ihres Modells einsch√§tzen.


### Ben√∂tigte R-Pakete


```{r}
#| message: false
library(tidyverse)
library(easystats)
library(ggstatsplot)
library(rstanarm)
```



### Position im Lernpfad

Sie befinden sich im Abschnitt "Auswerten" in @fig-ueberblick.








## 1 between-Variable

### Design

@sauer_effect_2023 untersuchten in einer Querschnittsstudie den Effekt des Wirkstoff *Bringnixtin* auf die fluide Intelligenz. Die Autoren nahmen an, dass der Wirkstoff den individuellen Wert der abh√§ngigen Variable erh√∂hen w√ºrde.


Der Ablauf (aus Sicht der Probandis) ist in @fig-bringtnixtin-flow dargestellt.
`Intro` fasst die Begr√º√üung der Probandis inkl. Informed Consent sowie Erfassung von soziodemografischen Variablen zusammen.
`g.0` und `g.1` sind die zwei Stufen der UV (*g* wie Gruppe), wobei `g.0` die Kontrollgruppe kodiert (Placebo, also Zuckerpille, kein Wirkstoff,) und `g.1` die *zweite* Stufe, d.h. die Experimentalgruppe (hohe Dosis Bringtnixtin).
`y2` ist die Messung der AV (d.h. nach Gabe von Bringtnixtin), d.h. ein Ma√ü der fluiden Intelligenz.
`outro` meint die Verabschiedung der Probanden sowie einige Fragen zu Compliance.


Die Hypothese lautet: $\mu_{g.2} > \mu_{g.1}$. 

In Worten:

>  Wir erwarten, dass der Mittelwert der Experimentalgruppe h√∂her ist als der Mittelwert der Kontrollgruppe.



```{mermaid}
%%| label: fig-bringtnixtin-flow
%%| fig-cap: Ablaufdiagramm der Bringtnixtin-Studie

flowchart LR
  Intro --> g.0
  Intro --> g.1
  g.0 --> y2
  g.1 --> y2
  y2 --> outro
```

Der DAG des Experiments ist in @fig-bringtnixtin-dag dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-bringtnixtin-dag
#| fig-cap: "DAG f√ºr der Bringtnixtin-Studie"
#| echo: false

mein_modell <- "dag{
g -> y2
u -> y2
}"

plot(graphLayout(mein_modell))
```



```{r d_bringtnixtin}
#| echo: false
#| eval: true
n_bringtnixtin <- 40

set.seed(42)
d_bringtnixtin <-
  tibble(id = 1:n_bringtnixtin,
         g = c(rep(0, n_bringtnixtin/2), rep(1, n_bringtnixtin/2)),
         y1 = rnorm(n_bringtnixtin),
         y2 = y1 + rnorm(n_bringtnixtin, mean = 0, sd = .2) - g/3,
         d = y2 - y1
  )

#write_csv(d_bringtnixtin, "data/d_bringtnixtin.csv")
```


Die Daten dieses Experiments sind hier zu beziehen:

```{r}
#| message: false
#| eval: false
d_bringtnixtin_path <- "https://raw.githubusercontent.com/sebastiansauer/fopra/main/data/d_bringtnixtin.csv"
d_bringtnixtin <- read_csv(d_bringtnixtin_path)
```


{{< downloadthis data/d_bringtnixtin.csv >}}

Die Autoren der Studie geben an, dass die Daten in z-Einheiten skaliert sind.


### Deskriptive Analyse


```{r}
#| eval: false
d_bringtnixtin %>% 
  group_by(g) %>% 
  summarise(iq_mw = mean(y2),
            iq_sd = sd(y2)) 
```


```{r}
#| echo: false
#| label: tbl-bringtnixtin-desk
#| tbl-cap: "Mittlere fluide Intelligenz nach der Bringtnixtin-Intervention in Abh√§ngigkeit der Gruppe"
d_bringtnixtin %>% 
  group_by(g) %>% 
  summarise(iq_mw = mean(y2),
            iq_sd = sd(y2)) 
```

Die deskriptiven Kennwerte sind in @fig-bringtnixtin-desk dargestellt.
Das sieht nicht gerade nach einem gro√üen Effekt aus ...^[Die Mittelwerte der beiden Gruppen sind praktisch identisch.]


```{r}
#| label: fig-bringtnixtin-desk
#| fig-cap: "Fluide Intelligenz (y2) nach der Bringtnixtin-Intervention. g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)"
ggbetweenstats(
  data = d_bringtnixtin,
  x = g,
  y = y2,
  results.subtitle = FALSE  # keine Statistiken zeigen
)
```



### Modellierung


Wir berechnen ein lineares Modell mit der Modellformel `y2 ~ g`. 
Die Ergebnisse sind in @tbl-m1-params zu sehen.

```{r}
#| label: tbl-m1-params
#| tbl-cap: Parameter des Modells m_bringtnixtin
m_bringtnixtin <- stan_glm(y2 ~ g, data = d_bringtnixtin, refresh = 0)
parameters(m_bringtnixtin)
```

Die Punkt- und Intervallsch√§tzer (95%-ETI) sind in @fig-m1-params dargestellt.

```{r}
#| label: fig-m1-params
#| fig-cap: "Parameter des Modells `m_bringtnixtin (95%-ETI)`"
parameters(m_bringtnixtin) %>% plot(show_intercept = TRUE)
```


```{r}
#| echo: false
m_bringtnixtin_hdi <- hdi(m_bringtnixtin)

m1_lo_ci <- m_bringtnixtin_hdi %>% filter(Parameter == "g") %>% pull(CI_low) %>% round(2)
m1_high_ci <- m_bringtnixtin_hdi %>% filter(Parameter == "g") %>% pull(CI_high) %>% round(2)
```



Der Gruppenunterschied wird auf `r round(coef(m_bringtnixtin), 2)` gesch√§tzt;
das ist der Punktsch√§tzer der UV `g`.
Die Grenzen eines 95%-CI f√ºr die UV liegen bei `r m1_lo_ci` bzw. `r m1_high_ci`.
Dieser Bereich enth√§lt die Null, vgl. @fig-m1-params.
Daher kann nicht ausgeschlossen werden,
dass Bringtnixtin nix bringt.

>   üë®‚Äçüè´ Frau Professor Lustig, wie kann das sein, dass sich die Hypothese nicht best√§tigt?

>   üë©‚Äçüè´ Herr Professor Sauer, auch ein negatives Ergebnis bringt die Wissenschaft weiter.


Testen wir eine Nullhypothese mit dem ROPE-Verfahren: `rope(m_bringtnixtin)`, s. @tbl-m1-rope und @fig-m1-rope.




```{r}
#| label: tbl-m1-rope
#| tbl-cap: ROPE f√ºr Modell m_bringtnixtin
#| echo: false
rope(m_bringtnixtin) %>% print_md()
```

```{r}
#| label: fig-m1-rope
#| fig-cap: "ROPE f√ºr Modell `m_bringtnixtin`"

rope(m_bringtnixtin) %>% plot()
```


Da sich das 95%-CI mit dem ROPE √ºberlappt, kann die Nullhypothese bzw. das ROPE (kein praktisch bedeutsamer Effekt) *nicht* ausgeschlossen werden.

```{r}
#| echo: false

m1_pd <- pd(m_bringtnixtin)$pd[2] %>% round(2)
```



Eine vergleichbare Information bietet uns die Kennzahl `pd`, s. @tbl-m1-params.
Der Wert f√ºr `g` liegt bei ca. `r m1_pd`.

:::{.callout-note}
`pd` gibt die Wahrscheinlichkeit (laut Modell) an, dass der Effekt in der Population negativ bzw. positiv ist (d.h. gleich dem Vorzeichen des Punktsch√§tzers; in diesem Fall negativ).$\square$
:::

<!-- Das Modell ist sich nicht sehr sicher, in welche Richtung der Effekt von Bringtnixtin zeigt. -->
<!-- Das Modell neigt eher zur Meinung, dass der Effekt von `g` (in der Population) *negativ* ist. Ganz sicher ist sich aber das Modell nicht. -->
Das Modell ist sicher ziemlich sicher, dass der Effekt von `g` (in der Population) *negativ* ist. 

>   üë®‚Äçüè´ Frau Professor Lustig, oh je!

>   üë©‚Äçüè´ Herr Professor Sauer, wir m√ºssen erst einmal in Ruhe die Studie replizieren. Eine Schwalbe macht noch keinen Fr√ºhling.



## Vorher-Nachher-Messung, 1 between-Variable


### Design

@sauer_effect_2023 fiel auf, dass es sinnvoller ist, zuerst die AV mittels eines Vortests zu messen, dann die Intervention anzuwenden, und dann nachher (Posttest) die AV wieder zu messen.
Daher haben sie sowohl vor der Intervention (`t1`) als auch nach der Intervention (Gabe von Bringtnixtin), `t2`, die AV (`y`, Behaltensleistung) gemessen.


:::{.callout-note}
Eine Vorher-Nachher-Messung hat den Verteil, dass sie - im Gegensatz zur Nur-Nachher-Messung - unterschiedliche Ausgangswerte in der AV herausrechnet. 
Bei gro√üen Gruppen wird sich bei einer randomisierten Zuweisung zu den Gruppen der Ausgangswert der AV angleichen. Bei nicht so gro√üen Gruppen kann aber auch bei Randomisierung ein - mitunter erheblicher - Unterschied zwischen den Gruppen verbleiben.
Findet man bei der Post-Messung einen Effekt, so kann es sein, dass dieser nicht auf die Intervention beruht, sondern auf die von vornherein vorhandenen Unterschieden zwischen den Gruppen.$\square$
:::


:::{#callout-note}
Vergleicht man die Delta-Werte zwischen zwei Gruppen,
berechnet man die Differenz zwischen den Gruppen der Delta-Werte.
Man spricht daher von einer *Difference-in-Difference-Analyse*.$\square$
:::



@fig-bringtnixtin-flow2 zeigt den Ablaufplan dieses Experiments.

```{mermaid}
%%| label: fig-bringtnixtin-flow2
%%| fig-cap: Ablaufdiagramm der Bringtnixtin-Studie

flowchart LR
  Intro --> y1
  y1 --> g.1
  y1 --> g.2
  g.1 --> y2
  g.2 --> y2
  y2 --> outro
```

DAG des Experiments ist in @fig-bringtnixtin-dag2 dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-bringtnixtin-dag2
#| fig-cap: "DAG f√ºr der Bringtnixtin-Studie"
#| echo: false

mein_modell <- "dag{
g -> d
u -> d
}"

plot(graphLayout(mein_modell))
```

### Deskriptive Analyse

Eine einfache (und sinnvolle) Art, solche Studiendesigns auszuwerten ist die Bildung einer Differenz-Variable^[auch Delta-Veriable genannt].
Diese Differenzvariable gibt die Ver√§nderung der fluiden Intelligenz durch die Intervention an.
Anders gesagt: Die Differenz ist die IQ-Wert einer Person *nach* der Intervention minus dem IQ-Wert *vor* der Intervention: $d = y_2 - y_1$:

```{r}
d_bringtnixtin <-
  d_bringtnixtin %>% 
  mutate(d = y2 - y1)
```

Schauen wir uns die ersten paar d-Werte f√ºr jede der beiden Gruppen (`g=0`  bzw. `g=1`) an:

```{r}
#| echo: false
d_bringtnixtin %>% 
  group_by(g) %>% 
  slice_head(n = 3) %>% 
  print_md()
```


<!-- Puh! Das Bringtnixtin scheint die IQ zu *verringern*, zumindest in einigen F√§llen. -->




Vielleicht ist es anschaulicher, wenn wir die Gruppe `0` in den Text `Kontrollgruppe` umbenennen und `1` in `Experimentalgruppe`:


```{r}
d_bringtnixtin <-
  d_bringtnixtin %>% 
  mutate(g_text =
           case_when(g == 0 ~ "Kontrollgruppe",
                     g == 1 ~ "Experimentalgruppe"))
```

Hier sind die Mittelwerte f√ºr jede der beiden Gruppen:



```{r}
#| eval: false
d_bringtnixtin %>% 
  group_by(g_text) %>%
  summarise(d = mean(d))
```

```{r}
#| echo: false
#| label: d-bringtnixtin-mean
#| tbl-cap: "Mittelwerte der Ver√§nderung der Behaltensleistung nach Gruppe"
d_bringtnixtin %>% 
  group_by(g_text) %>%
  summarise(d = mean(d)) %>% 
  print_md()
```

Die deskiptiven Kennwerte sind in @fig-bringtnixtin-desk2 dargestellt.


```{r}
#| label: fig-bringtnixtin-desk2
#| fig-cap: "Ver√§nderung der fluiden Intelligenz (d) in Abh√§ngigkeit der Gruppe; g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)"
ggbetweenstats(
  data = d_bringtnixtin,
  x = g_text,
  y = d,
  results.subtitle = FALSE  # keine Statistiken zeigen
)
```



### Modellierung

Wir modellieren (in `m_bringtnixtin2`) jetzt die Ver√§nderung `d = y2 - y1` als AV; UV ist wieder `g`, s. @tbl-m-bringtnixtin2-params.

```{r}
#| results: hide
m_bringtnixtin2 <- stan_glm(d ~ g, data = d_bringtnixtin, refresh = 0)
parameters(m_bringtnixtin2)
```
```{r}
#| echo: false
#| label: tbl-m-bringtnixtin2-params
#| tbl-cap: "Parameter von `m_bringtnixtin2`"
parameters(m_bringtnixtin2) %>% 
  print_md()
```


@fig-bringtnixtin2-params zeigt die Parameterwerte f√ºr `m_bringtnixtin2`,

```{r}
#| fig-cap: "Parameterwerte von m_bringtnixtin2 (Intercept ist nicht dargestellt), 95%-ETI; die Null ist nicht enthalten, der Mittelwert ist negativ."
#| label: fig-bringtnixtin2-params
plot(parameters(m_bringtnixtin2))
```


Wie man den Parameterwerten entnehmen kann,
ist sich das Modell sehr sicher, dass der Effekt von Bringtnixtin *negativ* ist.
<!-- ist sich das Modell nicht sicher, welche Richtung der Effekt von Bringtnixtin hat. -->


## Beobachtungsstudien

G√§ngige Forschungsfragen f√ºr Beobachtungsstudien sind [hier](https://start-bayes.netlify.app/https://start-bayes.netlify.app/1000-metrische-av) erl√§utert.






## 1 within-Variable


Eine Studie mit Vorher-Nachher-Messung setzt ein Within-Design um.


:::{#exm-within1}
### Statisches Diagramm vs. animiertes Diagramm
Ein Forschungsteam untersuch den Effekt der UV *Diagrammart* `D` (mit den zwei Stufen `D.1` *animiert* und `D.2` *statisch*) auf die Behaltensleistung (`y`) von Probanden.
Nach jeder Bedingung wird die Behaltensleistung gemessen (anhand von 10 Wissensfragen, die jeweils als "richtig" oder "falsch" bewertet wurden), mit `y1` nach `D.1` und `y2` f√ºr `D.2`.$\square$
:::



### Design


Forschungsfrage:

>    Hat die Diagrammart einen Einfluss auf die Behaltensleistung? Anders gesagt: Unterscheiden sich die Diagrammarten in ihrem Einfluss auf die mittlere Behaltensleistung?


Die zugeh√∂rige statistische Hypothese kann man so formulieren: $\bar{d} \ne 0$, wobei $d = y_1 - y_2$.
$d$ misst also den Unterschied der Behaltensleistung von animierten und statischen Diagrammen,
wobei positive Werte zugunsten von statischen Diagrammen sprechen.

Die Modellformel lautet: `d ~ 1`,
das ist ein *Intercept-Modell*, also ein Modell ohne Pr√§diktor. 
Uns interessiert, ob die Variable `d` im Mittelwert ungleich Null ist oder positiv (zugunsten statischer Diagramme) oder negativ (Behaltensleistung h√∂her bei animierten Diagrammen).

Der Ablauf ist in @fig-diagrammart-flow dargestellt.

```{mermaid}
%%| label: fig-diagrammart-flow
%%| fig-cap: "Ablauf der Studie zur Behaltensleistung y2 in Abh√§ngigkeit der Diagrammart d (Within-Variable)"
flowchart LR
  D.1 --> y1 --> D.2 --> y2
```




Der DAG des Experiments ist in @fig-diagrammarten-dag dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-diagrammarten-dag 
#| fig-cap: "DAG f√ºr die Studie zur Behaltensleistung y2 in Abh√§ngigkeit der Diagrammart D"
#| echo: false

mein_modell <- "dag{
d -> y2
u -> y2
}"

plot(graphLayout(mein_modell))
```

### Deskriptive Analyse

Hier sind einige Spieldaten:

```{r}
#| message: false
d_within <- 
  read_csv("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv") %>% 
  select(-c(y3, g)) # diese beiden Variablen ignorieren wir f√ºr den Augenblick

head(d_within)
```

{{< downloadthis data/withindesign.csv >}}




Wir berechnen `d`, das die zentrale Variable der Forschungsfrage ist.


```{r}
d_within <-
  d_within %>% 
  mutate(d = y1 - y2)

head(d_within)
```

Es klingt trivial, aber man muss sich ein Bild von den Daten (hier `d`) machen, wortw√∂rtlich, s. @fig-d1.

```{r}
#| label: fig-d1
#| fig-cap: "Die Verteilung von d: Die Behaltensleistung ist im Mittel besser f√ºr animierte Diagramme (in diesen Daten)"
gghistostats(d_within,
             x = d,
             results.subtitle = FALSE  # verzichte auf zus√§tzliche Statistiken
             )
```

Da `d` im Mittel negativ ist, ist der Mittelwert von `y2` (animiert) h√∂her als der von `y1` (statisch).

Lassen wir uns die deskriptiven Kennwerte ausgeben, s. @tbl-d1-desk.


```{r}
#| eval: false
d_within %>% 
  describe_distribution(d)
```


```{r}
#| label: tbl-d1-desk
#| tbl-cap: Statistiken f√ºr `d` 
#| echo: false
d_within %>% 
  describe_distribution(d) %>% 
  print_md()
```


Um die Daten noch anders  visualisieren zu k√∂nnen, formen wir sie ins "lange Format" um.

```{r}
d_long <-
  d_within %>% 
  pivot_longer(cols = c(y1, y2), names_to = "time", values_to = "y")
```
Hier ist ein Auszug aus der Tabelle:

```{r}
head(d_long)
```


Visualisieren wir uns die Daten, s. @fig-d2.

```{r}
#| label: fig-d2
#| fig-cap: Der Unterschied in der Behaltensleistung pro Versuchsperson; im Durchschnitt ist der Wert bei y2 h√∂her als bei y1
ggwithinstats(
  data = d_long,
  x = time,
  y = y,
  results.subtitle = FALSE  # verzichte auf zus√§tzliche Statistiken
)
```


### Inferenzanalyse

Wir berechnen das Modell (`m_within`):

```{r}
#| results: hide
m_within <- stan_glm(d ~ 1, data = d_within, refresh = 0)
parameters(m_within)
```

```{r}
#| echo: false
parameters(m_within) %>% 
  print_md()
```


Hier ist eine Visualisierung des 95%-ETI des Unterschieds (`d`) zwischen den beiden Bedingungen (@fig-m-within-params).

```{r}
#| label: fig-m-within-params
#| fig-cap: "95%-CI f√ºr d (Achsenabschnitt mit Modell m_within)" 
parameters(m_within) %>% plot(show_intercept = TRUE)
```

Wie man sieht, ist die Null nicht im CI enthalten. Wir k√∂nnen daher res√ºmieren,
dass es einen Unterschied zwischen den Bedingungen (statisch vs. animiert) gibt hinsichtlich `y2` (Behaltensleistung). Die Behaltensleistung animierter Diagramme ist der von statischen Diagrammen √ºberlegen (laut diesem Modell).


## 1 within-Variable, 1 between-Variable

### Design

Forschungsfrage:


>    Hat die Diagrammart einen Einfluss auf die Behaltensleistung? Anders gesagt: Unterscheiden sich die Diagrammarten in ihrem Einfluss auf die Behaltensleistung? Dabei kontrollieren wir die Reihenfolge.

Forschungspraktisch bedeutet das, dass es zwei Gruppen, `g1` und `g2` in diesem Experiment gibt.
Diese beiden Gruppen definieren eine between-Variable, `g`, die die Reihenfolge der Darbietung kontrolliert, s. @fig-within2-flow.
Die Diagrammart `D` ist auch eine UV, aber als Within-Variable konzipiert.


```{mermaid}
%%| label: fig-within2-flow
%%| fig-cap: "Ablaufdiagramm f√ºr die Studie mit der Modellgleichung mit einem Within- und einem Between-Faktor"
flowchart LR
  subgraph g2
    direction LR
    D.1 --> y1 --> D.2 --> y2
  end
  subgraph g1
    direction LR
    D2[D.2] --> y22[y2] --> D1[D.1] --> y11[y1] 
  end
```



Da es zwei UVs gibt, gibt es auch zwei Hypothesen:

1. H1: $\bar{d} < 0$, mit $d = y_1 - y_2$: Die mittlere Behaltensleistung ist in der Bedingung *animiert*  h√∂her als in der Bedingung *statisch*.
2. H2: $\bar{d}_{g.1} = \bar{d}_{g.2}$: Der Unterschied in der Behaltensleistung zwischen den zwei Bedingung unterscheidet sich nicht von der Reihenfolge der Darbietung.



Die Modellformel lautet: `d ~ 1 + g`.
Das kann man synonym so schreiben: `d ~ g`.


Der DAG des Experiments ist in @fig-within2-dag dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-within2-dag
#| fig-cap: "DAG f√ºr die Studie mit der Modellgleichung mit einem Within- und einem Between-Faktor. Es wird kein Effekt f√ºr g erwartet, wohl aber ein Effekt f√ºr D"
#| echo: false

mein_modell <- "dag{
D -> y2
u -> y2
g 
}"

plot(graphLayout(mein_modell))
```



### Deskriptive Analyse

Hier sind einige Spieldaten:

```{r}
#| message: false
d_within <- 
  read_csv("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv") %>% 
  select(-c(y3)) # die  Variable `y3` ignorieren wir f√ºr den Augenblick

head(d_within)
```



Wir berechnen `d`, der Unterschied zwischen den beiden Bedingungen:

```{r}
d_within <-
  d_within %>% 
  mutate(d = y1 - y2)

head(d_within)
```

Betrachten wir den Unterschied von `d` zwischen den Gruppen (H2), s. @fig-d-within2.

```{r}
#| label: fig-d-within2
#| fig-cap: Der Unterschied der Behaltensleistung (d) in Abh√§ngigkeit von der Reihenfolge der Darbietung
ggbetweenstats(
  d_within,
  x = g,
  y = d,
  results.subtitle = FALSE
)
```

Es gibt einen gewissen Unterschied zwischen den beiden Reihenfolgen (A und B) wie @fig-d-within2 zeigt;
die Reihenfolge k√∂nnte also einen Einfluss auf `d` haben.
Aber wir m√ºssen inferenzstatistisch pr√ºfen, wie gro√ü der Einfluss ist.



### Inferenzanalyse

Berechnen wir `m_within2`, das nicht nur den Intercept pr√ºft (wie `m_within1`), 
sondern auch zus√§tzlich den Effekt der Reihenfolge (`g`).

```{r m-within2}
m_within2 <- stan_glm(d ~ g, data = d_within, refresh = 0)
```

```{r}
#| echo: false
parameters(m_within2) %>% 
  print_md()
```


Das CI f√ºr die Reihenfolge (Variable `gB`) beinhaltet die Null;
Daher kann ein Nulleffekt der Reihenfolge - also kein Effekt der Reihenfolge - nicht ausgeschlossen werden, `g=0` ist also im Bereich der plausiblen Werte.

Der Effekt f√ºr `d` (`(Intercept)`) zeigt ein Intervall, das die Null (knapp) enth√§lt.
Daher k√∂nnen wir wir die Nullhypothese nicht mit hoher Sicherheit ausschlie√üen.

In Summe:

1. H1 (H√∂here Behaltensleistung von *animiert*) konnte nicht best√§tigt werden, aber tendenziell fand sich ein Effekt in erwarteter Richtung (zugunsten einer h√∂heren Behaltensleistung von *animiert*).
2. H2 (Reihenfolgeeffekt) konnte nicht best√§tigt werden.


## Vertiefung



### 1 within-Variable mit mehr als zwei Stufen

{{< fa dumbbell >}} VERTIEFUNG {{< fa dumbbell >}} - Sie k√∂nnen diesen Abschnitt ohne Gefahr ignorieren.


### Design

Eine Forscherin hat die Gesundheit (`y`) von Studentis drei Mal (t1, t2, t3) im Zeitraum eines Semesters untersucht.

Ihre Forschungsfrage lautet, ob sich die Gesundheit im Laufe des Semesters substanziell ver√§ndert.
Ihre Hypothese lautet, dass die Werte √ºber die Zeit hinweg stabil bleiben.

### Deskriptive Analyse

Hier sind einige Spieldaten:

```{r}
#| message: false
d_within <- 
  read_csv("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv")

head(d_within)
```

Hier ben√∂tigen wir die Daten in Langform:


```{r}
d_long <-
  d_within %>% 
  pivot_longer(cols = y1:y3, names_to = "time", values_to = "y")

head(d_long)
```


Es hilft (wie meistens), sich die Daten zu visualisieren, s. @fig-within-y3.

```{r}
#| label: fig-within-y3
#| fig-cap: "Messwerte (y) in Abh√§ngigkeit vom Messzeitpunkt (t1, t2, t3)"
#| fig-subcap: 
#|   - Einfaches Punktediagramm
#|   - Informationsreiches Punkte-, Boxplot- und Violinendiagramm mit Statistiken der Ver√§nderung angereichert
#| layout-ncol: 2
p_y123_a <-
  d_long %>% 
  ggplot(aes(x = time, y = y)) +
  geom_jitter(width = .2)

p_y123_b <-
  ggwithinstats(d_long, 
                x = time,
                y = y,
                results.subtitle = FALSE)

p_y123_a
p_y123_b
```


Berechnen wir die Mittelwerte von `y` pro Messzeitpunkte sowie die Ver√§nderung von t1 zu t2 bzw. von t2 zu t3, s. @tbl-d123.

```{r}
#| eval: false
d_long %>% 
  group_by(time) %>% 
  summarise(y_mean = mean(y)) %>% 
  mutate(d = y_mean - lag(y_mean))
```


```{r}
#| label: tbl-d123
#| tbl-cap: "Mittelwerte von `y` pro Messzeitpunkte (`y_mean`) sowie die Ver√§nderung von t1 zu t2 bzw. von t2 zu t3 (`d`)"
#| echo: false
d_long %>% 
  group_by(time) %>% 
  summarise(y_mean = mean(y)) %>% 
  mutate(d = y_mean - lag(y_mean)) %>% 
  print_md()
```



### Inferenzanalyse



```{r}
m_within3 <- stan_lmer(y ~ 1 + (1 | time), data = d_long, refresh = 0)
summary(m_within3)
```

Die Schreibweise `(1 | time)` soll sagen, dass die Messwerte innerhalb von `time` verschachtelt sind und variieren. 
Die `1` sagt, dass es sich bei der variierenden Gr√∂√üe um den Intercept handelt,
nicht um eine UV.

Ein "fixer" Effekt ist ein Effekt, f√ºr den kein Pooling stattfindet,
das ist hier der Intercept.

Nur die festen (*fixed*) Effekte kann man sich so ausgeben lassen:

```{r}
fixef(m_within3)
```


Im Durchschnitt werden ca. 7.1 Fragen richtig beantwortet (Gesamtmittel);
das ist die Information die der Punktsch√§tzer des Intercepts bietet.


Nur die Random-Effekte kann man sich so ausgeben lassen:

```{r}
ranef(m_within3)
```

Das sind jeweils die Abweichungen der Gruppenmittelwerte (y1, y2, y3) vom Gesamtmittel.
Die Random-Effekte kann man sich visualisieren lassen, s. @fig-randef-m3.

```{r}
#| label: fig-randef-m3
#| fig-cap: "95%-CI der Random-Effekte von `m_within3`"
plot(m_within3)
```



### Mediatoranalyse

[Hier](https://wgruber.github.io/Modellbildung2/mediation.html) findet sich eine Einf√ºhrung in die Mediationsanalyse.
[Dieses R-Paket](https://github.com/GerkeLab/mediator/tree/master) stellt ebenfalls komfortable Funktionen zur Verf√ºgung f√ºr Mediationsanalysen.




## Fazit

Unter Modellieren versteht man in der Forschungspraxis meist ein Regressionsmodell der Form `av ~ uv`.
Die Inferenzstatistik hilft, die Modellparameter mit Sch√§tzwerten f√ºr die Population zu versehen.


## Aufgaben


S. bei [Datenwerk]() die Aufgaben mit dem Tag [research-question](https://datenwerk.netlify.app/#category=research-question) und [researchdesign](https://datenwerk.netlify.app/#category=researchdesign)


- [within-design-analysis1](https://datenwerk.netlify.app/posts/within-design-analysis1/within-design-analysis1.html)
