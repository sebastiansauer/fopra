# Auswerten: Modellieren {#sec-modellieren}


```{r}
#| include: false
library(tidyverse)
library(dagitty)
library(easystats)
```


```{r}
#| echo: false
library(ggplot2)
theme_set(theme_minimal())
```

## Lernsteuerung


### Lernziele


- Sie k√∂nnen die Modellformel Ihrer Forschungsfrage nennen.
- Sie k√∂nnen Ihre Modellformel (korrekt) in R spezifizieren.
- Sie k√∂nnen Ihr Modell in R berechnen und die Ausgabe interpretieren.
<!-- - Sie k√∂nnen die G√ºltigkeit bzw. die Grenzen der Aussagen Ihres Modells einsch√§tzen. -->


### Ben√∂tigte R-Pakete


```{r}
#| message: false
library(tidyverse)
library(easystats)
library(ggstatsplot)  # Visualisierung
library(ggpubr)  # Visualisierung
library(rstanarm)  # Bayes
```



### Position im Lernpfad

Sie befinden sich im Abschnitt "Auswerten" in @fig-ueberblick.
Behalten Sie Ihren Fortschritt im Projektplan im Blick, s. @fig-projektplan.





### Weitere Lernmaterialien

#### Skript Bayes-Modellierung üìñ

Die Grundlagen der statistischen Modellierung mit einem Fokus auf Bayes-Modellen k√∂nnen Sie [hier](https://start-bayes.netlify.app/) nachlesen.


#### Videos üìΩÔ∏è

In einigen Playlists des Autors finden Sie Videos passend zu diesem Kapitel:

- [Playlist "Forschungspraxis](https://youtube.com/playlist?list=PLRR4REmBgpIEh_YSXawzTs6jybXFcXJxM&si=R-YT9lsIOuW_vXP-)
- [Playlist "ROPE"](https://www.youtube.com/playlist?list=PLRR4REmBgpIGKGnvnpno2Cc3kq294RQsl)
- [Playlist "Bayes"](https://www.youtube.com/playlist?list=PLRR4REmBgpIFRDF5WvsNM9Bqj_bhYJLHG)
- [Playlist "Regression](https://www.youtube.com/playlist?list=PLRR4REmBgpIFoiu3mVXF0zISTKzBOYfdy)

### √úberblick

In diesem Kapitel sind die grundlegenden Verfahren zur Modellierung und inferenzstatistischen Absicherung Ihrer Forschungsfragen angerissen.
Die Darstellung zielt auf ein "so-geht's" ab, nicht auf eine vollst√§ndige Darstellung aller Auswertungsm√∂glichkeiten.

## 1 between-Variable, nur Nachher-Messung

### Design

@sauer_effect_2023 untersuchten in einer Querschnittsstudie den Effekt des Wirkstoff *Bringnixtin* auf die fluide Intelligenz. Die Autoren nahmen an, dass der Wirkstoff den individuellen Wert der abh√§ngigen Variable erh√∂hen w√ºrde.


Der Ablauf (aus Sicht der Probandis) ist in @fig-bringtnixtin-flow dargestellt.
`Intro` fasst die Begr√º√üung der Probandis inkl. Informed Consent sowie Erfassung von soziodemografischen Variablen zusammen.
`g.0` und `g.1` sind die zwei Stufen der UV (*g* wie Gruppe), wobei `g.0` die Kontrollgruppe kodiert (Placebo, also Zuckerpille, kein Wirkstoff,) und `g.1` die *zweite* Stufe, d.h. die Experimentalgruppe (hohe Dosis Bringtnixtin).
`y2` ist die Messung der AV (d.h. nach Gabe von Bringtnixtin), d.h. ein Ma√ü der fluiden Intelligenz.
`outro` meint die Verabschiedung der Probanden sowie einige Fragen zu Compliance.


Die Hypothese lautet: $\mu_{g.2} > \mu_{g.1}$. 

In Worten:

>  Wir erwarten, dass der Mittelwert der Experimentalgruppe h√∂her ist als der Mittelwert der Kontrollgruppe.



```{mermaid}
%%| label: fig-bringtnixtin-flow
%%| fig-cap: Ablaufdiagramm der Bringtnixtin-Studie

flowchart LR
  Intro --> g.0
  Intro --> g.1
  g.0 --> y2
  g.1 --> y2
  y2 --> outro
```

Der DAG des Experiments ist in @fig-bringtnixtin-dag dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-bringtnixtin-dag
#| fig-cap: "DAG f√ºr der Bringtnixtin-Studie"
#| echo: false

mein_modell <- "dag{
g -> y2
u -> y2
}"

plot(graphLayout(mein_modell))
```


:::{.callout-note}
Im DAG  @fig-bringtnixtin-dag ist `u` als Ursache von `y2` angegeben.
`u` steht hier stellvertretend f√ºr alle weiteren Ursachen von `y2`, vermutlich sind das sehr viele.
Aber sie interessieren uns nicht.
Daher k√∂nnen Sie `u` auch aus dem DAG weglassen.
Streng genommen sollten Sie es sogar weglassen,
denn im DAG zeigt man nur diejenigen Variablen, die f√ºr Ihre Hypothese von Belang sind. 
Da `u` keine Verbindung zum Pfad `g -> y2` hat,
brauchen wir es f√ºr die Bestimmung des Kausaleffekts nicht zu ber√ºcksichtigen.$\square$
:::

```{r d_bringtnixtin}
#| echo: false
#| eval: true
n_bringtnixtin <- 40

set.seed(42)
d_bringtnixtin <-
  tibble(id = 1:n_bringtnixtin,
         g = c(rep(0, n_bringtnixtin/2), rep(1, n_bringtnixtin/2)),
         y1 = rnorm(n_bringtnixtin),
         y2 = y1 + rnorm(n_bringtnixtin, mean = 0, sd = .2) - g/3,
         d = y2 - y1
  )

#write_csv(d_bringtnixtin, "data/d_bringtnixtin.csv")
```


Die Daten dieses Experiments sind hier zu beziehen:

```{r}
#| message: false
#| eval: false
d_bringtnixtin_path <- "https://raw.githubusercontent.com/sebastiansauer/fopra/main/data/d_bringtnixtin.csv"
d_bringtnixtin <- read_csv(d_bringtnixtin_path)
```


{{< downloadthis data/d_bringtnixtin.csv dname = "bringtnixtin.csv" >}}

Die Autoren der Studie geben an, dass die Daten in *z*-Einheiten skaliert sind.


### Deskriptive Analyse


```{r}
#| eval: false
d_bringtnixtin %>% 
  group_by(g) %>% 
  summarise(iq_mw = mean(y2),
            iq_sd = sd(y2)) 
```




```{r}
#| echo: false
#| label: tbl-bringtnixtin-desk
#| tbl-cap: "Mittlere fluide Intelligenz nach der Bringtnixtin-Intervention in Abh√§ngigkeit der Gruppe"
d_bringtnixtin %>% 
  group_by(g) %>% 
  summarise(iq_mw = mean(y2),
            iq_sd = sd(y2)) 
```

Die deskriptiven Kennwerte sind in @fig-bringtnixtin-desk1 bzw. @fig-bringtnixtin-desk1 visualisiert.
Das sieht nicht gerade nach einem gro√üen Effekt aus ...^[Die Mittelwerte der beiden Gruppen sind praktisch identisch.]

:::{.panel-tabset}


### Mit ggstatsplot

```{r}
#| label: fig-bringtnixtin-desk1
#| fig-cap: "Fluide Intelligenz (y2) nach der Bringtnixtin-Intervention. g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)"
ggbetweenstats(
  data = d_bringtnixtin,
  x = g,
  y = y2,
  results.subtitle = FALSE  # keine Statistiken zeigen
)
```


#### Mit ggpubr

```{r}
#| label: fig-bringtnixtin-desk2
#| fig-cap: "Fluide Intelligenz (y2) nach der Bringtnixtin-Intervention. g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)"
ggboxplot(
  data = d_bringtnixtin,
  x = "g",
  y = "y2"
)
```
::::

Sowohl das R-Paket `ggstatsplot` als auch das R-Paket `ggpubr` bieten ansprechende Datenvisualisierung.^[Beide bauen auf dem R-Paket `ggplot` auf, sind also eigentlich nur "Abk√ºrzungen".]

### Modellierung


Wir berechnen ein lineares Modell mit der Modellformel `y2 ~ g`. 


#### Parametersch√§tzung

Die Ergebnisse unseres Modells `m_bringtnixtin` sind in @tbl-m1-params zu sehen.

```{r}
#| label: tbl-m1-params
#| tbl-cap: Parameter des Modells m_bringtnixtin
m_bringtnixtin <- stan_glm(y2 ~ g, data = d_bringtnixtin, refresh = 0, seed = 42)
parameters(m_bringtnixtin)
```


```{r}
#| echo: false
m_bringtnixtin_hdi <- hdi(m_bringtnixtin)

m1_lo_ci <- m_bringtnixtin_hdi %>% filter(Parameter == "g") %>% pull(CI_low) %>% round(2)
m1_high_ci <- m_bringtnixtin_hdi %>% filter(Parameter == "g") %>% pull(CI_high) %>% round(2)
```


Der Gruppenunterschied wird auf das `r round(coef(m_bringtnixtin)[2], 2)` gesch√§tzt;
das ist der *Punktsch√§tzer* der UV `g`.
Wenn wir nur eine Zahl nennen d√ºrften zu unserem Wissen zum Effekt von `g`, so w√§re das unsere Zahl.
Die Grenzen eines 95%-CI f√ºr die UV liegen bei `r m1_lo_ci` bzw. `r m1_high_ci`; diese beiden Werten markieren die Grenzen des *Intervallsch√§tzers.*
Dieser Bereich enth√§lt die Null, vgl. @fig-m1-params.
Daher kann nicht ausgeschlossen werden,
dass Bringtnixtin *nix* bringt.
Anders gesagt: Die (strenge) Nullhypothese kann *nicht* verworfen werden. Der Wert Null ist ein plausibler Wert f√ºr den Parameter, da er im 95%-CI enthalten ist.


:::{.callout-note}
- Ist der Wert Null NICHT im 95%-Sch√§tzintervall enthalten, so hei√üt das, dass die Null(hypothese) verworfen werden. 
- Ist der Wert Null im 95%-Sch√§tzintervall enthalten, so hei√üt das, dass die Null(hypothese) NICHT verworfen werden. 
$\square$
:::


Die Punkt- und Intervallsch√§tzer (95%-ETI) f√ºr Achsenabschnitt und Regressiongewicht von `g` sind in @fig-m1-params visualisiert.

:::{.callout-note}
Zur Erinnerung: Ein Punktsch√§tzer sch√§tzt einen (unbekannten) Wert in der Population auf einen einzelnen Wert (daher "Punkt").
Ein *Intersch√§tzer* sch√§tzt einen Wertebereich f√ºr diesen unbekannten Wert. $\square$
:::

```{r}
#| eval: false
parameters(m_bringtnixtin) %>% plot(show_intercept = TRUE)
```


```{r}
#| label: fig-m1-params
#| fig-cap: "Parameter des Modells `m_bringtnixtin (95%-ETI)`; der ROPE ist als vertikaler blauer Balken markiert"
parameters(m_bringtnixtin) %>% plot(show_intercept = TRUE) +
  geom_rect(aes(xmin = -.13, xmax = 0+.13, ymin = -Inf, ymax = Inf), 
              fill = "lightblue", alpha = .3, color = NA)
```






>   üë®‚Äçüè´ Frau Professor Lustig, wie kann das sein, dass sich die Hypothese nicht best√§tigt?

>   üë©‚Äçüè´ Herr Professor Sauer, auch ein negatives Ergebnis bringt die Wissenschaft weiter.


#### Praktisch-Null-Hypothese (ROPE)

Mit dem ROPE-Verfahren kann man eine "Praktisch-Null-Hypothese" testen, 
also ob ein Bereich *um die Null herum*, also "Null plus-minus ein bisschen" im Hauptbereich im Hauptbereich (95%-KI) enthalten ist.

In R geht das so: `rope(m_bringtnixtin)`, s. @tbl-m1-rope und @fig-m1-rope.




```{r}
#| label: tbl-m1-rope
#| tbl-cap: ROPE f√ºr Modell m_bringtnixtin
#| echo: false
rope(m_bringtnixtin) %>% print_md()
```

@tbl-m1-rope zeigt uns, dass 3% des 95%-HDIs im ROPE-Bereich liegt.
Das ist nicht viel; aber streng genommen hei√üt das als Fazit:

>    Wir k√∂nnen nicht ausschlie√üen, dass der Effekt von `g` ein praktisch unbedeutsamen Wert hat,
also sehr klein und nahe der Null ist. Diese Wahrscheinlichkeit ist allerdings nicht hoch. Es ist somit *keine* klare Entscheidung m√∂glich.

Ist man sich nicht sicher, wie der ROPE-Wert zu interpretieren ist,
kann man auch R fragen:

```{r}
interpret_rope(0.03)
```



Das gleiche Ergebnis zeigt uns anschaulicher @fig-m1-rope.

```{r}
#| eval: false
rope(m_bringtnixtin) %>% plot()
```



```{r}
#| label: fig-m1-rope
#| fig-cap: "ROPE f√ºr Modell `m_bringtnixtin`"

plot(rope(m_bringtnixtin)) + scale_fill_okabeito() 
```

[`scale_fill_okabeito()`](https://malcolmbarrett.github.io/ggokabeito/reference/scale_okabe_ito.html) ist eine Funktion aus dem Metapaket `{easystats}`.^[Genauer gesagt aus dem Paket `{see}`, das ein Teil des Metapakets `{easystasts}` ist.]
Das [Farbschema nach Okabe und Ito](https://jfly.uni-koeln.de/color/) ist gut geeignet, um nominal skalierte Farben zu kodieren (s. Details [hier](https://data-se.netlify.app/2023/06/30/farbpaletten/)).

Da sich das 95%-CI mit dem ROPE √ºberlappt, kann die Nullhypothese bzw. das ROPE (kein praktisch bedeutsamer Effekt) *nicht* ausgeschlossen werden.

```{r}
#| echo: false

m1_pd <- pd(m_bringtnixtin)$pd[2] %>% round(2)
```



Eine vergleichbare Information bietet uns die Kennzahl `pd`, s. @tbl-m1-params.
Der Wert f√ºr `g` liegt bei ca. `r m1_pd`.

:::{.callout-note}
`pd` gibt die Wahrscheinlichkeit (laut Modell) an, dass der Effekt in der Population negativ bzw. positiv ist (d.h. gleich dem Vorzeichen des Punktsch√§tzers; in diesem Fall negativ).$\square$
:::

<!-- Das Modell ist sich nicht sehr sicher, in welche Richtung der Effekt von Bringtnixtin zeigt. -->
<!-- Das Modell neigt eher zur Meinung, dass der Effekt von `g` (in der Population) *negativ* ist. Ganz sicher ist sich aber das Modell nicht. -->
Das Modell ist sicher *ziemlich* sicher, dass der Effekt von `g` (in der Population) *negativ* ist. 
Aber eine kleine Chance, dass der Effekt von `g` doch (ungef√§hr) Null oder sogar positiv ist, bleibt.

>   üë®‚Äçüè´ Frau Professor Lustig, oh je! Unser Wirkstoff Bringtnixtin bringt anscheinend gar nix!

>   üë©‚Äçüè´ Herr Professor Sauer, wir m√ºssen erst einmal in Ruhe die Studie replizieren. Eine Schwalbe macht noch keinen Fr√ºhling.


#### Modellg√ºte

Berechnen wir abschlie√üend noch eine standardisierte Effektst√§rke der Modellg√ºte, $R¬≤$.

```{r}
r2(m_bringtnixtin)
```


Also etwa 9% erkl√§rte Varianz.
Aber ist das viel oder wenig?
Fragen wir Herr Cohen, der hat sich dazu mal Gedanken gemacht.

```{r}
interpret_r2(.09)
```


Nach dieser Einsch√§tzung ist der Effekt von `g` also schwach.


## Vorher-Nachher-Messung, 1 between-Variable


### Design

@sauer_effect_2023 fiel auf, dass es sinnvoller ist, zuerst die AV mittels eines Vortests zu messen, dann die Intervention anzuwenden, und dann nachher (Posttest) die AV wieder zu messen.
Daher haben sie sowohl vor der Intervention (`t1`) als auch nach der Intervention (Gabe von Bringtnixtin), `t2`, die AV (`y`, Behaltensleistung) gemessen.


:::{.callout-note}
Eine Vorher-Nachher-Messung hat den Verteil, dass sie - im Gegensatz zur Nur-Nachher-Messung - unterschiedliche Ausgangswerte in der AV herausrechnet.
Damit kommt man oft zu belastbareren, also besseren, Ergebnissen.
Bei gro√üen Gruppen wird sich bei einer randomisierten Zuweisung zu den Gruppen der Ausgangswert der AV angleichen. Bei nicht so gro√üen Gruppen kann aber auch bei Randomisierung ein - mitunter erheblicher - Unterschied zwischen den Gruppen verbleiben.
Findet man bei der Post-Messung einen Effekt, so kann es sein, dass dieser nicht auf die Intervention beruht, sondern auf die von vornherein vorhandenen Unterschieden zwischen den Gruppen.$\square$
:::


:::{#callout-note}
Vergleicht man die Delta-Werte zwischen zwei Gruppen,
berechnet man die Differenz zwischen den Gruppen der Delta-Werte.
Man spricht daher von einer *Difference-in-Difference-Analyse*.$\square$
:::



@fig-bringtnixtin-flow2 zeigt den Ablaufplan dieses Experiments.

```{mermaid}
%%| label: fig-bringtnixtin-flow2
%%| fig-cap: Ablaufdiagramm der Bringtnixtin-Studie

flowchart LR
  Intro --> y1
  y1 --> g.1
  y1 --> g.2
  g.1 --> y2
  g.2 --> y2
  y2 --> outro
```

DAG des Experiments ist in @fig-bringtnixtin-dag2 dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-bringtnixtin-dag2
#| fig-cap: "DAG f√ºr der Bringtnixtin-Studie"
#| echo: false

mein_modell <- "dag{
g -> d
u -> d
}"

plot(graphLayout(mein_modell))
```

### Deskriptive Analyse

Eine einfache (und sinnvolle) Art, solche Studiendesigns auszuwerten ist die Bildung einer Differenz-Variable^[auch Delta-Veriable genannt].
Diese Differenzvariable gibt die Ver√§nderung der fluiden Intelligenz durch die Intervention an.
Anders gesagt: Die Differenz ist die IQ-Wert einer Person *nach* der Intervention minus dem IQ-Wert *vor* der Intervention: $d = y_2 - y_1$:

```{r}
d_bringtnixtin <-
  d_bringtnixtin %>% 
  mutate(d = y2 - y1)
```

Schauen wir uns die ersten paar d-Werte f√ºr jede der beiden Gruppen (`g=0`  bzw. `g=1`) an:

```{r}
#| echo: false
d_bringtnixtin %>% 
  group_by(g) %>% 
  slice_head(n = 3) %>% 
  print_md()
```


<!-- Puh! Das Bringtnixtin scheint die IQ zu *verringern*, zumindest in einigen F√§llen. -->




Vielleicht ist es anschaulicher, wenn wir die Gruppe `0` in den Text `Kontrollgruppe` umbenennen und `1` in `Experimentalgruppe`:


```{r}
d_bringtnixtin <-
  d_bringtnixtin %>% 
  mutate(g_text =
           case_when(g == 0 ~ "Kontrollgruppe",
                     g == 1 ~ "Experimentalgruppe"))
```

Hier sind die Mittelwerte f√ºr jede der beiden Gruppen:



```{r}
#| eval: false
d_bringtnixtin %>% 
  group_by(g_text) %>%
  summarise(d = mean(d))
```

```{r}
#| echo: false
#| label: d-bringtnixtin-mean
#| tbl-cap: "Mittelwerte der Ver√§nderung der Behaltensleistung nach Gruppe"
d_bringtnixtin %>% 
  group_by(g_text) %>%
  summarise(d = mean(d)) %>% 
  print_md()
```

Die deskriptiven Kennwerte sind in @fig-bringtnixtin-within-desk dargestellt.


```{r}
#| label: fig-bringtnixtin-within-desk
#| fig-cap: "Ver√§nderung der fluiden Intelligenz (d) in Abh√§ngigkeit der Gruppe; g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)"
ggbetweenstats(
  data = d_bringtnixtin,
  x = g_text,
  y = d,
  results.subtitle = FALSE  # keine Statistiken zeigen
)
```



### Modellierung

Wir modellieren (in `m_bringtnixtin2`) jetzt die *Ver√§nderung* `d = y2 - y1` als AV; UV ist wieder `g`, s. @tbl-m-bringtnixtin2-params.

```{r}
#| results: hide
m_bringtnixtin2 <- stan_glm(d ~ g, data = d_bringtnixtin, refresh = 0, seed = 42)
parameters(m_bringtnixtin2)
```



```{r}
#| echo: false
#| label: tbl-m-bringtnixtin2-params
#| tbl-cap: "Parameter von `m_bringtnixtin2`"
parameters(m_bringtnixtin2) %>% 
  print_md()
```


@fig-bringtnixtin2-params zeigt die Parameterwerte f√ºr `m_bringtnixtin2`,

```{r}
#| fig-cap: "Parameterwerte von m_bringtnixtin2 (Intercept ist nicht dargestellt), 95%-ETI; die Null ist nicht enthalten, der Mittelwert ist negativ. ROPE ist als blaues Balken eingezeichnet. Wir k√∂nnen die exakte und die praktische Nullhypothese ausschlie√üen."
#| label: fig-bringtnixtin2-params
plot(parameters(m_bringtnixtin2)) +
  geom_rect(aes(xmin = -.023, xmax = 0+.023, ymin = -Inf, ymax = Inf), 
              fill = "lightblue", color = NA)
```


Wie man den Parameterwerten entnehmen kann,
ist sich das Modell sehr sicher, dass der Effekt von Bringtnixtin *negativ* ist.
<!-- ist sich das Modell nicht sicher, welche Richtung der Effekt von Bringtnixtin hat. -->


Testen wir noch die Praktisch-Null-Hypothese (f√ºr den Effekt von `g` auf `d`) mit dem ROPE-Verfahern:

```{r}
rope(m_bringtnixtin2)
```


Das Ergebnis zeigt uns, dass wir die Praktisch-Null-Hypothese ausschlie√üen k√∂nnen:
Null Prozent des 95%-HDI liegt im ROPE.

```{r}
#| label: fig-rope-m_bringtnixtin2
#| fig-cap: "95%-HDI und ROPE √ºberlappt nicht: Wir verwerfen die ROPE Hypothese"
plot(rope(m_bringtnixtin2)) + scale_fill_okabeito()
```



## Beobachtungsstudien

G√§ngige Forschungsfragen f√ºr Beobachtungsstudien sind im Skript [Start:Byes](https://start-bayes.netlify.app/) aufgef√ºhrt, schauen Sie mal [hier]https://start-bayes.netlify.app/1000-metrische-av).






## 1 within-Variable


Eine Studie mit Vorher-Nachher-Messung setzt ein Within-Design um.


:::{#exm-within1}
### Statisches Diagramm vs. animiertes Diagramm
Ein Forschungsteam untersuch den Effekt der UV *Visualisierungsart* `V` (mit den zwei Stufen `V.1` *animiert* und `V.2` *statisch*) auf die Behaltensleistung (`y`) von Probanden.
Nach jeder Bedingung wird die Behaltensleistung gemessen (anhand von 10 Wissensfragen, die jeweils als "richtig" oder "falsch" bewertet wurden), mit `y1` nach `V.1` und `y2` f√ºr `V.2`.$\square$
:::



### Design


Forschungsfrage:

>    Hat die Diagrammart einen Einfluss auf die Behaltensleistung? Anders gesagt: Unterscheiden sich die Diagrammarten in ihrem Einfluss auf die mittlere Behaltensleistung?


Die zugeh√∂rige statistische Hypothese kann man so formulieren: $\bar{d} \ne 0$, wobei $d = y_1 - y_2$.
$d$ misst also den Unterschied der Behaltensleistung von animierten und statischen Diagrammen,
wobei positive Werte zugunsten von statischen Diagrammen sprechen.

Die Modellformel lautet: `d ~ 1`,
das ist ein *Intercept-Modell*, also ein Modell ohne Pr√§diktor. 
Uns interessiert, ob die Variable `d` im Mittelwert ungleich Null ist oder positiv (zugunsten statischer Diagramme) oder negativ (Behaltensleistung h√∂her bei animierten Diagrammen).

Der Ablauf der Studie (aus Sicht der Probandis) ist in @fig-diagrammart-flow dargestellt.

```{mermaid}
%%| label: fig-diagrammart-flow
%%| fig-cap: "Ablauf der Studie zur Behaltensleistung y2 in Abh√§ngigkeit der Visualisierungsart V (Within-Variable)"
flowchart LR
  V.1 --> y1 --> V.2 --> y2
```




Der DAG des Experiments ist in @fig-diagrammarten-dag dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-diagrammarten-dag 
#| fig-cap: "DAG f√ºr die Studie zur Behaltensleistung y2 in Abh√§ngigkeit des Visualiserungstyp V"
#| echo: false

mein_modell <- "dag{
V -> y
u -> y
}"

plot(graphLayout(mein_modell))
```

### Deskriptive Analyse

Hier sind einige Spieldaten:

```{r}
#| message: false
d_within <- 
  read_csv("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv") %>% 
  select(-c(y3, g)) # diese beiden Variablen ignorieren wir f√ºr den Augenblick

head(d_within)
```

{{< downloadthis data/withindesign.csv dname = "withindesign.csv" >}}




Wir berechnen `d`, was die zentrale Variable der Forschungsfrage ist.


```{r}
d_within <-
  d_within %>% 
  mutate(d = y1 - y2)

head(d_within)
```

Es klingt trivial, aber man muss sich ein Bild von den Daten (hier `d`) machen, wortw√∂rtlich, s. @fig-d1.

```{r}
#| label: fig-d1
#| fig-cap: "Die Verteilung von d: Die Behaltensleistung ist im Mittel besser f√ºr animierte Diagramme (in diesen Daten)"
gghistostats(d_within,
             x = d,
             results.subtitle = FALSE  # verzichte auf zus√§tzliche Statistiken
             )
```

Da `d` im Mittel negativ ist, ist der Mittelwert von `y2` (animiert) h√∂her als der von `y1` (statisch).

Lassen wir uns die deskriptiven Kennwerte ausgeben, s. @tbl-d1-desk.


```{r}
#| eval: false
d_within %>% 
  describe_distribution(d)
```


```{r}
#| label: tbl-d1-desk
#| tbl-cap: Statistiken f√ºr `d` 
#| echo: false
d_within %>% 
  describe_distribution(d) %>% 
  print_md()
```


Um die Daten noch anders  visualisieren zu k√∂nnen, formen wir sie ins "lange Format" um.

```{r}
d_long <-
  d_within %>% 
  pivot_longer(cols = c(y1, y2), names_to = "time", values_to = "y")
```
Hier ist ein Auszug aus der Tabelle:

```{r}
head(d_long)
```


Visualisieren wir uns die Daten, s. @fig-d2.

```{r}
#| label: fig-d2
#| fig-cap: Der Unterschied in der Behaltensleistung pro Versuchsperson; im Durchschnitt ist der Wert bei y2 h√∂her als bei y1
ggwithinstats(
  data = d_long,
  x = time,
  y = y,
  results.subtitle = FALSE  # verzichte auf zus√§tzliche Statistiken
)
```


### Inferenzanalyse

Wir berechnen das Modell (`m_within`),s. @tbl-d2-params:

```{r}
#| results: hide
m_within <- stan_glm(d ~ 1, data = d_within, refresh = 0, seed = 42)
parameters(m_within)
```

```{r}
#| echo: false
#| label: tbl-d2-params
#| tbl-cap: Modellparameter von m_within
parameters(m_within) %>% 
  print_md()
```


Hier ist eine Visualisierung des 95%-ETI des Unterschieds (`d`) zwischen den beiden Bedingungen (@fig-m-within-params).

```{r}
#| label: fig-m-within-params
#| fig-cap: "95%-CI f√ºr d (Achsenabschnitt mit Modell m_within)" 
parameters(m_within) %>% plot(show_intercept = TRUE)
```

:::{.callout-note}
Wenn Sie die `parameters` `plot`ten und nur einen Intercept haben, m√ºssen Sie mit `show_intercept=TRUE` einschalten, dass er gezeigt wird.
Sonst gibt es eine Fehlermeldung.$\square$
:::

Wie man sieht, ist die Null nicht im CI enthalten. Wir k√∂nnen daher res√ºmieren,
dass es einen Unterschied zwischen den Bedingungen (statisch vs. animiert) gibt hinsichtlich `y2` (Behaltensleistung). Die Behaltensleistung animierter Diagramme ist der von statischen Diagrammen √ºberlegen (laut diesem Modell).
Die exakte Nullhypothese ist zu verwerfen.
Nat√ºrlich k√∂nnte man jetzt noch ein Rope berechnen.


### Vertiefung


In [diesem Blog-Post](https://data-se.netlify.app/2022/06/04/vorher-nachher-messung-und-vergleich-zwischen-gruppen/) findet eine kleine Fallstudie zur Analyse von "Vorher-Nachher-Daten".


## 1 within-Variable, 1 between-Variable

### Design

Forschungsfrage:


>    Hat die Diagrammart einen Einfluss auf die Behaltensleistung? Anders gesagt: Unterscheiden sich die Diagrammarten in ihrem Einfluss auf die Behaltensleistung? Dabei kontrollieren wir die Reihenfolge.

Forschungspraktisch bedeutet das, dass es zwei Gruppen, `g1` und `g2` in diesem Experiment gibt.
Diese beiden Gruppen definieren eine between-Variable, `g`, die die Reihenfolge der Darbietung kontrolliert, s. @fig-within2-flow.
Die Diagrammart `D` ist auch eine UV, aber als Within-Variable konzipiert.


```{mermaid}
%%| label: fig-within2-flow
%%| fig-cap: "Ablaufdiagramm f√ºr die Studie mit der Modellgleichung mit einem Within- und einem Between-Faktor"
flowchart LR
  subgraph g2
    direction LR
    V.1 --> y1 --> V.2 --> y2
  end
  subgraph g1
    direction LR
    D2[V.2] --> y22[y2] --> D1[V.1] --> y11[y1] 
  end
```



Da es zwei UVs gibt, gibt es auch zwei Hypothesen:

1. H1: $\bar{d} < 0$, mit $d = y_1 - y_2$: Die mittlere Behaltensleistung ist in der Bedingung *animiert*  h√∂her als in der Bedingung *statisch*.
2. H2: $\bar{d}_{g.1} = \bar{d}_{g.2}$: Der Unterschied in der Behaltensleistung zwischen den zwei Bedingung unterscheidet sich nicht von der Reihenfolge der Darbietung.



Die Modellformel lautet: `y ~ 1 + g`.
Das kann man synonym so schreiben: `y ~ g`.
Dabei meint `y` meint die Behaltensleistung;
statistisch erfassen wir den *Effekt* auf `y` anhand des Differenzma√ües `d`.



Der DAG des Experiments ist in @fig-within2-dag dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-within2-dag
#| fig-cap: "DAG f√ºr die Studie mit der Modellgleichung mit einem Within- und einem Between-Faktor. Es wird kein Effekt f√ºr g erwartet (daher kein Pfeil von g auf y), wohl aber ein Effekt f√ºr V"
#| echo: false

mein_modell <- "dag{
V -> y
g 
u -> y
}"

plot(graphLayout(mein_modell))
```



### Deskriptive Analyse

Hier sind einige Spieldaten:

```{r}
#| message: false
d_within <- 
  read_csv("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv") %>% 
  select(-c(y3)) # die  Variable `y3` ignorieren wir f√ºr den Augenblick

head(d_within)
```



Wir berechnen `d`, der Unterschied zwischen den beiden Bedingungen:

```{r}
d_within <-
  d_within %>% 
  mutate(d = y1 - y2)

head(d_within)
```

Betrachten wir den Unterschied von `d` zwischen den Gruppen (H2), s. @fig-d-within2.

```{r}
#| label: fig-d-within2
#| fig-cap: Der Unterschied der Behaltensleistung (d) in Abh√§ngigkeit von der Reihenfolge der Darbietung
ggbetweenstats(
  d_within,
  x = g,
  y = d,
  results.subtitle = FALSE
)
```

Es gibt einen gewissen Unterschied zwischen den beiden Reihenfolgen (A und B) wie @fig-d-within2 zeigt;
die Reihenfolge k√∂nnte also einen Einfluss auf `d` haben.
Aber wir m√ºssen inferenzstatistisch pr√ºfen, wie gro√ü der Einfluss ist.



### Inferenzanalyse

Berechnen wir `m_within2`, das nicht nur den Intercept pr√ºft (wie `m_within1`), 
sondern auch zus√§tzlich den Effekt der Reihenfolge (`g`), vgl. @tbl-m_within2-params.

```{r m-within2}
m_within2 <- stan_glm(d ~ g, data = d_within, refresh = 0, seed = 42)
```

```{r}
#| echo: false
#| label: tbl-m_within2-params
#| tbl-cap: Modellparameter von m_within2
parameters(m_within2) %>% 
  print_md()
```


Das CI f√ºr die Reihenfolge (Variable `gB`) beinhaltet die Null;
Daher kann ein Nulleffekt der Reihenfolge - also kein Effekt der Reihenfolge - nicht ausgeschlossen werden, `g=0` ist also im Bereich der plausiblen Werte.

Der Effekt f√ºr `d` (`(Intercept)`) zeigt ein Intervall, das die Null (knapp) enth√§lt.
Daher k√∂nnen wir wir die Nullhypothese nicht mit hoher Sicherheit ausschlie√üen.

In Summe:

1. H1 (H√∂here Behaltensleistung von *animiert*) konnte nicht best√§tigt werden, aber tendenziell fand sich ein Effekt in erwarteter Richtung (zugunsten einer h√∂heren Behaltensleistung von *animiert*).
2. H2 (Reihenfolgeeffekt) konnte nicht best√§tigt werden.


## Vertiefung



### 1 within-Variable mit mehr als zwei Stufen

{{< fa dumbbell >}} VERTIEFUNG {{< fa dumbbell >}} - Sie k√∂nnen diesen Abschnitt ohne Gefahr ignorieren.


### Design

Eine Forscherin hat die Gesundheit (`y`) von Studentis drei Mal (t1, t2, t3) im Zeitraum eines Semesters untersucht.

Ihre Forschungsfrage lautet, ob sich die Gesundheit im Laufe des Semesters substanziell ver√§ndert.
Ihre Hypothese lautet, dass die Werte √ºber die Zeit hinweg stabil bleiben.

### Deskriptive Analyse

Hier sind einige Spieldaten:

```{r}
#| message: false
d_within <- 
  read_csv("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv")

head(d_within)
```

Hier ben√∂tigen wir die Daten in Langform:


```{r}
d_long <-
  d_within %>% 
  pivot_longer(cols = y1:y3, names_to = "time", values_to = "y")

head(d_long)
```


Es hilft (wie meistens), sich die Daten zu visualisieren, s. @fig-within-y3.

```{r}
#| label: fig-within-y3
#| fig-cap: "Messwerte (y) in Abh√§ngigkeit vom Messzeitpunkt (t1, t2, t3)"
#| fig-subcap: 
#|   - Einfaches Punktediagramm
#|   - Informationsreiches Punkte-, Boxplot- und Violinendiagramm mit Statistiken der Ver√§nderung angereichert
#| layout-ncol: 2
p_y123_a <-
  d_long %>% 
  ggplot(aes(x = time, y = y)) +
  geom_jitter(width = .2)

p_y123_b <-
  ggwithinstats(d_long, 
                x = time,
                y = y,
                results.subtitle = FALSE)

p_y123_a
p_y123_b
```


Berechnen wir die Mittelwerte von `y` pro Messzeitpunkte sowie die Ver√§nderung von t1 zu t2 bzw. von t2 zu t3, s. @tbl-d123.

```{r}
#| eval: false
d_long %>% 
  group_by(time) %>% 
  summarise(y_mean = mean(y)) %>% 
  mutate(d = y_mean - lag(y_mean))
```


```{r}
#| label: tbl-d123
#| tbl-cap: "Mittelwerte von `y` pro Messzeitpunkte (`y_mean`) sowie die Ver√§nderung von t1 zu t2 bzw. von t2 zu t3 (`d`)"
#| echo: false
d_long %>% 
  group_by(time) %>% 
  summarise(y_mean = mean(y)) %>% 
  mutate(d = y_mean - lag(y_mean)) %>% 
  print_md()
```



### Inferenzanalyse



```{r}
m_within3 <- stan_lmer(y ~ 1 + (1 | time), data = d_long, refresh = 0)
summary(m_within3)
```

Die Schreibweise `(1 | time)` soll sagen, dass die Messwerte innerhalb von `time` verschachtelt sind und variieren. 
Die `1` sagt, dass es sich bei der variierenden Gr√∂√üe um den Intercept handelt,
nicht um eine UV.

Ein "fixer" Effekt ist ein Effekt, f√ºr den kein Pooling stattfindet,
das ist hier der Intercept.

Nur die festen (*fixed*) Effekte kann man sich so ausgeben lassen:

```{r}
fixef(m_within3)
```


Im Durchschnitt werden ca. 7.1 Fragen richtig beantwortet (Gesamtmittel);
das ist die Information die der Punktsch√§tzer des Intercepts bietet.


Nur die Random-Effekte kann man sich so ausgeben lassen:

```{r}
ranef(m_within3)
```

Das sind jeweils die Abweichungen der Gruppenmittelwerte (y1, y2, y3) vom Gesamtmittel.
Die Random-Effekte kann man sich visualisieren lassen, s. @fig-randef-m3.

```{r}
#| label: fig-randef-m3
#| fig-cap: "95%-CI der Random-Effekte von `m_within3`"
plot(m_within3)
```



### Mediatoranalyse

[Hier](https://wgruber.github.io/Modellbildung2/mediation.html) findet sich eine Einf√ºhrung in die Mediationsanalyse.
[Dieses R-Paket](https://github.com/GerkeLab/mediator/tree/master) stellt ebenfalls komfortable Funktionen zur Verf√ºgung f√ºr Mediationsanalysen.




## Fazit

Unter Modellieren versteht man in der Forschungspraxis meist ein Regressionsmodell der Form `av ~ uv`.
Die Inferenzstatistik hilft, die Modellparameter mit Sch√§tzwerten f√ºr die Population zu versehen.


## Aufgaben


Schauen Sie sich im [Datenwerk](https://datenwerk.netlify.app/) die Aufgaben mit folgenden Tags an:

- [research-question](https://datenwerk.netlify.app/#category=research-question) - [researchdesign](https://datenwerk.netlify.app/#category=researchdesign)
<!-- - [within-design-analysis1](https://datenwerk.netlify.app/posts/within-design-analysis1/within-design-analysis1.html) -->
- [inference](https://datenwerk.netlify.app/#category=inference)
- [bayes](https://datenwerk.netlify.app/#category=bayes)
