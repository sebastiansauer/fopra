[
  {
    "objectID": "090-Modellieren.html#lernsteuerung",
    "href": "090-Modellieren.html#lernsteuerung",
    "title": "12  Auswerten: Modellieren",
    "section": "12.1 Lernsteuerung",
    "text": "12.1 Lernsteuerung\n\n12.1.1 Lernziele\n\nSie können die Modellformel Ihrer Forschungsfrage nennen.\nSie können Ihre Modellformel (korrekt) in R spezifizieren.\nSie können Ihr Modell in R berechnen und die Ausgabe interpretieren.\nSie können die Gültigkeit bzw. die Grenzen der Aussagen Ihres Modells einschätzen.\n\n\n\n12.1.2 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggstatsplot)  # Visualisierung\nlibrary(ggpubr)  # Visualisierung\nlibrary(rstanarm)  # Bayes\n\n\n\n12.1.3 Position im Lernpfad\nSie befinden sich im Abschnitt “Auswerten” in Abbildung 1.2. Behalten Sie Ihren Fortschritt im Projektplan im Blick, s. Abbildung 1.3.\n\n\n12.1.4 Grundlagen der statischen Modellierung\nDie Grundlagen der statistischen Modellierung mit einem Fokus auf Bayes-Modellen können Sie hier nachlesen.\n\n\n12.1.5 Überblick\nIn diesem Kapitel sind die grundlegenden Verfahren zur Modellierung und inferenzstatistischen Absicherung Ihrer Forschungsfragen angerissen. Die Darstellung zielt auf ein “so-geht’s” ab, nicht auf eine vollständige Darstellung aller Auswertungsmöglichkeiten.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#between-variable",
    "href": "090-Modellieren.html#between-variable",
    "title": "12  Auswerten: Modellieren",
    "section": "12.2 1 between-Variable",
    "text": "12.2 1 between-Variable\n\n12.2.1 Design\nSauer und Lustig (2023) untersuchten in einer Querschnittsstudie den Effekt des Wirkstoff Bringnixtin auf die fluide Intelligenz. Die Autoren nahmen an, dass der Wirkstoff den individuellen Wert der abhängigen Variable erhöhen würde.\nDer Ablauf (aus Sicht der Probandis) ist in Abbildung 12.1 dargestellt. Intro fasst die Begrüßung der Probandis inkl. Informed Consent sowie Erfassung von soziodemografischen Variablen zusammen. g.0 und g.1 sind die zwei Stufen der UV (g wie Gruppe), wobei g.0 die Kontrollgruppe kodiert (Placebo, also Zuckerpille, kein Wirkstoff,) und g.1 die zweite Stufe, d.h. die Experimentalgruppe (hohe Dosis Bringtnixtin). y2 ist die Messung der AV (d.h. nach Gabe von Bringtnixtin), d.h. ein Maß der fluiden Intelligenz. outro meint die Verabschiedung der Probanden sowie einige Fragen zu Compliance.\nDie Hypothese lautet: \\(\\mu_{g.2} &gt; \\mu_{g.1}\\).\nIn Worten:\n\nWir erwarten, dass der Mittelwert der Experimentalgruppe höher ist als der Mittelwert der Kontrollgruppe.\n\n\n\n\n\n\n\nflowchart LR\n  Intro --&gt; g.0\n  Intro --&gt; g.1\n  g.0 --&gt; y2\n  g.1 --&gt; y2\n  y2 --&gt; outro\n\n\n\n\nAbbildung 12.1: Ablaufdiagramm der Bringtnixtin-Studie\n\n\n\n\n\nDer DAG des Experiments ist in Abbildung 12.2 dargestellt.\n\n\n\n\n\n\n\n\nAbbildung 12.2: DAG für der Bringtnixtin-Studie\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nIm DAG Abbildung 12.2 ist u als Ursache von y2 angegeben. u steht hier stellvertretend für alle weiteren Ursachen von y2, vermutlich sind das sehr viele. Aber sie interessieren uns nicht. Daher können Sie u auch aus dem DAG weglassen. Streng genommen sollten Sie es sogar weglassen, denn im DAG zeigt man nur diejenigen Variablen, die für Ihre Hypothese von Belang sind. Da u keine Verbindung zum Pfad g -&gt; y2 hat, brauchen wir es für die Bestimmung des Kausaleffekts nicht zu berücksichtigen.\\(\\square\\)\n\n\nDie Daten dieses Experiments sind hier zu beziehen:\n\nd_bringtnixtin_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/fopra/main/data/d_bringtnixtin.csv\"\nd_bringtnixtin &lt;- read_csv(d_bringtnixtin_path)\n\n Download \nDie Autoren der Studie geben an, dass die Daten in z-Einheiten skaliert sind.\n\n\n12.2.2 Deskriptive Analyse\n\nd_bringtnixtin %&gt;% \n  group_by(g) %&gt;% \n  summarise(iq_mw = mean(y2),\n            iq_sd = sd(y2)) \n\n\n\n\n\nTabelle 12.1: Mittlere fluide Intelligenz nach der Bringtnixtin-Intervention in Abhängigkeit der Gruppe\n\n\n\n\n  \n\n\n\n\n\n\nDie deskriptiven Kennwerte sind in Abbildung 12.3 bzw. Abbildung 12.3 visualisiert. Das sieht nicht gerade nach einem großen Effekt aus …1\n\nMit ggstatsplot\n\n\n\nggbetweenstats(\n  data = d_bringtnixtin,\n  x = g,\n  y = y2,\n  results.subtitle = FALSE  # keine Statistiken zeigen\n)\n\n\n\n\n\n\n\nAbbildung 12.3: Fluide Intelligenz (y2) nach der Bringtnixtin-Intervention. g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)\n\n\n\n\n\n\n12.2.2.1 Mit ggpubr\n\nggboxplot(\n  data = d_bringtnixtin,\n  x = \"g\",\n  y = \"y2\"\n)\n\n\n\n\n\n\n\nAbbildung 12.4: Fluide Intelligenz (y2) nach der Bringtnixtin-Intervention. g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)\n\n\n\n\n\n\n\n\n\nSowohl das R-Paket ggstatsplot als auch das R-Paket ggpubr bieten ansprechende Datenvisualisierung.2\n\n\n12.2.3 Modellierung\nWir berechnen ein lineares Modell mit der Modellformel y2 ~ g. Die Ergebnisse sind in Tabelle 13.5 zu sehen.\n\nm_bringtnixtin &lt;- stan_glm(y2 ~ g, data = d_bringtnixtin, refresh = 0, seed = 42)\nparameters(m_bringtnixtin)\n\n\n\nTabelle 12.2: Parameter des Modells m_bringtnixtin\n\n\n\n\n  \n\n\n\n\n\n\nDer Gruppenunterschied wird auf das -0.77 geschätzt; das ist der Punktschätzer der UV g. Wenn wir nur eine Zahl nennen dürften zu unserem Wissen zum Effekt von g, so wäre das unsere Zahl. Die Grenzen eines 95%-CI für die UV liegen bei -1.56 bzw. 0.02; diese beiden Werten markieren die Grenzen des Intervallschätzers. Dieser Bereich enthält die Null, vgl. Abbildung 12.5. Daher kann nicht ausgeschlossen werden, dass Bringtnixtin nix bringt. Anders gesagt: Die Nullhypothese kann nicht verworfen werden.\nDie Punkt- und Intervallschätzer (95%-ETI) für Achsenabschnitt und Regressiongewicht von g sind in Abbildung 12.5 visualisiert.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Ein Punktschätzer schätzt einen (unbekannten) Wert in der Population auf einen einzelnen Wert (daher “Punkt”). Ein Interschätzer schätzt einen Wertebereich für diesen unbekannten Wert. \\(\\square\\)\n\n\n\nparameters(m_bringtnixtin) %&gt;% plot(show_intercept = TRUE)\n\n\n\n\n\n\n\nAbbildung 12.5: Parameter des Modells m_bringtnixtin (95%-ETI)\n\n\n\n\n\n\n👨‍🏫 Frau Professor Lustig, wie kann das sein, dass sich die Hypothese nicht bestätigt?\n\n\n👩‍🏫 Herr Professor Sauer, auch ein negatives Ergebnis bringt die Wissenschaft weiter.\n\nMit dem Rope-Verfahren kann man testen, ob ein Bereich um die Null herum, also “Null plus-minus ein bisschen” im Hauptbereich im Hauptbereich (95%-KI) enthalten ist.\nTesten wir eine Nullhypothese mit dem ROPE-Verfahren: rope(m_bringtnixtin), s. Tabelle 12.3 und Abbildung 12.6.\n\n\n\n\nTabelle 12.3: ROPE für Modell m_bringtnixtin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-0.13\n0.13\n0.29\nfixed\nconditional\n\n\ng\n0.95\n-0.13\n0.13\n0.03\nfixed\nconditional\n\n\n\n\n\n\n\n\n\nplot(rope(m_bringtnixtin)) + scale_fill_okabeito()\n\n\n\n\n\n\n\nAbbildung 12.6: ROPE für Modell m_bringtnixtin\n\n\n\n\n\nscale_fill_okabeito() ist eine Funktion aus dem Metapaket {easystats}.3 Das Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (s. Details hier).\nDa sich das 95%-CI mit dem ROPE überlappt, kann die Nullhypothese bzw. das ROPE (kein praktisch bedeutsamer Effekt) nicht ausgeschlossen werden.\nEine vergleichbare Information bietet uns die Kennzahl pd, s. Tabelle 13.5. Der Wert für g liegt bei ca. 0.97.\n\n\n\n\n\n\nHinweis\n\n\n\npd gibt die Wahrscheinlichkeit (laut Modell) an, dass der Effekt in der Population negativ bzw. positiv ist (d.h. gleich dem Vorzeichen des Punktschätzers; in diesem Fall negativ).\\(\\square\\)\n\n\n\n\nDas Modell ist sicher ziemlich sicher, dass der Effekt von g (in der Population) negativ ist. Aber eine kleine Chance, dass der Effekt von g doch (ungefähr) Null oder sogar positiv ist, bleibt.\n\n👨‍🏫 Frau Professor Lustig, oh je! Unser Wirkstoff Bringtnixtin bringt anscheinend gar nix!\n\n\n👩‍🏫 Herr Professor Sauer, wir müssen erst einmal in Ruhe die Studie replizieren. Eine Schwalbe macht noch keinen Frühling.\n\nBerechnen wir abschließend noch eine standardisierte Effektstärke, \\(R²\\).\n\nr2(m_bringtnixtin)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.089 (95% CI [4.766e-09, 0.251])\n\nAlso etwa 9% erklärte Varianz. Aber ist das viel oder wenig? Fragen wir Herr Cohen, der hat sich dazu mal Gedanken gemacht.\n\ninterpret_r2(.09)\n## [1] \"weak\"\n## (Rules: cohen1988)\n\nNach dieser Einschätzung ist der Effekt von g also schwach.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#vorher-nachher-messung-1-between-variable",
    "href": "090-Modellieren.html#vorher-nachher-messung-1-between-variable",
    "title": "12  Auswerten: Modellieren",
    "section": "12.3 Vorher-Nachher-Messung, 1 between-Variable",
    "text": "12.3 Vorher-Nachher-Messung, 1 between-Variable\n\n12.3.1 Design\nSauer und Lustig (2023) fiel auf, dass es sinnvoller ist, zuerst die AV mittels eines Vortests zu messen, dann die Intervention anzuwenden, und dann nachher (Posttest) die AV wieder zu messen. Daher haben sie sowohl vor der Intervention (t1) als auch nach der Intervention (Gabe von Bringtnixtin), t2, die AV (y, Behaltensleistung) gemessen.\n\n\n\n\n\n\nHinweis\n\n\n\nEine Vorher-Nachher-Messung hat den Verteil, dass sie - im Gegensatz zur Nur-Nachher-Messung - unterschiedliche Ausgangswerte in der AV herausrechnet. Bei großen Gruppen wird sich bei einer randomisierten Zuweisung zu den Gruppen der Ausgangswert der AV angleichen. Bei nicht so großen Gruppen kann aber auch bei Randomisierung ein - mitunter erheblicher - Unterschied zwischen den Gruppen verbleiben. Findet man bei der Post-Messung einen Effekt, so kann es sein, dass dieser nicht auf die Intervention beruht, sondern auf die von vornherein vorhandenen Unterschieden zwischen den Gruppen.\\(\\square\\)\n\n\n\nVergleicht man die Delta-Werte zwischen zwei Gruppen, berechnet man die Differenz zwischen den Gruppen der Delta-Werte. Man spricht daher von einer Difference-in-Difference-Analyse.\\(\\square\\)\n\nAbbildung 12.7 zeigt den Ablaufplan dieses Experiments.\n\n\n\n\n\n\nflowchart LR\n  Intro --&gt; y1\n  y1 --&gt; g.1\n  y1 --&gt; g.2\n  g.1 --&gt; y2\n  g.2 --&gt; y2\n  y2 --&gt; outro\n\n\n\n\nAbbildung 12.7: Ablaufdiagramm der Bringtnixtin-Studie\n\n\n\n\n\nDAG des Experiments ist in Abbildung 12.8 dargestellt.\n\n\n\n\n\n\n\n\nAbbildung 12.8: DAG für der Bringtnixtin-Studie\n\n\n\n\n\n\n\n12.3.2 Deskriptive Analyse\nEine einfache (und sinnvolle) Art, solche Studiendesigns auszuwerten ist die Bildung einer Differenz-Variable4. Diese Differenzvariable gibt die Veränderung der fluiden Intelligenz durch die Intervention an. Anders gesagt: Die Differenz ist die IQ-Wert einer Person nach der Intervention minus dem IQ-Wert vor der Intervention: \\(d = y_2 - y_1\\):\n\nd_bringtnixtin &lt;-\n  d_bringtnixtin %&gt;% \n  mutate(d = y2 - y1)\n\nSchauen wir uns die ersten paar d-Werte für jede der beiden Gruppen (g=0 bzw. g=1) an:\n\n\n\n\n\nid\ng\ny1\ny2\nd\n\n\n\n\n1\n0\n1.37\n1.41\n0.04\n\n\n2\n0\n-0.56\n-0.64\n-0.07\n\n\n3\n0\n0.36\n0.51\n0.15\n\n\n21\n1\n-0.31\n-0.71\n-0.41\n\n\n22\n1\n-1.78\n-2.08\n-0.30\n\n\n23\n1\n-0.17\n-0.39\n-0.22\n\n\n\n\n\n\nVielleicht ist es anschaulicher, wenn wir die Gruppe 0 in den Text Kontrollgruppe umbenennen und 1 in Experimentalgruppe:\n\nd_bringtnixtin &lt;-\n  d_bringtnixtin %&gt;% \n  mutate(g_text =\n           case_when(g == 0 ~ \"Kontrollgruppe\",\n                     g == 1 ~ \"Experimentalgruppe\"))\n\nHier sind die Mittelwerte für jede der beiden Gruppen:\n\nd_bringtnixtin %&gt;% \n  group_by(g_text) %&gt;%\n  summarise(d = mean(d))\n\n\n\n\nMittelwerte der Veränderung der Behaltensleistung nach Gruppe\n\n\ng_text\nd\n\n\n\n\nExperimentalgruppe\n-0.30\n\n\nKontrollgruppe\n-1.82e-04\n\n\n\n\n\nDie deskriptiven Kennwerte sind in Abbildung 12.9 dargestellt.\n\nggbetweenstats(\n  data = d_bringtnixtin,\n  x = g_text,\n  y = d,\n  results.subtitle = FALSE  # keine Statistiken zeigen\n)\n\n\n\n\n\n\n\nAbbildung 12.9: Veränderung der fluiden Intelligenz (d) in Abhängigkeit der Gruppe; g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)\n\n\n\n\n\n\n\n12.3.3 Modellierung\nWir modellieren (in m_bringtnixtin2) jetzt die Veränderung d = y2 - y1 als AV; UV ist wieder g, s. Tabelle 12.4.\n\nm_bringtnixtin2 &lt;- stan_glm(d ~ g, data = d_bringtnixtin, refresh = 0, seed = 42)\nparameters(m_bringtnixtin2)\n\n\n\n\n\nTabelle 12.4: Parameter von m_bringtnixtin2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-1.34e-03\n(-0.08, 0.08)\n51.42%\n1.000\n3934.00\nNormal (-0.15 +- 0.59)\n\n\ng\n-0.30\n(-0.41, -0.18)\n100%\n0.999\n4181.00\nNormal (0.00 +- 1.17)\n\n\n\n\n\n\n\n\nAbbildung 12.10 zeigt die Parameterwerte für m_bringtnixtin2,\n\nplot(parameters(m_bringtnixtin2))\n\n\n\n\n\n\n\nAbbildung 12.10: Parameterwerte von m_bringtnixtin2 (Intercept ist nicht dargestellt), 95%-ETI; die Null ist nicht enthalten, der Mittelwert ist negativ.\n\n\n\n\n\nWie man den Parameterwerten entnehmen kann, ist sich das Modell sehr sicher, dass der Effekt von Bringtnixtin negativ ist.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#beobachtungsstudien",
    "href": "090-Modellieren.html#beobachtungsstudien",
    "title": "12  Auswerten: Modellieren",
    "section": "12.4 Beobachtungsstudien",
    "text": "12.4 Beobachtungsstudien\nGängige Forschungsfragen für Beobachtungsstudien sind hier erläutert.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#within-variable",
    "href": "090-Modellieren.html#within-variable",
    "title": "12  Auswerten: Modellieren",
    "section": "12.5 1 within-Variable",
    "text": "12.5 1 within-Variable\nEine Studie mit Vorher-Nachher-Messung setzt ein Within-Design um.\n\nBeispiel 12.1 (Statisches Diagramm vs. animiertes Diagramm) Ein Forschungsteam untersuch den Effekt der UV Visualisierungsart V (mit den zwei Stufen V.1 animiert und V.2 statisch) auf die Behaltensleistung (y) von Probanden. Nach jeder Bedingung wird die Behaltensleistung gemessen (anhand von 10 Wissensfragen, die jeweils als “richtig” oder “falsch” bewertet wurden), mit y1 nach V.1 und y2 für V.2.\\(\\square\\)\n\n\n12.5.1 Design\nForschungsfrage:\n\nHat die Diagrammart einen Einfluss auf die Behaltensleistung? Anders gesagt: Unterscheiden sich die Diagrammarten in ihrem Einfluss auf die mittlere Behaltensleistung?\n\nDie zugehörige statistische Hypothese kann man so formulieren: \\(\\bar{d} \\ne 0\\), wobei \\(d = y_1 - y_2\\). \\(d\\) misst also den Unterschied der Behaltensleistung von animierten und statischen Diagrammen, wobei positive Werte zugunsten von statischen Diagrammen sprechen.\nDie Modellformel lautet: d ~ 1, das ist ein Intercept-Modell, also ein Modell ohne Prädiktor. Uns interessiert, ob die Variable d im Mittelwert ungleich Null ist oder positiv (zugunsten statischer Diagramme) oder negativ (Behaltensleistung höher bei animierten Diagrammen).\nDer Ablauf der Studie (aus Sicht der Probandis) ist in Abbildung 12.11 dargestellt.\n\n\n\n\n\n\nflowchart LR\n  V.1 --&gt; y1 --&gt; V.2 --&gt; y2\n\n\n\n\nAbbildung 12.11: Ablauf der Studie zur Behaltensleistung y2 in Abhängigkeit der Visualisierungsart V (Within-Variable)\n\n\n\n\n\nDer DAG des Experiments ist in Abbildung 12.12 dargestellt.\n\n\n\n\n\n\n\n\nAbbildung 12.12: DAG für die Studie zur Behaltensleistung y2 in Abhängigkeit des Visualiserungstyp V\n\n\n\n\n\n\n\n12.5.2 Deskriptive Analyse\nHier sind einige Spieldaten:\n\nd_within &lt;- \n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv\") %&gt;% \n  select(-c(y3, g)) # diese beiden Variablen ignorieren wir für den Augenblick\n\nhead(d_within)\n\n\n  \n\n\n\n Download \nWir berechnen d, was die zentrale Variable der Forschungsfrage ist.\n\nd_within &lt;-\n  d_within %&gt;% \n  mutate(d = y1 - y2)\n\nhead(d_within)\n\n\n  \n\n\n\nEs klingt trivial, aber man muss sich ein Bild von den Daten (hier d) machen, wortwörtlich, s. Abbildung 12.13.\n\ngghistostats(d_within,\n             x = d,\n             results.subtitle = FALSE  # verzichte auf zusätzliche Statistiken\n             )\n\n\n\n\n\n\n\nAbbildung 12.13: Die Verteilung von d: Die Behaltensleistung ist im Mittel besser für animierte Diagramme (in diesen Daten)\n\n\n\n\n\nDa d im Mittel negativ ist, ist der Mittelwert von y2 (animiert) höher als der von y1 (statisch).\nLassen wir uns die deskriptiven Kennwerte ausgeben, s. Tabelle 12.5.\n\nd_within %&gt;% \n  describe_distribution(d)\n\n\n\n\n\nTabelle 12.5: Statistiken für d\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nd\n-1.60\n2.63\n4\n(-9.00, 3.00)\n-0.55\n0.30\n40\n0\n\n\n\n\n\n\n\n\nUm die Daten noch anders visualisieren zu können, formen wir sie ins “lange Format” um.\n\nd_long &lt;-\n  d_within %&gt;% \n  pivot_longer(cols = c(y1, y2), names_to = \"time\", values_to = \"y\")\n\nHier ist ein Auszug aus der Tabelle:\n\nhead(d_long)\n\n\n  \n\n\n\nVisualisieren wir uns die Daten, s. Abbildung 12.14.\n\nggwithinstats(\n  data = d_long,\n  x = time,\n  y = y,\n  results.subtitle = FALSE  # verzichte auf zusätzliche Statistiken\n)\n\n\n\n\n\n\n\nAbbildung 12.14: Der Unterschied in der Behaltensleistung pro Versuchsperson; im Durchschnitt ist der Wert bei y2 höher als bei y1\n\n\n\n\n\n\n\n12.5.3 Inferenzanalyse\nWir berechnen das Modell (m_within),s. Tabelle 12.6:\n\nm_within &lt;- stan_glm(d ~ 1, data = d_within, refresh = 0, seed = 42)\nparameters(m_within)\n\n\n\n\n\nTabelle 12.6: Modellparameter von m_within\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-1.59\n(-2.46, -0.69)\n100%\n1.000\n2536.00\nNormal (-1.60 +- 6.57)\n\n\n\n\n\n\n\n\nHier ist eine Visualisierung des 95%-ETI des Unterschieds (d) zwischen den beiden Bedingungen (Abbildung 12.15).\n\nparameters(m_within) %&gt;% plot(show_intercept = TRUE)\n\n\n\n\n\n\n\nAbbildung 12.15: 95%-CI für d (Achsenabschnitt mit Modell m_within)\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWenn Sie die parameters plotten und nur einen Intercept haben, müssen Sie mit show_intercept=TRUE einschalten, dass er gezeigt wird. Sonst gibt es eine Fehlermeldung.\\(\\square\\)\n\n\nWie man sieht, ist die Null nicht im CI enthalten. Wir können daher resümieren, dass es einen Unterschied zwischen den Bedingungen (statisch vs. animiert) gibt hinsichtlich y2 (Behaltensleistung). Die Behaltensleistung animierter Diagramme ist der von statischen Diagrammen überlegen (laut diesem Modell). Die exakte Nullhypothese ist zu verwerfen. Natürlich könnte man jetzt noch ein Rope berechnen.\n\n\n12.5.4 Vertiefung\nIn diesem Blog-Post findet eine kleine Fallstudie zur Analyse von “Vorher-Nachher-Daten”.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#within-variable-1-between-variable",
    "href": "090-Modellieren.html#within-variable-1-between-variable",
    "title": "12  Auswerten: Modellieren",
    "section": "12.6 1 within-Variable, 1 between-Variable",
    "text": "12.6 1 within-Variable, 1 between-Variable\n\n12.6.1 Design\nForschungsfrage:\n\nHat die Diagrammart einen Einfluss auf die Behaltensleistung? Anders gesagt: Unterscheiden sich die Diagrammarten in ihrem Einfluss auf die Behaltensleistung? Dabei kontrollieren wir die Reihenfolge.\n\nForschungspraktisch bedeutet das, dass es zwei Gruppen, g1 und g2 in diesem Experiment gibt. Diese beiden Gruppen definieren eine between-Variable, g, die die Reihenfolge der Darbietung kontrolliert, s. Abbildung 12.16. Die Diagrammart D ist auch eine UV, aber als Within-Variable konzipiert.\n\n\n\n\n\n\nflowchart LR\n  subgraph g2\n    direction LR\n    V.1 --&gt; y1 --&gt; V.2 --&gt; y2\n  end\n  subgraph g1\n    direction LR\n    D2[V.2] --&gt; y22[y2] --&gt; D1[V.1] --&gt; y11[y1] \n  end\n\n\n\n\nAbbildung 12.16: Ablaufdiagramm für die Studie mit der Modellgleichung mit einem Within- und einem Between-Faktor\n\n\n\n\n\nDa es zwei UVs gibt, gibt es auch zwei Hypothesen:\n\nH1: \\(\\bar{d} &lt; 0\\), mit \\(d = y_1 - y_2\\): Die mittlere Behaltensleistung ist in der Bedingung animiert höher als in der Bedingung statisch.\nH2: \\(\\bar{d}_{g.1} = \\bar{d}_{g.2}\\): Der Unterschied in der Behaltensleistung zwischen den zwei Bedingung unterscheidet sich nicht von der Reihenfolge der Darbietung.\n\nDie Modellformel lautet: y ~ 1 + g. Das kann man synonym so schreiben: y ~ g. y meint die Behaltensleistung; statisch erfassen wir den Effekt auf y anhand des Differenzmaßes d.\nDer DAG des Experiments ist in Abbildung 12.17 dargestellt.\n\n\n\n\n\n\n\n\nAbbildung 12.17: DAG für die Studie mit der Modellgleichung mit einem Within- und einem Between-Faktor. Es wird kein Effekt für g erwartet (daher kein Pfeil von g auf y), wohl aber ein Effekt für V\n\n\n\n\n\n\n\n12.6.2 Deskriptive Analyse\nHier sind einige Spieldaten:\n\nd_within &lt;- \n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv\") %&gt;% \n  select(-c(y3)) # die  Variable `y3` ignorieren wir für den Augenblick\n\nhead(d_within)\n\n\n  \n\n\n\nWir berechnen d, der Unterschied zwischen den beiden Bedingungen:\n\nd_within &lt;-\n  d_within %&gt;% \n  mutate(d = y1 - y2)\n\nhead(d_within)\n\n\n  \n\n\n\nBetrachten wir den Unterschied von d zwischen den Gruppen (H2), s. Abbildung 12.18.\n\nggbetweenstats(\n  d_within,\n  x = g,\n  y = d,\n  results.subtitle = FALSE\n)\n\n\n\n\n\n\n\nAbbildung 12.18: Der Unterschied der Behaltensleistung (d) in Abhängigkeit von der Reihenfolge der Darbietung\n\n\n\n\n\nEs gibt einen gewissen Unterschied zwischen den beiden Reihenfolgen (A und B) wie Abbildung 12.18 zeigt; die Reihenfolge könnte also einen Einfluss auf d haben. Aber wir müssen inferenzstatistisch prüfen, wie groß der Einfluss ist.\n\n\n12.6.3 Inferenzanalyse\nBerechnen wir m_within2, das nicht nur den Intercept prüft (wie m_within1), sondern auch zusätzlich den Effekt der Reihenfolge (g), vgl. Tabelle 12.7.\n\nm_within2 &lt;- stan_glm(d ~ g, data = d_within, refresh = 0, seed = 42)\n\n\n\n\n\nTabelle 12.7: Modellparameter von m_within2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-1.15\n(-2.33, -8.72e-03)\n97.60%\n0.999\n3902.00\nNormal (-1.60 +- 6.57)\n\n\ngB\n-0.89\n(-2.61, 0.73)\n86.28%\n1.000\n3684.00\nNormal (0.00 +- 12.98)\n\n\n\n\n\n\n\n\nDas CI für die Reihenfolge (Variable gB) beinhaltet die Null; Daher kann ein Nulleffekt der Reihenfolge - also kein Effekt der Reihenfolge - nicht ausgeschlossen werden, g=0 ist also im Bereich der plausiblen Werte.\nDer Effekt für d ((Intercept)) zeigt ein Intervall, das die Null (knapp) enthält. Daher können wir wir die Nullhypothese nicht mit hoher Sicherheit ausschließen.\nIn Summe:\n\nH1 (Höhere Behaltensleistung von animiert) konnte nicht bestätigt werden, aber tendenziell fand sich ein Effekt in erwarteter Richtung (zugunsten einer höheren Behaltensleistung von animiert).\nH2 (Reihenfolgeeffekt) konnte nicht bestätigt werden.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#vertiefung-1",
    "href": "090-Modellieren.html#vertiefung-1",
    "title": "12  Auswerten: Modellieren",
    "section": "12.7 Vertiefung",
    "text": "12.7 Vertiefung\n\n12.7.1 1 within-Variable mit mehr als zwei Stufen\n VERTIEFUNG  - Sie können diesen Abschnitt ohne Gefahr ignorieren.\n\n\n12.7.2 Design\nEine Forscherin hat die Gesundheit (y) von Studentis drei Mal (t1, t2, t3) im Zeitraum eines Semesters untersucht.\nIhre Forschungsfrage lautet, ob sich die Gesundheit im Laufe des Semesters substanziell verändert. Ihre Hypothese lautet, dass die Werte über die Zeit hinweg stabil bleiben.\n\n\n12.7.3 Deskriptive Analyse\nHier sind einige Spieldaten:\n\nd_within &lt;- \n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv\")\n\nhead(d_within)\n\n\n  \n\n\n\nHier benötigen wir die Daten in Langform:\n\nd_long &lt;-\n  d_within %&gt;% \n  pivot_longer(cols = y1:y3, names_to = \"time\", values_to = \"y\")\n\nhead(d_long)\n\n\n  \n\n\n\nEs hilft (wie meistens), sich die Daten zu visualisieren, s. Abbildung 12.19.\np_y123_a &lt;-\n  d_long %&gt;% \n  ggplot(aes(x = time, y = y)) +\n  geom_jitter(width = .2)\n\np_y123_b &lt;-\n  ggwithinstats(d_long, \n                x = time,\n                y = y,\n                results.subtitle = FALSE)\n\np_y123_a\np_y123_b\n\n\n\n\n\n\n\n\n\n\n\n(a) Einfaches Punktediagramm\n\n\n\n\n\n\n\n\n\n\n\n(b) Informationsreiches Punkte-, Boxplot- und Violinendiagramm mit Statistiken der Veränderung angereichert\n\n\n\n\n\n\n\nAbbildung 12.19: Messwerte (y) in Abhängigkeit vom Messzeitpunkt (t1, t2, t3)\n\n\n\nBerechnen wir die Mittelwerte von y pro Messzeitpunkte sowie die Veränderung von t1 zu t2 bzw. von t2 zu t3, s. Tabelle 12.8.\n\nd_long %&gt;% \n  group_by(time) %&gt;% \n  summarise(y_mean = mean(y)) %&gt;% \n  mutate(d = y_mean - lag(y_mean))\n\n\n\n\n\nTabelle 12.8: Mittelwerte von y pro Messzeitpunkte (y_mean) sowie die Veränderung von t1 zu t2 bzw. von t2 zu t3 (d)\n\n\n\n\n\n\ntime\ny_mean\nd\n\n\n\n\ny1\n5.45\n\n\n\ny2\n7.05\n1.60\n\n\ny3\n8.97\n1.92\n\n\n\n\n\n\n\n\n\n\n12.7.4 Inferenzanalyse\n\nm_within3 &lt;- stan_lmer(y ~ 1 + (1 | time), data = d_long, refresh = 0)\nsummary(m_within3)\n## \n## Model Info:\n##  function:     stan_lmer\n##  family:       gaussian [identity]\n##  formula:      y ~ 1 + (1 | time)\n##  algorithm:    sampling\n##  sample:       4000 (posterior sample size)\n##  priors:       see help('prior_summary')\n##  observations: 120\n##  groups:       time (3)\n## \n## Estimates:\n##                                       mean   sd   10%   50%   90%\n## (Intercept)                          7.2    1.2  5.8   7.2   8.5 \n## b[(Intercept) time:y1]              -1.7    1.2 -3.0  -1.7  -0.3 \n## b[(Intercept) time:y2]              -0.1    1.2 -1.5  -0.1   1.3 \n## b[(Intercept) time:y3]               1.8    1.2  0.4   1.8   3.2 \n## sigma                                1.5    0.1  1.3   1.4   1.6 \n## Sigma[time:(Intercept),(Intercept)]  4.7    5.1  1.1   3.1  10.2 \n## \n## Fit Diagnostics:\n##            mean   sd   10%   50%   90%\n## mean_PPD 7.2    0.2  6.9   7.2   7.4  \n## \n## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n## \n## MCMC diagnostics\n##                                     mcse Rhat n_eff\n## (Intercept)                         0.0  1.0  1181 \n## b[(Intercept) time:y1]              0.0  1.0  1201 \n## b[(Intercept) time:y2]              0.0  1.0  1225 \n## b[(Intercept) time:y3]              0.0  1.0  1179 \n## sigma                               0.0  1.0  2953 \n## Sigma[time:(Intercept),(Intercept)] 0.1  1.0  1501 \n## mean_PPD                            0.0  1.0  3725 \n## log-posterior                       0.1  1.0  1078 \n## \n## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nDie Schreibweise (1 | time) soll sagen, dass die Messwerte innerhalb von time verschachtelt sind und variieren. Die 1 sagt, dass es sich bei der variierenden Größe um den Intercept handelt, nicht um eine UV.\nEin “fixer” Effekt ist ein Effekt, für den kein Pooling stattfindet, das ist hier der Intercept.\nNur die festen (fixed) Effekte kann man sich so ausgeben lassen:\n\nfixef(m_within3)\n## (Intercept) \n##    7.166984\n\nIm Durchschnitt werden ca. 7.1 Fragen richtig beantwortet (Gesamtmittel); das ist die Information die der Punktschätzer des Intercepts bietet.\nNur die Random-Effekte kann man sich so ausgeben lassen:\n\nranef(m_within3)\n## $time\n##    (Intercept)\n## y1   -1.672117\n## y2   -0.123990\n## y3    1.760269\n## \n## with conditional variances for \"time\"\n\nDas sind jeweils die Abweichungen der Gruppenmittelwerte (y1, y2, y3) vom Gesamtmittel. Die Random-Effekte kann man sich visualisieren lassen, s. Abbildung 12.20.\n\nplot(m_within3)\n\n\n\n\n\n\n\nAbbildung 12.20: 95%-CI der Random-Effekte von m_within3\n\n\n\n\n\n\n\n12.7.5 Mediatoranalyse\nHier findet sich eine Einführung in die Mediationsanalyse. Dieses R-Paket stellt ebenfalls komfortable Funktionen zur Verfügung für Mediationsanalysen.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#fazit",
    "href": "090-Modellieren.html#fazit",
    "title": "12  Auswerten: Modellieren",
    "section": "12.8 Fazit",
    "text": "12.8 Fazit\nUnter Modellieren versteht man in der Forschungspraxis meist ein Regressionsmodell der Form av ~ uv. Die Inferenzstatistik hilft, die Modellparameter mit Schätzwerten für die Population zu versehen.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#aufgaben",
    "href": "090-Modellieren.html#aufgaben",
    "title": "12  Auswerten: Modellieren",
    "section": "12.9 Aufgaben",
    "text": "12.9 Aufgaben\nSchauen Sie sich im Datenwerk die Aufgaben mit folgenden Tags an:\n\nresearch-question - researchdesign \ninference\nbayes\n\n\n\n\n\nSauer, Sebastian, und Ludwilla Lustig. 2023. „The Effect of Bringtnixtin on Fluid Intelligence: A Randomized, Controlled Trial“. Journal for Fake Data 42 (1): 271–314.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#lernsteuerung",
    "href": "100-Statistiken-berichten.html#lernsteuerung",
    "title": "13  Auswerten: Berichten von Statistiken",
    "section": "13.1 Lernsteuerung",
    "text": "13.1 Lernsteuerung\n\n13.1.1 Lernziele\n\nSie können Ihre Forschungfrage mit Methoden der Inferenzstatistik nach Bayes auswerten.\n\n\n\n13.1.2 Position im Lernpfad\nSie befinden sich im Abschnitt “Auswertung” in Abbildung 1.2. Behalten Sie Ihren Fortschritt im Projektplan im Blick, s. Abbildung 1.3.\n\n\n13.1.3 tl;dr\nIn diesem Kapitel wird folgende Frage beantwortet: “Wie man die Ergebnisse einer Bayes-Analyse berichtet”\n\n\n13.1.4 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\nlibrary(gt)  # optional\nlibrary(gtsummary)  # optional",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#warum-das-berichten-ihrer-analyse-wichtig-ist",
    "href": "100-Statistiken-berichten.html#warum-das-berichten-ihrer-analyse-wichtig-ist",
    "title": "13  Auswerten: Berichten von Statistiken",
    "section": "13.2 Warum das Berichten (Ihrer Analyse) wichtig ist",
    "text": "13.2 Warum das Berichten (Ihrer Analyse) wichtig ist\nStatistische Analysen können komplex und schwierig zu verstehen sein.1 Die Versuchung ist daher immer gegeben, beim Berichten einer Analyse wichtige Aspekte unerwähnt oder unerklärt zu lassen. Lässt man aber wichtige Informationen aus, steigt die Gefahr, dass die Analyse nicht nachvollziehbar ist. Am schönsten ist dieses Problem im Cartoon mit den zwei Wissenschaftlern von einer Tafel (von Sidney Harris) dargestellt.\n\n\n\n\n\n\nWichtig\n\n\n\nStellen Sie sicher, dass Ihre Analyse nachvollziehbar ist. Andere Personen sollten Ihre Analyse auch ausführen können. Daher ist es wichtig, dass Sie Ihre Analyse zu Ihrer Studie einreichen (außerdem auch die Daten und Ihr Data-Dictionary).\\(\\square\\)",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#prinzipien-der-berichtlegung-von-bayes-statistik",
    "href": "100-Statistiken-berichten.html#prinzipien-der-berichtlegung-von-bayes-statistik",
    "title": "13  Auswerten: Berichten von Statistiken",
    "section": "13.3 Prinzipien der Berichtlegung (von Bayes-Statistik)",
    "text": "13.3 Prinzipien der Berichtlegung (von Bayes-Statistik)\nIm Folgenden sind einige Grundlagen des Berichtens von Statistiken dargestellt. Zwar wird in einigen Teilen auf die Bayes-Methode abgestellt, aber viele Teile gelten für alle statistischen Analysen. Dabei sei hinzugefügt, dass Statistik, so nüchtern sie den geneigten Studenis auch erscheinen mag, durchaus Eitel- und Partikularitäten aufweist: Nicht jeder Autor oder Dozent oder jede Richtlinie gibt die gleichen Anweisungen oder Empfehlungen! Die folgenden Hinweise entsprechen der (aktuellen, sich durchaus im Lauf der Zeit ändernden) Sicht dieses Dozenten.\nDas erste Prinzip des Berichtlegens lautet “so viel wie nötig, aber so wenig wie möglich”. Man will die Lesis nicht überfrachten, aber alle nötigen Informationen übermitteln. Das zweite Prinzip lautet, dass man die Informationen am rechten Ort vermittelt. So wird ei Lesi die Erklärung der Zusammensetzung der Stichprobe nicht im Diskussionsteil vermuten und sich zu Recht wundern, im Methodenteil nichts zur Stichprobe zu finden. Das dritte Prinzip lautet, dass man priorisiert. Wichtiges in den Hauptteil, Details in den Anhang (bzw. in ergänzende Datein, “supplementary files”). Detaillreiche Statistiken berichtet man eher in Tabellen; geht es um einen Überblick, bietet sich häufig ein Diagramm an. Berichtet man im Text, so schreibt man auf “gut Deutsch” die Aussage in den Satz, und die Zahlen eher in Klammern dahinter. Das vierte Prinzip lautet, konsistent zu sein. Es gibt viele Wege nach Rom, bzw. viele Ansätze, nützlich und effektiv - mithin “richtig” - zu berichten. Wichtiger als die Wahl einer bestimmten Art und Weise, ist es, konsistent zu sein, ähnlich wie beim Zitieren. Das fünfte Prinzip, könnte man sagen, ist so selbstverständlich, dass es keiner Erwähnung bedarfe, aber die Realität lehrt uns leider mitunter das Gegenteil. Es lautet Lauterkeit oder Rechtschaffenheit. Kennzahlen bewusst falsch zu berichten rangiert irgendwo zwischen Straftat und beruflichem Fehlverhalten, je nach Kontext und kann harte Bestrafung verdienen. Gängiger sicherlich sind subtilere Arten, dieses Prinzip zu verletzen. Dazu ist als erstes das selektive Berichten zu nennen: Unliebsame Befunde werden verschwiegen, hypothesenkonforme hingegen nach vorne gestellt. Das ist zwar dann nicht gelogen aber die Irreführung wird bewusst in Kauf genommen.\nDie gute Nachricht für alle Studentis: Es gibt für Sie keinen Anreiz, die Ergebnisse “aufzuhübschen” (im Gegensatz zu Berufswissenschaftlis). Ihre Note wird nicht daran gemessen, ob Sie einen neuen Expoplaneten entdecken, oder sonstige “starke” Ergebnisse aufweisen können. Nein! Unklare, nicht-bestätigende oder unerwartete Ergebnisse sind genauso gut - auch wissenschaftlich übrigens haben sie die gleiche Daseinsberechtigung, wie die Ergebnisse, die im “Journal of Flashy Results” für Presseberichte sorgen. Für ihre Note ist es unerheblich, wie “signifikant”, “effektstark”, “präzise” oder “hypothesenkonform” ihre Ergebnisse sind.\nEs ist hilfreich, im Sinne des vierten Prinzips (Konsistenz) sich nach einer bekannten, vielleicht sogar verbreiteten Nomenklatur bzw. Vorgehensweise zu richten. Für Bayes-Analysen gibt es dazu Richtlinien und Checklisten; die folgenden Hinweise orientieren sich an Kruschke (2021), genannt BARG (Bayesian Analysis Reporting Guidelines); der Volltext ist hier zugänglich. Auch die APA (American Psychological Assocation) hat eine Checkliste herausgegeben, wie Bayes-Statistik berichtet werden sollte.\nDie wichtigsten Ergebnisse der BARG sind in dieser Tabelle ausgelegt. Im folgenden wird eine Auswahl der BARG vorgestellt. Das Ziel ist nicht eine umfassende Darstellung mit einer hohen Tiefe der Exposition. Vielmehr soll - angepasst an den Kenntnissstand von Bachelor-Studentis - ein angemessener Überblick ausgewählt werden. Ambitionierte Studentis sind aufgefordert, breite und tiefer als in der folgenden Ausführtung erläutert, zu berichten. Die folgende Ausführung orientiert sich an der Standardgliederung wissenschaftlicher Berichte.\nLesis seien verwiesen auf das Buch von Jhangiani, Chiang, und Cuttler (2019), die einen hervorragenden Überblick über die Materie vermitteln.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#allgemeine-richtlinien-zum-berichten-von-statistik",
    "href": "100-Statistiken-berichten.html#allgemeine-richtlinien-zum-berichten-von-statistik",
    "title": "13  Auswerten: Berichten von Statistiken",
    "section": "13.4 Allgemeine Richtlinien zum Berichten von Statistik",
    "text": "13.4 Allgemeine Richtlinien zum Berichten von Statistik\nDie APA hat eine Checkliste bzw. Richtlinie herausgegeben zum Berichten von Statistik (vgl. Cooper 2020). Die lesenswerten Schwesterbüch von Jan Hendrik Peters und Dörfler (2019) bzw. Jan H. Peters und Dörfler (2015) geben nicht nur Formulierungshilfen, sondern erläutern, wie man eine sinnvolle Gliederung erstellt und welche Inhalte in welchem Abschnitt gehören.\nGrundlegende Prinzipien des Berichtens von Statistiken sind:\n\nBegründet: Eine Erläuterung, warum ein Vorgehen gewählt wurde, wird gegeben.\nNachvollziehbar: Lesis können anhand des Berichts (potenziell) nachvollziehen, wie die Autoren zu einem Ergebnis gelangt sind.\nVon einfach zu komplex: Es ist verbreitet, zunächst grundlegende Ergebnisse, dann komplexere Modellanalysen zu präsentieren.\nDeskriptiv: Ergebnisse werden berichtet, aber nicht bewertet (das kommt erst im Diskussionsteil).\nLauter: Alle relevanten Ergebnisse werden offengelegt.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#theorieteil",
    "href": "100-Statistiken-berichten.html#theorieteil",
    "title": "13  Auswerten: Berichten von Statistiken",
    "section": "13.5 Theorieteil",
    "text": "13.5 Theorieteil\n\n13.5.1 Testen oder Schätzen?\nAm Ende des Theorieteils bietet es sich an, die Hypothesen oder die Forschungsfrage zu spezifizieren. Sie können sich für eines von beiden entscheiden oder auch beides angehen.\nIn der bisherigen Literatur (in der Psychologie) werden zumeist Hypothesen getestet, nach dem Motto “jo, unsere Vermutung scheint zu stimmen!” oder “nein, das Zeugs taugt nix!”. Das Problem ist, dass solches Denken etwas simpel ist, Schwarz-Weiß eben. Außerdem sind Nullhypothesen streng genommen immer falsch, weswegen es eigentlich keinen Sinn macht, sie zu untersuchen. Aber dafür ist das Schwarz-Weiß-Denken schön einfach.\nParameterschätzung fragt nicht ob, sondern wieviel. Nicht viel komplizierter, aber viel nuancierter; (eigentlich) besser. Außerdem enthält das Parameterschätzen auch das Hypothesentesten: Ist die Null im Schätz-Intervall nicht enthalten, so kann man die Null-Hypothese ausschließen.\n\n\n13.5.2 Modell definieren\nEs bietet sich auch an, ein Modell mit einem Pfaddiagramm bzw. DAG zu visualisieren, z. B. so, s. Abbildung 13.1.\n\nlibrary(dagitty)\n\nmein_dag &lt;- 'dag {\nA [pos=\"-2.200,-1.520\"]\nB [pos=\"1.400,-1.460\"]\nD [outcome,pos=\"1.400,1.621\"]\nE [exposure,pos=\"-2.200,1.597\"]\nZ [pos=\"-0.300,-0.082\"]\nA -&gt; E\nA -&gt; Z [pos=\"-0.791,-1.045\"]\nB -&gt; D\nB -&gt; Z [pos=\"0.680,-0.496\"]\nE -&gt; D\n}'\n\n\nmein_modell &lt;- \"dag{\nlern -&gt; erfolg\nmot -&gt; erfolg\nmot -&gt; lern\n}\"\n\nplot(graphLayout(mein_modell))\n\n\n\n\n\n\n\nAbbildung 13.1: Beispielhafter DAG\n\n\n\n\n\nDabei steht lern für “Lernzeit in Stunden”, mot für “Motivation” und lern für “Lernerfolg”. Die Operationalisierung der Variablen sollten im Methodenteil genauer beschrieben sein.\nÜbrigens: R-Quellcode sollte nicht im Hauptteil eines wissenschaftlichen Berichts stehen, verbannen Sie ihn in den Anhang (es sei denn, der Quellcode bzw. die Entwicklung von Syntax ist Gegenstand der Arbeit).\nAußerdem macht es Sinn, das Modell formal zu spezifizieren, etwa so:\n\\[\n\\begin{aligned}\n\\text{erfolg} &\\sim N(\\mu_i, \\sigma) \\qquad \\text{Likelihood} \\\\\n\\mu_i &= \\beta_0 + \\beta_1 \\text{lern} + \\beta_2 \\text{mot} \\qquad \\text{lineares Modell} \\\\\n\\beta_0 &\\sim N(0, 2.5)  \\qquad \\text{Prior Achsenabschnitt} \\\\\n\\beta_1 &\\sim N(0, 2.5)  \\qquad \\text{Prior Regressiongewicht lern} \\\\\n\\beta_2 &\\sim N(0, 2.5)  \\qquad \\text{Prior Regressiongewicht mot} \\\\\n\\sigma &\\sim Exp(1) \\qquad \\text{Prior Streuung} \\\\\n\\end{aligned}\n\\]\nWenn Sie das Modell mit STAN berechnen, also vermittelt über z. B. rstanarm, dann wählt stan_glm() für Sie folgende Priori-Werte:\n\n\\(\\beta\\)s: Normalverteilt mit Mittelwert 0 und SD 2.5\n\\(\\sigma\\): Exponentialverteilt mit Streckung 1\n\nDie \\(\\beta\\)s sind am einfachsten als z-Werte zu verstehen: Grob übersetzt sagt rstanarm “Mei, ich geh davon aus, dass der Effekt vermutlich 2.5-SD-Einheiten um den Mittelwert rum liegt, könnten auch etwas mehr sein, aber mehr als 5-SD-Einheiten sind schon echt unwahrscheinlich”. Das nennt man einen “schwach informativen Prior”: der erlaubt viel, aber den größten Quatsch schließt er aus.\nPraktischerweise müssten sie nicht mal ihre Variablen z-tranformieren (aber Sie können ohne Schaden!), denn rstanarm macht das für Sie.\nTipp: Geben Sie an, dass Sie die Standardwerte (Voreinstellung) der von Ihnen verwendeten Software (wie rstanarm) verwendet haben. Zitieren Sie möglichst die Software (in der verwendeten Version) und reichen Sie die Syntax ein.\nMehr zu Prioris bei rstanarm findet sich hier.\nMit prior_summary(mein_model) bekommt man einen Überblick über die Prioriwerte, die im Modell mein_modell verwendet wurden.\nEs macht Sinn, zu begründen, warum sie das Modell so gewählt haben, wie sie es gewählt haben. Wenn Sie eine Normalverteilung für die Priori-Verteilungen wählen, haben Sie Argumentationslinien: epistemologisch und ontologisch. Epistemologisch können Sie argumentieren, dass die Normalverteilung die Entropie maximiert, also die Verteilung mit den wenigsten Vorannahmen ist, wenn man davon ausgeht, dass die gesuchte Verteilung über eine endliche Varianz und einen endlichen Mittelwert verfügt. Ontologisch können Sie argumentieren, dass z. B. Körpergröße (innerhalb eines Geschlechts zumindest) hinreichend normalverteilt ist.\nDie Begründung für das lineare Modelle erschließt sich aus der Theorie, nämlich dass z. B. die gewählten UV den gesuchten Effekt gut beschreiben.\n\n13.5.2.1 Kausal- vs. Korrelationsmodell\nSie wollten weiterhin angeben, ob Ihre Forschungsfrage ein kausales Modell annimmt oder ein deskiptives (korrelatives). Bei einem kausalen Modell sollen dann die Pfeile Wirkungsrichtungen, also Ursache-Wirkungs-Beziehungen angeben.\nAuch wenn ihre Studie nicht die “Kraft” hat, Kausalbeziehungen (in Gänze) aufzudecken, ist es trotzdem meistens sinnvoll, ein Kausalmodell aufzustellen, da Theorien (und Praxis) meist an Kausalbeziehungen interessiert sind, und an Korrelationsbeziehungen wenig(er).\nViele wissenschaftliche Studien haben ein kausales Erkenntnisziel, nicht ein deskriptives.\n\n\n13.5.2.2 Hypothesen testen\nDas Testen der Hypothese ist eine Umsetzung der Idee, eine Behauptung einer empirisch-rationalen Prüfung zu unterziehen.\nEs bietet sich an, eine Hypothese zu wählen, wenn der Stand der Theorie dies erlaubt, idealerweise mehr als nur eine Null-Effekt-Hypothese, etwas \\(\\beta=0\\). Dass nämlich ein Effekt exakt Null ist, erscheint für die meisten Situationen der Sozialwissenschaften reichlich unplausibel.\nSie sollten die Hypothese zuerst als Aussage formulieren, aber danach möglichst mit mathematischen Symbolen präzisieren (“statistische Hypothesen”).\nHier sind Beispiele für statistische Hypothesen:\n\n\\(H: \\mu &gt; 0\\)\n\\(H: \\mu = 0\\)\n\\(H: \\mu \\ne 0\\)\n\\(H: \\beta &gt; 0\\)\n\\(H: d &gt; 0\\)\n\\(H: R^2 &gt; 0\\)\n\nDabei meint \\(\\beta\\) ein Regressiongewicht, \\(d\\) eine Differenz (zweier Gruppen) und \\(R^2\\) die erklärte Varianz eines Modells.\n\\(R^2\\) als Kennzahl einer Hypothese ist interessant, weil es Ihnen erlaubt, ein ganzes Modell als Hypothese zu formulieren. Also “Verbundhypothesen” aufzustellen, die mehr als eine oder zwei Variablen umfassen.\nMöchten Sie eine Hypothese zu einem Parameter testen, der einen Nullwert beinhaltet, bietet sich das ROPE-Verfahren an, vgl. Kruschke (2018).\n\n\n13.5.2.3 Parameterschätzung\nBei einer Parameterschätzung formulieren Sie ein Modell, genau wie beim Hypothesen testen, nur eben ohne Hypothesen. Es geht Ihnen dann nicht um die Frage, ob irgend ein Sachverhalt der Fall ist (das ist Hypothesen prüfen). Stattdessen interessieren Sie sich für die Frage, wie sehr etwas der Fall ist:\n\n“Wie stark ist der Zusammenhang von Lernzeit und Prüfungserfolg?”\n“Um wie viele Sekunden parken Frauen im Schnitt schneller ein als Männer?”\n“Wie groß ist der statistische Effekt eines Sportwagens auf einem männlichen Profilbild beim Online-Dating?”\n\nAuch hier ist es erlaubt und sinnvoll, eine sprachliche Frage, die oft vage ist, schon aufgrund der natürlichen Ambuität der Sprache, mit Hilfe mathematischer Notation zu präzisieren:\n\n“Der Zusammenhang \\(\\beta\\) ist definiert als das Regressiongewicht der Variable lern im Modell m1.\n“Operationalisiert wurde die Einparkgeschwindigkeit als die Dauer der Durchführung in Sekunden nach Instruktion wie im Abschnitt XYZ beschrieben. Unser Modell (m1) schätzte den Parameter s.\n“Der statistische Effekt ist definiert als das Regressiongewicht der experimentellen Bedingung (binäre Variable group) im Modell m1.\n\nGeben Sie weiter an, welches Intervall Sie berichten, z. B. “Die Parameterschätzungen werden anhand eines 95%-HDI berichtet”.\nAuch wenn Sie eine Hypothese testen, sollten Sie Bereichsschätzungen für die Parameter vornehmen, also Schätzbereiche aus der Posteriori-Verteilung berichten.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#methodenteil",
    "href": "100-Statistiken-berichten.html#methodenteil",
    "title": "13  Auswerten: Berichten von Statistiken",
    "section": "13.6 Methodenteil",
    "text": "13.6 Methodenteil\n\n13.6.1 Analyse\n\n13.6.1.1 Bayes erklären\n\nErklären Sie, warum Sie eine Bayes-Analyse verwenden und nicht eine frequentistische. Eine ehrliche Antwort wäre zwar, “mein Dozent wollte es so, was bleibt mir groß übrig”, aber es gibt (vermutlich?!) auch fachliche Gründe (z. B.: Eine Priori-Annahme zur Wahrscheinlichkeit eines Parameters wird durch Daten zu einer Wahrscheinlichkeit verschoben). Die sollten sie anführen.\nErklären, was eine Bayes-Analyse ist. (Man bekommt Wahrscheinlichkeiten für Hypothesen, was man beim Frequentismus nicht bekommt.)\nFühren Sie an, ob Sie an einer Parameterschätzung oder einer Hypothesentestung interessiert sind. Die Parameterschätzung ist oft zu bevorzugen, da informationsreicher.\n\nBayes-Statistiken sollten Sie im kurz erläutern, da sie vielen Lesis nicht so gut vertraut sein wird.\nSie können z. B. bei Kruschke (2018)” die Grundlagen des ROPE-Konzepts nachlesen. Vielleicht findet sich ja auch in Ihrem Statistik-Skript etwas Passendes?\n\n\n13.6.1.2 ROPE\nKurz gesagt wird beim ROPE geprüft, welcher Anteil des Posteriori-Intervalls zu einem Bereich “vernachlässigbar kleiner” Parameterwerte bewegt. Die folgende Abbildung illustriert ein Rope für die Forschungsfrage “Wie stark ist der Effekt der Zylinderzahl auf den Spritverbrauch?”; genauer gesagt ist die Posteriori-Verteilung für den (Regressions-)Effekt, \\(\\beta\\), des Parameters cyl gezeigt. Wie man sieht, ist die Posteriori-Verteilung (glockenförmige Verteilung) komplett außerhalb des Bereichs “sehr kleiner” Werte (ROPE; blaues Rechteck rechts). Wir resümieren: “Es ist auszuschließen, dass der Effekt der Variable Zylinder auf den Spritverbrauch praktisch Null (sehr klein) ist”.\nWenn man die Null bzw. den Nullbereich (ROPE) eines Parameters ausschließt, nennt man das Ergebnis bzw. den Effekt auch “signifikant” (leider ein häufig missbrauchter und missverstandener Begriff). Unser Effekt in diesem Beispiel ist also signifikant (nach dieser Definition). Besser ist es aber, wenn Sie den Begriff vermeiden, und stattdessen davon sprechen, dass Sie einen Effekt gefunden haben (oder nicht oder dass eine unklare Ergebnislage vorliegt). Haben Sie einen Effekt gefunden, so heißt das synonym, dass die Nullhypothese ausgeschlossen ist (falsifiziert ist), natürlich immer auf Basis des vorliegenden Modells bzw. der vorliegenden Daten.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#ergebnisteil",
    "href": "100-Statistiken-berichten.html#ergebnisteil",
    "title": "13  Auswerten: Berichten von Statistiken",
    "section": "13.7 Ergebnisteil",
    "text": "13.7 Ergebnisteil\n\n13.7.1 Deskriptive Statistik\n\n13.7.1.1 Was soll ich schreiben?\nBevor Sie die Ergebnisse Ihrer Modellierung zeigen, bietet sich etwas “Aufwärmen” an, vor dem Fußballspiel wärmt man sich ja auch erstmal auf. Dazu bieten sich die deskriptiven Statistiken zu Ihren Daten an.\nHäufig wird man ein Maß der zentralen Tendenz (Mittelwert oder Median) sowie ein dazu passendes Streuungsmaß berichten (z. B. SD) berichten. Evtl. kann man ein Maß zur Präzision des Mittelwerts angeben (SE). Bei schiefen Verteilungen greift man meist auf robuste Kennwerte zurück; bei normalverteilten Verteilungen ist Mittelwert und SD die Statistik der Wahl. Die Stichprobengröße sollte klar sein; liegen fehlende Werte vor, so sollte pro Kennzahl jeweils die effektive Stichprobengröße berichtet sein. Ansonsten reicht es, die Stichprobengröße an einer Stelle (im Text) anzuführen.\nGängige statistische Symbole sollen nicht definiert werden, z. B. M, SD, F, t, df, N, n, OR. Andere statistischen Abkürzungen, die weniger gebräuchlich sind, sollten definiert bzw. auf die Definition verwiesen werden, z. B. pd, ROPE.\nFormulierungsvorschlag\n\nDer mittlere Achtsamkeits-Wert lag in der Stichprobe bei M = 12.23 (SD = 1.23).\n\n\nDie Reaktionszeit in der Experimentalbedingung war höher als in der Kontrollbedingung (Experimentalbedingung: M = 2.7, SD = 0.3; Kontrollbedingung: M = 0.1, SD = 0.4).\n\n\nEs fand sich eine starke Korrelation zwischen Achtsamkeit und Lebenszufriedenheit, r(134) = .42, 95% CI [.32, .52].\n\nHat man eine größere Zahl an Statistiken, so bietet es sich an, die Ergebnisse nicht im Fließtext, sondern in einer Tabelle zu berichten. Berichtet man Ergebnisse in einer Tabelle, so doppelt man sie nicht im Text.\nEine nützliche Ergänzung ist es, zusätzlich zu den univariaten Statistiken noch Zusammenhangskoeffizienten (Korrelationen) zu berichten.\n\n\n13.7.1.2 Tabellen mit R\nIm folgenden sind Möglichkeiten aufgezeigt, wie Sie Tabellen mit R für Ihren Bericht erstellen können. Bitte behalten Sie im Blick, dass in einem deutschsprachigen Bericht die Variablen- und Kennzahlennamen in deutscher Sprache erscheinen sollten. Auf “technisch” anmutenden Abkürzungen (z. B. mpg_sd) sollten man verzichten zugunsten “sprechenderer” Formulierengen (z. B. SD Spritverbrauch, oder SD MPG, wenn “MPG” in der Fußnote der Tabelle definiert ist). Tabellen sollten für sich selber verständlich sein, ohne Bezug zum Text.\nMit gängigen R-Methoden kann man sich deskriptive Statistiken ausgeben lassen, s. Tabelle 13.1.\n\nmtcars %&gt;% \n  summarise(mpg_avg = mean(mpg),\n            mpg_sd = sd(mpg),\n            cor_mpg_hp = cor(mpg, hp)) %&gt;% \n  rename(`MW Spritverbrauch` = mpg_avg,\n         `SD Spritverbrauch`= mpg_sd,\n         `Korrelation Spritverbrauch mit PS-Zahl` = cor_mpg_hp)\n\n\n\nTabelle 13.1: Einfache Tabelle mit deskriptiven Statistiken\n\n\n\n\n  \n\n\n\n\n\n\nAlternativ zu selbsterstellten Tabellen kann “Statistik-Fast-Food” konsumieren und lässt sich einen Haufen Zahlen auf einmal ausgeben. R-Pakete wie r_statix, skimr oder easystats helfen dabei, s. als Beispiel Tabelle 13.2.\n\nlibrary(easystats)\n\ndescribe_distribution(mtcars) %&gt;% \n  select(-n, -n_Missing) %&gt;% \n  rename(MW = Mean, Schiefe = Skewness)\n\n\n\n\n\nTabelle 13.2: Einfache Tabelle mit describe_distribution aus easystats\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMW\nSD\nIQR\nRange\nSchiefe\nKurtosis\n\n\n\n\nmpg\n20.09\n6.03\n7.53\n(10.40, 33.90)\n0.67\n-0.02\n\n\ncyl\n6.19\n1.79\n4.00\n(4.00, 8.00)\n-0.19\n-1.76\n\n\ndisp\n230.72\n123.94\n221.53\n(71.10, 472.00)\n0.42\n-1.07\n\n\nhp\n146.69\n68.56\n84.50\n(52.00, 335.00)\n0.80\n0.28\n\n\ndrat\n3.60\n0.53\n0.84\n(2.76, 4.93)\n0.29\n-0.45\n\n\nwt\n3.22\n0.98\n1.19\n(1.51, 5.42)\n0.47\n0.42\n\n\nqsec\n17.85\n1.79\n2.02\n(14.50, 22.90)\n0.41\n0.86\n\n\nvs\n0.44\n0.50\n1.00\n(0.00, 1.00)\n0.26\n-2.06\n\n\nam\n0.41\n0.50\n1.00\n(0.00, 1.00)\n0.40\n-1.97\n\n\ngear\n3.69\n0.74\n1.00\n(3.00, 5.00)\n0.58\n-0.90\n\n\ncarb\n2.81\n1.62\n2.00\n(1.00, 8.00)\n1.16\n2.02\n\n\n\n\n\n\n\n\nTabellen mit flextable(), gtsummary oder gt() kann man sich eine schicke Tabelle (im HTML-Format) ausgeben lassen, die man dann per Copy-Paste in Word, d.h. den eigene Forschungsbericht, übernehmen kann. s. Tabelle 13.3.\n\nlibrary(gt)  # gt wie \"grammer of tables\"\n\nmeine_tab &lt;- \n  describe_distribution(mtcars) %&gt;% \n  gt() %&gt;%  # erzeugt schicke Tabelle\n  fmt_number(where(is.numeric), decimals = 2) # Anzahl der Dezimalstellen\n\nmeine_tab\n\n\n\nTabelle 13.3: Deskriptive Statistiken mit gt\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nmpg\n20.09\n6.03\n7.53\n10.40\n33.90\n0.67\n−0.02\n32.00\n0.00\n\n\ncyl\n6.19\n1.79\n4.00\n4.00\n8.00\n−0.19\n−1.76\n32.00\n0.00\n\n\ndisp\n230.72\n123.94\n221.53\n71.10\n472.00\n0.42\n−1.07\n32.00\n0.00\n\n\nhp\n146.69\n68.56\n84.50\n52.00\n335.00\n0.80\n0.28\n32.00\n0.00\n\n\ndrat\n3.60\n0.53\n0.84\n2.76\n4.93\n0.29\n−0.45\n32.00\n0.00\n\n\nwt\n3.22\n0.98\n1.19\n1.51\n5.42\n0.47\n0.42\n32.00\n0.00\n\n\nqsec\n17.85\n1.79\n2.02\n14.50\n22.90\n0.41\n0.86\n32.00\n0.00\n\n\nvs\n0.44\n0.50\n1.00\n0.00\n1.00\n0.26\n−2.06\n32.00\n0.00\n\n\nam\n0.41\n0.50\n1.00\n0.00\n1.00\n0.40\n−1.97\n32.00\n0.00\n\n\ngear\n3.69\n0.74\n1.00\n3.00\n5.00\n0.58\n−0.90\n32.00\n0.00\n\n\ncarb\n2.81\n1.62\n2.00\n1.00\n8.00\n1.16\n2.02\n32.00\n0.00\n\n\n\n\n\n\n\n\n\n\nAus APA-Sicht würde vermutlich MW und SD genüge tun (sofern man von normalverteilten Variablen) ausgeht. Allerdings schadet es auch nicht, zusätzliche Kennwerte anzugeben. Verzichten sollte man aber vermutlih - in diesem Fall - auf die Spalte n_Missing, da die Spalte keine Information birgt.\nSo sieht eine Tabelle mit gtsummary aus, s. Tabelle 13.4. Hier wird die Häufigkeitsanalyse gezeigt.\n\nlibrary(gtsummary)\nmtcars %&gt;% \n  select(mpg, cyl) %&gt;% \n  tbl_summary()\n\n\n\nTabelle 13.4: Deskriptive Statistiken mit gtsummary\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 321\n\n\n\n\nmpg\n19.2 (15.4, 22.8)\n\n\ncyl\n\n\n\n\n    4\n11 (34%)\n\n\n    6\n7 (22%)\n\n\n    8\n14 (44%)\n\n\n\n1 Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\n\n\nHier findet sich noch mehr zum Thema Exportieren von Tabellen aus R nach Word.\nEine tidy Korrelationstabelle kann man sich z. B. (mit easystats, aber es gibt mehrere R-Pakete für diesen Zweck) so ausgeben lassen:\n\nmeine_cor_tab &lt;-\n  mtcars %&gt;% \n  select(mpg, hp, disp) %&gt;% \n  correlation()\n\nmeine_cor_tab %&gt;% print_md()\n\n\nCorrelation Matrix (pearson-method)\n\n\nParameter1\nParameter2\nr\n95% CI\nt(30)\np\n\n\n\n\nmpg\nhp\n-0.78\n(-0.89, -0.59)\n-6.74\n&lt; .001***\n\n\nmpg\ndisp\n-0.85\n(-0.92, -0.71)\n-8.75\n&lt; .001***\n\n\nhp\ndisp\n0.79\n(0.61, 0.89)\n7.08\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 32\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit print_md erreicht man, dass die Tabelle in schönerem Markdown-Format gedruckt wird. Da Markdown sich problemlos in HTML- oder Word-Format konvertieren lässt, kann man auf diese Art schöner formatierte Tabellen erhalten (als mit dem Standard von describe_distribution and friends). gt ist allerdings schon von Natur aus schön.\\(\\square\\)\n\n\nMöchte man eine quadratische Korrelationstabelle (was der üblicheren Berichtsform entspricht) kann man das so bekommen:\n\nsummary(meine_cor_tab) %&gt;% \n  gt() %&gt;%  # machen wir gleich eine schicke HTML-Tabelle\n  fmt_number(where(is.numeric), decimals = 2)\n\n\n\n\n\n\n\nParameter\ndisp\nhp\n\n\n\n\nmpg\n−0.85\n−0.78\n\n\nhp\n0.79\nNA\n\n\n\n\n\n\n\nVergessen Sie nicht, das Tabellen (genau wie Abbildungen) im Text zu referenzieren sind.\n\n\n\n13.7.2 Diagramme exportieren\nDiagramme, die Sie mit ggplot erstellt haben, können Sie z. B. mit dem Befehl ggsave in eine Datei speichern (z. B. im Format PNG oder PDF).\nInteressant könnte für Sie auch das Paket qwraps2 sein, das u.a. einen Formulierungsvorschlag erstellt, wie man Statistiken im Fließtext anführt. Betrachten wir ein Beispiel mit mtcars. Sagen wir, wir möchten den mittleren Spritverbrauch berichten.\n\nlibrary(qwraps2)\n\nmean_sd(mtcars$mpg)\n## [1] \"20.09 $\\\\pm$ 6.03\"\n\nDas Zeichen $\\\\pm$ steht für “Plus-Minus” ± (im Formelmodus). In Word sollten Sie es händisch durch den Glyphen (das Zeichen) “±” ersetzen.2\n\n\n13.7.3 Inferenzstatistik\nEs empfiehlt sich, die Modellgleichung inkl. Prior-Spezifiaktion aufzuführen.\n\n13.7.3.1 Posteriori-Verteilung\nFür jede Hypothese müssen Sie die zentralen Ergebnisse berichten. Die Hypothesen beziehen sich auf Populationen, also benötigen wir Inferenzstatistik. In der frequentistischen Statistik finden hier Statistiken wie der p-Wert und das (frequentistische) Konfidenzintervall Verwendung. In einer Bayes-Analyse ist die Posteriori-Verteilung der Dreh- und Angelpunkt der Ergebnisse.\nDie Post-Verteilung gibt an, wie wahrscheinlich ein bestimmter Parameterwert jetzt ist, nachdem die Daten bekannt sind.\nEin statistisches Modell wird zumeist mit einem Regressionsmodell umgesetzt. Ein Regressionsmodell kann man in R mit lm() (frequentistisch) oder z. B. stan_glm() (Bayes) berechnen. Die Syntax ist sehr ähnlich.\n\n\n13.7.3.2 Umsetzung in R\nSie können eine Posteriori-Verteilung z. B. für ihr Modell berechnen:\n\nlibrary(rstanarm)\n\nm1 &lt;- stan_glm(mpg ~ am, data = mtcars, seed = 42)\n\nHier sind die Ergebnisse; noch nicht ganz poliert für einen APA-Bericht, s. Tabelle 13.5.\n\nparameters(m1, prob = .95) %&gt;% \n  print_md()\n\n\n\nTabelle 13.5: Parameter für das Modell m1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n17.14\n(14.85, 19.51)\n100%\n0.999\n3739.00\nNormal (20.09 +- 15.07)\n\n\nam\n7.21\n(3.72, 10.70)\n99.95%\n0.999\n3755.00\nNormal (0.00 +- 30.20)\n\n\n\n\n\n\n\n\nWir bekommen ein 95%-Perzentilintervall (PI, kein HDI, ist aber auch ok, allerdings ist das HDI einen Tick besser). Es erlaubt uns zu sagen, dass der Unterschied im Spritverbrauch zwischen 3.6 und 11 Meilen (pro Gallone Sprit) liegt, laut dem Modell. Der Schalter prob erlaubt, andere CI-Breiten, z. B. 97% zu wählen.\nEin HDI bekommen Sie, wenn Sie bei ci_method den Wert \"hdi wählen; oder wenn Sie gleich den Befehl hdi(m1) ausführen, s. Tabelle 13.6.\n\nparameters(m1, prob = .95, ci_method = \"hdi\") %&gt;% print_md()  # oder: hdi(m1)\n\n\n\nTabelle 13.6: Parameter für das Modell m1. Das Intervall ist ein HDI.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n17.14\n(14.95, 19.59)\n100%\n0.999\n3739.00\nNormal (20.09 +- 15.07)\n\n\nam\n7.21\n(3.67, 10.62)\n99.95%\n0.999\n3755.00\nNormal (0.00 +- 30.20)\n\n\n\n\n\n\n\n\nDie Tabelle können Sie natürlich auch gleich wieder aufhübschen, für Ihren Bericht, s. Tabelle 13.7.\n\nhdi(m1) %&gt;% \n  select(Parameter, CI_low, CI_high) %&gt;% \n  gt() %&gt;% \n  fmt_number(where(is.numeric), decimals = 2)\n\n\n\nTabelle 13.7: Parameter für das Modell m1. Das Intervall ist ein HDI.\n\n\n\n\n\n\n\n\n\nParameter\nCI_low\nCI_high\n\n\n\n\n(Intercept)\n14.95\n19.59\n\n\nam\n3.67\n10.62\n\n\n\n\n\n\n\n\n\n\nEin ähnliches Ergebnis erzielt man mit dem Paket gtsummary, s. Tabelle 13.8.\n\ntbl_regression(m1)\n\n\n\nTabelle 13.8: Parameter für das Modell m1.\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\n\n\n\n\nam\n7.2\n3.7, 11\n\n\n\n1 CI = Credible Interval\n\n\n\n\n\n\n\n\n\n\n\nDen Punktschätzer (Median) zum Unterschied für die Gruppen (Automatik vs. Schaltgetriebe) hat uns die Funktion parameters() auch geliefert. Der Unterschied zwischen den beiden Gruppen liegt laut Modell bei ca. 7.2 Meilen.\nIm Bericht könnte man z. B. schreiben:\nFormulierungsvorschlag\n\nDer Unterschied im Spritverbrauch zwischen den beiden Gruppen (Automatik vs. Schaltgetriebe) wurde auf 7.2 Meilen geschätzt, 95% PI [3.7, 11.0].\n\nWeiter macht es Sinn zu überlegen, ob Sie den Effekt für “klein” oder “groß” halten. Das ist eine subjektive Frage, die Sie am besten auf Basis theoretischer (nicht statistischer) Überlegungen entscheiden. Am besten Sie erwähnen im Methodenteil, was Sie als “kleinen” und “großen” Effekt einschätzen. So könnten Sie argumentieren, dass ein Unterschied von 1 Meile “klein” ist und 5 Meilen “groß”. Demnach sprechen unsere Ergebnisse deutlich gegen einen kleinen Effekt und sind gut mit einem “großen” Effekt kompatibel.\nEs bietet sich an, die Parameter-Schätzbereiche zu visualisieren. Das kann man z. B. so machen:\n\nparameters(m1) %&gt;% plot(show_intercept = TRUE)\n\n\n\n\n\n\n\n\nDer Schalter show_intercept regelt, ob der Schätzwert für den Achsenabschnitt gezeigt werden soll oder nicht.3\nMöchte man verschiedenen Regressiongsgewichte vergleichen, bietet es an, diese vorab zu standardisieren mit der z-Transformation.\nMehr zur Analyse mit rstanarm findet sich z. B. hier oder bei Gelman, Hill, und Vehtari (2021).\nÜbrigens kann man ein hdi() auch plotten, wenn man möchte:\n\nplot(hdi(m1))\n\nSieht auch ganz schick aus; im Hintergrund wird {easystats} zum Plotten verwendet. Praktischerweise ist es ein ggplot-Diagramm, man kann also mit bekannten (ggplot-)Methoden nachpolieren, z.B s. Abbildung 13.2.\n\nplot(hdi(m1)) +\n  labs(title =\"Hier steht mein Titel\",\n       y = \"\",\n       y = \"\",\n       x = \"Parameterwert\") +\n  theme_minimal() +\n  theme(axis.text.y = element_blank())  # keine Achsenlabels auf Y (\"am\" weg)\n\n\n\n\n\n\n\nAbbildung 13.2: Die Postverteilung als Berg visualisiert, nicht als Seil.\n\n\n\n\n\n\n\n\n13.7.4 ROPE\nTesten Sie eine Hypothese, die einen “praktischen Nullwert” ausschließen möchte, so bietet sich das ROPE-Verfahren an.\nMit ROPE testet man demnach keine “Exaktnullhypothese”, sondern eine “Praktischnullhypothese”, nämlich dass ein Effekt so klein ist, dass er praktisch keine Bedeutung hat.\nDiesem Konzept liegt die Überlegung zugrunde, dass es in der freien Wildbahn kaum oder keine Effekte gibt, die exakt Null sind, also “0,0000000000000000000000000 …” und so weiter bis alle Unendlichkeit.\nSinnvoller ist es daher zu prüfen, ob ein Effekt vernachlässigbar klein ist für praktische Belange.\nWie klein ein Effekt sein muss, um “klein genug” für “vernachlässigbar klein” zu sein, ist erstmal keine statistische Frage.\nSchauen Sie: Wie groß muss der Nutzen des Besuchens einer Vorlesung sein, damit Sie sie besuchen? Die Antwort der Frage hängt von mehreren Faktoren ab, und sie ist subjektiv in dem Sinne, dass die Antwort von persönlichen Präferenzen abhängt, die letztlich nicht objektiv zu begründen sind.\nSo kann man in R ein ROPE berechnen (lassen):‚\n\nlibrary(easystats)\n\nrope(m1)\n\n\n  \n\n\n\nDas Ergebnis sagt uns, dass 0% des 95%-HDI innerhalb des ROPE-Bereichs liegen. Die Nullhypothese ist also für praktische Zwecke auszuschließen.\nFormulierungsvorschlag &gt; Die Nullhypothese \\(H^1_0\\) ist auszuschließen laut Modell m1, 0% ROPE. Der Effekt ist demnach in diesem Sinne signifikant.\nDas kann man sich auch plotten lassen:\n\nplot(rope(m1))\n\n\n\n\n\n\n\n\nDie Hilfeseite von rope sagt uns:\n\nCompute the proportion of the HDI (default to the 89% HDI) of a posterior distribution that lies within a region of practical equivalence.\n\nWeiter steht dort:\nrope(x, range = \"default\", ci = 0.95, ci_method = \"ETI\", verbose = TRUE, ...)\nETI steht für “Equal Tail Interval”, das ist ein Perzentilintervall.\nZum Argument range ist zu lesen:\n\nROPE’s lower and higher bounds. Should be “default” or depending on the number of outcome variables a vector or a list. In models with one response, range should be a vector of length two (e.g., c(-0.1, 0.1)). In multivariate models, range should be a list with a numeric vectors for each response variable. Vector names should correspond to the name of the response variables. If “default” and input is a vector, the range is set to c(-0.1, 0.1). If “default” and input is a Bayesian model, rope_range() is used.\n\nUnd rope_range() sagt uns in der Hilfeseite:\n\nKruschke (2018) suggests that the region of practical equivalence could be set, by default, to a range from -0.1 to 0.1 of a standardized parameter (negligible effect size according to Cohen, 1988).\n\nWobei man schon im Methodenteil ROPE definieren sollte, dann müsste man das hier nicht mehr tun.\nMerkhilfe zur Entscheidung mit ROPE:\n\nSchneidet ROPE mit dem Berg, dem roten, dann Verwerfen ist verboten!\n\nMit “Verwerfen” ist das Verwerfen der “Praktischnullhypothese” gemeint.\nDas ROPE ist eine nette Sache: Man kann eine “Praktischnullhypothese” testen. Besser ist aber die Schätzung eines Konfidenzintervalls: Es beinhaltet die Informationen eines ROPE aber noch mehr.\n\n13.7.4.1 Standardisierte Effektstärke\nVergleicht man Gruppen und ist z. B. die AV wenig anschaulich (etwa ein Summenscore), so bietet es sich, standardisierte Maße des Gruppenunterschieds anzugeben. Man nennt sie auch Maße der Effektstärke.\nBei Gruppenvergleichen ist Cohens d ein bekanntes Maß. Man kann es sich so ausgeben lassen:\n\nlibrary(easystats)\ncohens_d(mpg ~ am, data = mtcars) %&gt;% print_md()\n\n\n\n\nCohen’s d\n95% CI\n\n\n\n\n-1.48\n[-2.27, -0.67]\n\n\n\nEstimated using pooled SD.\n\n\nMan gibt also die Regressionsformel und die Daten an. Zu beachten ist, dass die AV zweistufig sein muss, sonst ist Cohens d nicht definiert.\nPraktischerweise kann man sich die Effektstärke auch gleich interpretieren lassen:\n\ninterpret_cohens_d(-1.48)\n## [1] \"large\"\n## (Rules: cohen1988)\n\nUm \\(R^2\\) in einem Bayes-Modell zu bekommen, bietet sich die Funktion bayes_R2() an:\n\nm1_R2 &lt;- \n  bayes_R2(m1) %&gt;% \n  as_tibble()\n\nhdi(m1_R2) %&gt;% print_md()\n\n\nHighest Density Interval\n\n\nParameter\n95% HDI\n\n\n\n\nvalue\n[0.10, 0.54]\n\n\n\n\n\n\n\n13.7.4.2 R-Paket report\nVielleicht ist das R-Paket report für Sie nützlich. Ich bin nicht ganz sicher, denn das Paket ist noch sehr neu und berichtet recht viel Informationen. Aber vielleicht wollen Sie es ja mal ausprobieren.\n\nlibrary(easystats)\n\nreport lieft z. B. eine Beschreibung der Stichprobe:\n\nmtcars %&gt;% \n  select(1:3) %&gt;%  # hier nur die Variablen 1 bis 3, der Einfachheit halber\n  report()\n## The data contains 32 observations of the following 3 variables:\n## \n##   - mpg: n = 32, Mean = 20.09, SD = 6.03, Median = 19.20, MAD = 5.41, range:\n## [10.40, 33.90], Skewness = 0.67, Kurtosis = -0.02, 0 missing\n##   - cyl: n = 32, Mean = 6.19, SD = 1.79, Median = 6.00, MAD = 2.97, range: [4,\n## 8], Skewness = -0.19, Kurtosis = -1.76, 0 missing\n##   - disp: n = 32, Mean = 230.72, SD = 123.94, Median = 196.30, MAD = 140.48,\n## range: [71.10, 472], Skewness = 0.42, Kurtosis = -1.07, 0 missing\n\nOder auch für (Bayes-)Regressionsmodelle:\n\nreport(m1)\n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\n## Chain 1: \n## Chain 1: Gradient evaluation took 0.000373 seconds\n## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 3.73 seconds.\n## Chain 1: Adjust your expectations accordingly!\n## Chain 1: \n## Chain 1: \n## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 1: \n## Chain 1:  Elapsed Time: 0.166 seconds (Warm-up)\n## Chain 1:                0.193 seconds (Sampling)\n## Chain 1:                0.359 seconds (Total)\n## Chain 1: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\n## Chain 2: \n## Chain 2: Gradient evaluation took 5e-05 seconds\n## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.5 seconds.\n## Chain 2: Adjust your expectations accordingly!\n## Chain 2: \n## Chain 2: \n## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 2: \n## Chain 2:  Elapsed Time: 0.18 seconds (Warm-up)\n## Chain 2:                0.21 seconds (Sampling)\n## Chain 2:                0.39 seconds (Total)\n## Chain 2: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\n## Chain 3: \n## Chain 3: Gradient evaluation took 4.2e-05 seconds\n## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.42 seconds.\n## Chain 3: Adjust your expectations accordingly!\n## Chain 3: \n## Chain 3: \n## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 3: \n## Chain 3:  Elapsed Time: 0.188 seconds (Warm-up)\n## Chain 3:                0.201 seconds (Sampling)\n## Chain 3:                0.389 seconds (Total)\n## Chain 3: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\n## Chain 4: \n## Chain 4: Gradient evaluation took 4.8e-05 seconds\n## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds.\n## Chain 4: Adjust your expectations accordingly!\n## Chain 4: \n## Chain 4: \n## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 4: \n## Chain 4:  Elapsed Time: 0.163 seconds (Warm-up)\n## Chain 4:                0.213 seconds (Sampling)\n## Chain 4:                0.376 seconds (Total)\n## Chain 4:\n## We fitted a Bayesian linear model (estimated using MCMC sampling with 4 chains\n## of 2000 iterations and a warmup of 1000) to predict mpg with am (formula: mpg ~\n## am). Priors over parameters were set as normal (mean = 0.00, SD = 30.20)\n## distributions. The model's explanatory power is substantial (R2 = 0.35, 95% CI\n## [0.10, 0.54], adj. R2 = 0.29). The model's intercept, corresponding to am = 0,\n## is at 17.14 (95% CI [14.85, 19.51]). Within this model:\n## \n##   - The effect of am (Median = 7.21, 95% CI [3.72, 10.70]) has a 99.95%\n## probability of being positive (&gt; 0), 99.92% of being significant (&gt; 0.30), and\n## 99.72% of being large (&gt; 1.81). The estimation successfully converged (Rhat =\n## 0.999) and the indices are reliable (ESS = 3755)\n## \n## Following the Sequential Effect eXistence and sIgnificance Testing (SEXIT)\n## framework, we report the median of the posterior distribution and its 95% CI\n## (Highest Density Interval), along the probability of direction (pd), the\n## probability of significance and the probability of being large. The thresholds\n## beyond which the effect is considered as significant (i.e., non-negligible) and\n## large are |0.30| and |1.81| (corresponding respectively to 0.05 and 0.30 of the\n## outcome's SD). Convergence and stability of the Bayesian sampling has been\n## assessed using R-hat, which should be below 1.01 (Vehtari et al., 2019), and\n## Effective Sample Size (ESS), which should be greater than 1000 (Burkner, 2017).\n\nreport berichtet Statistiken nach dem sog. SEXIT-Konzept Makowski u. a. (2019). Wenn Ihnen einige Statistiken nicht geläufig sind, ignorieren Sie sich einfach oder lesen Sie sie nach.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#diskussion",
    "href": "100-Statistiken-berichten.html#diskussion",
    "title": "13  Auswerten: Berichten von Statistiken",
    "section": "13.8 Diskussion",
    "text": "13.8 Diskussion\nIm Diskussionsteil fasst man die zentralen Ergebnisse zusammen und interpretiert sie. Danach schließt sich eine Kritik der Ergebnisse (oder vielmehr des Vorgehens) an.\nOb man eine Hypothese “annimmt” oder “verwirft”, sollte nicht von einer einzelnen Zahl abhängig sein. Vielmehr ist es keine Schwarz-Weiß-, sondern eine Grauton-Entscheidung mit mehreren Einflussgrößen, wie Präzision der Schätzung, Effektstärke, Stichprobengröße, Güte der Daten, Stärke des Versuchsplans, Generalisierbarkeit, um nur einige wichtige zu nennen.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#reproduzierbarkeit",
    "href": "100-Statistiken-berichten.html#reproduzierbarkeit",
    "title": "13  Auswerten: Berichten von Statistiken",
    "section": "13.9 Reproduzierbarkeit",
    "text": "13.9 Reproduzierbarkeit\nDer Geist der Wissenschaft heißt Transparenz. Also machen Sie ihre Arbeit nachprüfbar und legen Sie die zentralen Schritte offen:\n\nReichen Sie die Daten ein; legen Sie ein Data-Dictionary (Codebook) bei.\nReichen Sie die Syntax ein.\nReichen Sie die Messinstrumente und Stimuli ein (sofern nicht öffentlich einsehbar).\nExplizieren Sie Ihr Vorgehen prägnant.\nErläutern Sie Ihre theoretischen Argumente nachvollziehbar und unter Bezug auf die Literatur.\nFixieren Sie die Zufallszahlen in Analysen, die mit Zufallszahlen arbeiten (z. B. stan_glm).\n\nDie Zufallszahlen in stan_glm können Sie z. B. so fixieren:\n\nm1 &lt;- stan_glm(av ~ uv, data = meine_daten, seed = 42)\n\nDie genaue Wert bei seed ist nicht entscheidend; aber ein bestimmter Seed-Wert wird immer die gleichen Zufallszahlen zielen und damit immer die gleichen Parameterwerte im Modell nach sich ziehen.\n\n\n\n\nCooper, Harris. 2020. „Reporting Standards for Research in Psychology: Why Do We Need Them? What Might They Be?“ In Reporting Quantitative Research in Psychology: How to Meet APA Style Journal Article Reporting Standards, 2nd Ed, 3–17. Washington, DC, US: American Psychological Association. https://doi.org/10.1037/0000178-001.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nJhangiani, Rajiv S, Jhangiani, I-Chant A Chiang, und Dana C Cuttler Leighton. 2019. Research Methods in Psychology.\n\n\nKruschke, John K. 2018. „Rejecting or Accepting Parameter Values in Bayesian Estimation“. Advances in Methods and Practices in Psychological Science 1 (2): 270–80. https://doi.org/10.1177/2515245918771304.\n\n\n———. 2021. „Bayesian Analysis Reporting Guidelines“. Nature Human Behaviour 5 (10, 10): 1282–91. https://doi.org/10.1038/s41562-021-01177-7.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, und Daniel Lüdecke. 2019. „Indices of Effect Existence and Significance in the Bayesian Framework“. Frontiers in Psychology 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767.\n\n\nPeters, Jan H., und Tobias Dörfler. 2015. Abschlussarbeiten in der Psychologie und den Sozialwissenschaften - Schreiben und Gestalten. PS - Psychologie. Hallbergmoos/Germany: Pearson. https://www.pearson-studium.de/schreiben-und-gestalten-von-abschlussarbeiten-in-der-psychologie-und-den-sozialwissenschaften.html.\n\n\nPeters, Jan Hendrik, und Tobias Dörfler. 2019. Planen, Durchführen und Auswerten von Abschlussarbeiten in der Psychologie und den Sozialwissenschaften. Pearson. https://www.pearson-studium.de/planen-durchfuehren-und-auswerten-von-abschlussarbeiten-in-der-psychologie-und-den-sozialwissenschaften.html.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "120-abschluss.html#beispiele-für-gute-projektarbeiten",
    "href": "120-abschluss.html#beispiele-für-gute-projektarbeiten",
    "title": "14  Abschluss",
    "section": "14.1 Beispiele für gute Projektarbeiten",
    "text": "14.1 Beispiele für gute Projektarbeiten\nAuf der Seite der Schriftenreihe des Instituts für Wirtschaftspsychologie (iwp) der FOM Hochschule finden Sie eine Auswahl an insgesamt gut aufbereiteten Berichten zu psychologischen Studien – fast alle aus studentischer Feder. Diese Arbeiten können als Vorbilder für Ihren eigenen Bericht dienen.\nInteressant ist z. B. die Arbeit zum Thema Selbstwirksamkeit, Selbstregulation und Prokrastination – Überprüfung eines Mediationsmodells von (schuhmacher_selbstwirksamkeit_2022?). Die Arbeit ist frei im Netz verfügbar.\n\nLernen Sie von anderen, vergleichbaren Arbeiten und nutzen Sie diese als Vorbild. \\(\\square\\)",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "120-abschluss.html#fertig",
    "href": "120-abschluss.html#fertig",
    "title": "14  Abschluss",
    "section": "14.2 Fertig",
    "text": "14.2 Fertig\nSie haben dieses Modul abgeschlossen. Sie müssen Ihren Fortschritt im Projektplan nicht mehr im Blick behalten. 😄",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "130-references.html",
    "href": "130-references.html",
    "title": "References",
    "section": "",
    "text": "Adler, Mortimer Jerome, and Charles Van Doren. 1972. How to Read a\nBook. Rev. and updated ed. New York: Simon and\nSchuster.\n\n\nAl-Natour, Sameh, Izak Benbasat, and Ronald Cenfetelli. 2011. “The\nAdoption of Online Shopping Assistants:\nPerceived Similarity as an Antecedent to\nEvaluative Beliefs.” Journal of the Association\nfor Information Systems 12 (5). https://doi.org/10.17705/1jais.00267.\n\n\nAmelang, M., and Lothar Schmidt-Atzert. 2012. Psychologische\nDiagnostik. https://doi.org/10.1007/978-3-642-17001-0.\n\n\nAmerican Psychological Association. 2019. Publication\nManual of the American Psychological\nAssociation, 7th Edition. Washington,\nDC: American Psychological Association (APA). https://www.amazon.com/Publication-Manual-American-Psychological-Association/dp/1433805618?SubscriptionId=0JYN1NVW651KCA56C102&tag=techkie-20&linkCode=xm2&camp=2025&creative=165953&creativeASIN=1433805618.\n\n\nAriely, Dan. 2012. Die Halbe Wahrheit Ist Die Beste\nLüge: Wie Wir Andere Täuschen–Und Uns Selbst\nAm Meisten. München: Droemer.\n\n\n———. 2015. Denken hilft zwar, nützt aber nichts: warum wir immer\nwieder unvernünftige Entscheidungen treffen. Translated by Maria\nZybak and Gabrielle Gockel. Vollständige Taschenbuchausgabe. Droemer\n30088. München: Droemer.\n\n\nBangor, Aaron, Philip T. Kortum, and James T. Miller. 2008. “An\nEmpirical Evaluation of the System Usability\nScale.” International Journal of Human–Computer\nInteraction 24 (6): 574–94. https://doi.org/10.1080/10447310802205776.\n\n\nBortz, Jürgen, and Nicola Döring. 2006. Forschungsmethoden Und\nEvaluation: Für Human- Und\nSozialwissenschaftler. 4. Auflage.\nBerlin: Springer. https://link.springer.com/book/10.1007/978-3-540-33306-7.\n\n\nBrembs, Björn. 2018. “Prestigious Science Journals\nStruggle to Reach Even Average Reliability.”\nFrontiers in Human Neuroscience 12 (February). https://doi.org/10.3389/fnhum.2018.00037.\n\n\nBrembs, Björn, Katherine Button, and Marcus Munafò. 2013. “Deep\nImpact: Unintended Consequences of Journal Rank.” Frontiers\nin Human Neuroscience 7. https://doi.org/10.3389/fnhum.2013.00291.\n\n\nBrown, Patricia M., Amanda M. George, and Debra J. Rickwood. 2021.\n“Rash Impulsivity, Reward Seeking and Fear of Missing Out as\nPredictors of Texting While Driving: Indirect Effects via\nMobile Phone Involvement.” Personality and Individual\nDifferences 171 (March): 110492. https://doi.org/10.1016/j.paid.2020.110492.\n\n\nBühner, M. 2011. Einführung in Die Test- Und\nFragebogenkonstruktion. PS Psychologie.\nHallbergmoos: Pearson Studium. https://books.google.de/books?id=Y4990CfV3wgC.\n\n\nChalmers, Alan F., and Alan F. Chalmers. 2007. Wege der\nWissenschaft: Einführung in die Wissenschaftstheorie. Edited by\nNiels Bergemann. 6., verb. Aufl. Berlin Heidelberg:\nSpringer.\n\n\nCialdini, Robert B. 2017. Die Psychologie des Überzeugens: wie Sie\nsich selbst und Ihren Mitmenschen auf die Schliche kommen.\nTranslated by Matthias Wengenroth. 8., unveränderte Auflage.\nBern: Hogrefe.\n\n\nCohen, J. 1992. “A Power Primer.” Psychological\nBulletin 112 (1): 155–59.\n\n\nCooper, Harris. 2020. “Reporting Standards for Research in\nPsychology: Why Do We Need Them? What Might\nThey Be?” In Reporting Quantitative Research in Psychology:\nHow to Meet APA Style Journal Article Reporting\nStandards, 2nd Ed, 3–17. Washington, DC, US:\nAmerican Psychological Association. https://doi.org/10.1037/0000178-001.\n\n\nDienes, Zoltan. 2008. Understanding Psychology as a Science: An\nIntroduction to Scientific and Statistical Inference. New\nYork: Palgrave Macmillan.\n\n\nDobelli, Rolf, and Birgit Lang. 2011. Die Kunst Des\nKlaren Denkens. Hanser.\n\n\nDPGs, BDP und. 2016. “Berufsethische\nRichtlinien.” Berufsverbandes Deutscher\nPsychologinnen und Psychologen e.V. und der Deutschen Gesellschaft für\nPsychologie e.V. https://www.dgps.de/die-dgps/aufgaben-und-ziele/berufsethische-richtlinien.\n\n\nEid, M, M Gollwitzer, and M Schmitt. 2013. Statistik Und\nForschungsmethoden: Lehrbuch. Mit\nOnline-Materialien. Beltz. http://books.google.de/books?id=bTdHyoIbMSAC.\n\n\nEscalas, Jennifer Edson, and Barbara B. Stern. 2003. “Sympathy and\nEmpathy: Emotional Responses to\nAdvertising Dramas.” Journal of Consumer\nResearch 29 (4): 566–78. https://doi.org/10.1086/346251.\n\n\nEtcoff, Nancy L., Shannon Stock, Lauren E. Haley, Sarah a. Vickery, and\nDavid M. House. 2011. “Cosmetics as a Feature of the Extended\nHuman Phenotype: Modulation of the Perception of\nBiologically Important Facial Signals.” PLoS ONE 6 (10):\n1–9. https://doi.org/10.1371/journal.pone.0025656.\n\n\nFerreira-Barbosa, Helena, Jerónimo García-Fernández, and Gabriel\nCepeda-Carrión. 2023. “The Mediating Role of\ne-Lifestyles to Use the Fitness Center\nApp.” International Journal of Human–Computer\nInteraction 0 (0): 1–10. https://doi.org/10.1080/10447318.2023.2204273.\n\n\nFisher, Gwenith G., Russell A. Matthews, and Alyssa Mitchell Gibbons.\n2016. “Developing and Investigating the Use of Single-Item\nMeasures in Organizational Research.” Journal of Occupational\nHealth Psychology 21: 3–23. https://doi.org/10.1037/a0039139.\n\n\nGalliker, Mark. 2016. Ist Die Psychologie Eine\nWissenschaft? Ihre Krisen Und\nKontroversen von Den Anfängen Bis Zur\nGegenwart. Wiesbaden:\nSpringer.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research.\nCambridge: Cambridge University Press.\n\n\nGraf, Laura K. M., Stefan Mayer, and Jan R. Landwehr. 2018.\n“Measuring Processing Fluency: One Versus Five\nItems.” Journal of Consumer Psychology 28: 393–411. https://doi.org/10.1002/jcpy.1021.\n\n\nGrant, Stan, Tom Aitchison, Esther Henderson, Jim Christie, Sharam Zare,\nJohn Mc Murray, and Henry Dargie. 1999. “A Comparison\nof the Reproducibility and the Sensitivity to\nChange of Visual Analogue Scales, Borg\nScales, and Likert Scales in Normal Subjects\nDuring Submaximal Exercise.” CHEST 116 (5):\n1208–17. https://doi.org/10.1378/chest.116.5.1208.\n\n\nGreenwald, Anthony G, and Mahzarin R Banaji. 1995. “Implicit\nSocial Cognition: Attitudes,\nSelf-Esteem, and Stereotypes.”\nPsychological Review 102 (1): 4–27.\n\n\nGrewal, Dhruv, Kent B. Monroe, and R. Krishnan. 1998. “The Effects\nof Price-Comparison Advertising on Buyers’ Perceptions of Acquisition\nValue, Transaction Value, and Behavioral Intentions.” Journal\nof Marketing 62: 46–59. https://doi.org/10.2307/1252160.\n\n\nGudmundsson, Einar. 2009. “Guidelines for Translating and Adapting\nPsychological Instruments.” Nordic Psychology 61 (2):\n29–45. https://doi.org/10.1027/1901-2276.61.2.29.\n\n\nGulbins, Jürgen, and Christine Kahrmann. 2000. Mut zur Typographie:\nein Kurs für Desktop-Publishing ; mit 40 Tabellen. 2., überarb. und\nerw. Aufl. X.media.press. Berlin: Springer.\n\n\nHayes, Andrew F., and Jacob J. Coutts. 2020. “Use Omega\nRather Than Cronbach’s Alpha for\nEstimating Reliability. But….”\nCommunication Methods and Measures 14 (1): 1–24. https://doi.org/10.1080/19312458.2020.1718629.\n\n\nHeesen, Bernd. 2021. Wissenschaftliches Arbeiten: Methodenwissen für\nWirtschafts-, Ingenieur- und Sozialwissenschaftler. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-62548-4.\n\n\nHo, Chin-Chang, and Karl F. MacDorman. 2010. “Revisiting the\nUncanny Valley Theory: Developing and Validating an\nAlternative to the Godspeed Indices.” Computers\nin Human Behavior, Online Interactivity:\nRole of Technology in Behavior\nChange, 26 (6): 1508–18. https://doi.org/10.1016/j.chb.2010.05.015.\n\n\nHofstadter, Douglas R., Susanne Held, and Douglas R. Hofstadter. 2008.\nIch bin eine seltsame Schleife. 2. Aufl.\nStuttgart: Klett-Cotta.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to\nResearch Design and Causality. Boca Raton: CRC\nPress, Taylor & Francis Group. https://theeffectbook.net/.\n\n\nJhangiani, Rajiv S, Jhangiani, I-Chant A Chiang, and Dana C Cuttler\nLeighton. 2019. Research Methods in\nPsychology.\n\n\nJonas, Klaus, Wolfgang Stroebe, and Miles Hewstone, eds. 2014.\nSozialpsychologie. Springer-Lehrbuch. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-41091-8.\n\n\nKahneman, Daniel. 2012. Schnelles Denken, Langsames\nDenken. München: Siedler\nVerlag.\n\n\nKornmeier, Martin. 2013. Wissenschaftlich Schreiben Leicht\nGemacht. 6th ed. Bern: Haupt-Verlag.\n\n\nKruschke, John K. 2018. “Rejecting or Accepting Parameter\nValues in Bayesian Estimation.” Advances\nin Methods and Practices in Psychological Science 1 (2): 270–80. https://doi.org/10.1177/2515245918771304.\n\n\n———. 2021. “Bayesian Analysis Reporting\nGuidelines.” Nature Human Behaviour 5 (10, 10):\n1282–91. https://doi.org/10.1038/s41562-021-01177-7.\n\n\nKurdi, Benedek, Shayn Lozano, and Mahzarin R. Banaji. 2017.\n“Introducing the Open Affective Standardized Image\nSet (OASIS).” Behavior Research\nMethods 49 (2): 457–70. https://doi.org/10.3758/s13428-016-0715-3.\n\n\nKwon, Min, Dai-Jin Kim, Hyun Cho, and Soo Yang. 2013. “The\nSmartphone Addiction Scale: Development and Validation of a Short\nVersion for Adolescents.” PloS One 8 (12): e83558. https://doi.org/10.1371/journal.pone.0083558.\n\n\nLabovitz, Sanford. 1970. “The Assignment of\nNumbers to Rank Order Categories.”\nAmerican Sociological Review 35 (3): 515–24. https://doi.org/10.2307/2093306.\n\n\nLang, P J, M M Bradley, and B N Cuthbert. 1999. “International\nAffective Picture System (IAPS): Instruction\nManual and Affective Ratings.” NIMH Center for the Study of\nEmotion and Attention.\n\n\nLewis, James R., and Jeff Sauro. 2009. “The Factor\nStructure of the System Usability Scale.” In\nHuman Centered Design, edited by Masaaki Kurosu,\n94–103. Lecture Notes in Computer Science.\nBerlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-02806-9_12.\n\n\nLienert, Gustav A., and Ulrich Raatz. 1998. Testaufbau und\nTestanalyse. 6. Auflage. Weinheim: Beltz,\nPsychologie Verlags Union.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel Lüdecke. 2019. “Indices of Effect Existence\nand Significance in the Bayesian\nFramework.” Frontiers in Psychology 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767.\n\n\nMaxham, James G., and Richard G. Netemeyer. 2002. “A\nLongitudinal Study of Complaining Customers’\nEvaluations of Multiple Service Failures and\nRecovery Efforts.” Journal of Marketing 66\n(4): 57–71. https://doi.org/10.1509/jmkg.66.4.57.18512.\n\n\nMichell, J, and C Ernst. 1997. “The Axioms of\nQuantity and the Theory of\nMeasurement.” Journal of Mathematical\nPsychology 41 (4): 345–56. http://www.ncbi.nlm.nih.gov/pubmed/9473397.\n\n\nMoosbrugger, Helfried, and Augustin Kelava, eds. 2012. Testtheorie\nUnd Fragebogenkonstruktion.\nSpringer-Lehrbuch. Berlin:\nSpringer. https://doi.org/10.1007/978-3-642-20072-4.\n\n\nMueller, Pam A., and Daniel M. Oppenheimer. 2014. “The Pen\nIs Mightier Than the Keyboard:\nAdvantages of Longhand Over Laptop Note\nTaking.” Psychological Science 25 (6): 1159–68.\nhttps://doi.org/10.1177/0956797614524581.\n\n\nNetemeyer, Richard G., Kelly L. Haws, and William O. Bearden, eds. 2011.\nHandbook of Marketing Scales: Multi-Item Measures for Marketing and\nConsumer Behavior Research. 3rd ed. Los Angeles:\nSAGE.\n\n\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New\nScience of Cause and Effect. First edition. New York:\nBasic Books.\n\n\nPeters, Jan H., and Tobias Dörfler. 2015. Abschlussarbeiten in der\nPsychologie und den Sozialwissenschaften - Schreiben und Gestalten.\nPS - Psychologie. Hallbergmoos/Germany:\nPearson. https://www.pearson-studium.de/schreiben-und-gestalten-von-abschlussarbeiten-in-der-psychologie-und-den-sozialwissenschaften.html.\n\n\nPeters, Jan H, and Tobias Dörfler. 2019. Schreiben und Gestalten von\nAbschlussarbeiten in der Psychologie und den Sozialwissenschaften.\nhttps://www.pearson-studium.de/drm/reader/nu/code/uesgvaaidpsy.\n\n\nPeters, Jan Hendrik, and Tobias Dörfler. 2019. Planen, Durchführen\nund Auswerten von Abschlussarbeiten in der Psychologie und den\nSozialwissenschaften. Pearson. https://www.pearson-studium.de/planen-durchfuehren-und-auswerten-von-abschlussarbeiten-in-der-psychologie-und-den-sozialwissenschaften.html.\n\n\nPopper, Karl. 2013. Logik Der Forschung. Edited by\nHerbert Keuth. Akademie Verlag. https://doi.org/10.1524/9783050063782.\n\n\nPorst, Rolf. 2014. Fragebogen: ein Arbeitsbuch. 4., erweiterte\nAuflage. Studienskripten zur Soziologie. Wiesbaden:\nSpringer.\n\n\nRedondo, Jaime, Isabel Fraga, Isabel Padrón, and Ana Piñeiro. 2008.\n“Affective Ratings of Sound Stimuli.” Behavior Research\nMethods 40 (3): 784–90. https://doi.org/10.3758/BRM.40.3.784.\n\n\nReichardt, Charles S. 2019. Quasi-Experimentation: A Guide to Design\nand Analysis. Methodology in the Social Sciences. New York :\nLondon: The Guilford Press.\n\n\nReiß, Siegbert, and Viktor Sarris. 2012. Experimentelle Psychologie:\nvon der Theorie zur Praxis. Pearson Studium Psychologie.\nMünchen: Pearson.\n\n\nSaint-Mont, Uwe. 2015. “Randomization Does Not Help\nMuch, Comparability Does.” PLoS ONE\n10 (7): e0132102. https://doi.org/10.1371/journal.pone.0132102.\n\n\nSatow, L. 2011. “B5T - Psychomeda\nBig-Five-Persönlichkeitstest.” https://doi.org/10.23668/PSYCHARCHIVES.4530.\n\n\n———. 2020. “B5T®. Big-Five-Persönlichkeitstest.” https://doi.org/10.23668/PSYCHARCHIVES.4611.\n\n\nSauer, Sebastian, and Ludwilla Lustig. 2023. “The Effect of\nBringtnixtin on Fluid Intelligence: A\nRandomized, Controlled Trial.” Journal for Fake Data 42\n(1): 271–314.\n\n\nSchepman, Astrid, and Paul Rodway. 2022. “The General\nAttitudes Towards Artificial Intelligence Scale\n(GAAIS): Confirmatory Validation and\nAssociations with Personality, Corporate\nDistrust, and General Trust.”\nInternational Journal of Human–Computer Interaction 0 (0):\n1–18. https://doi.org/10.1080/10447318.2022.2085400.\n\n\nSchönbrodt, Felix D, Moritz Heene, Michael Zehetleitner, Markus Maier,\nAnne M Scheel, Caroline Zygar-Hoffmann, Ramona Schoedel, Larissa Sust,\nLena Schiestel, and Malika Ihle. 2023. “Open Science Initiative in\nPsychology @LMU.” OSF. osf.io/mgwk8.\n\n\nSchönbrodt, Felix D., and Marco Perugini. 2013. “At What Sample\nSize Do Correlations Stabilize?” Journal of Research in\nPersonality 47 (5): 609–12. https://doi.org/10.1016/j.jrp.2013.05.009.\n\n\nSindermann, Cornelia, Peng Sha, Min Zhou, Jennifer Wernicke, Helena S.\nSchmitt, Mei Li, Rayna Sariyska, Maria Stavrou, Benjamin Becker, and\nChristian Montag. 2021. “Assessing the Attitude Towards\nArtificial Intelligence: Introduction of a\nShort Measure in German, Chinese,\nand English Language.” KI - Künstliche\nIntelligenz 35 (1): 109–18. https://doi.org/10.1007/s13218-020-00689-0.\n\n\nSong, Stephen Wonchul, and Mincheol Shin. 2022. “Uncanny\nValley Effects on Chatbot Trust,\nPurchase Intention, and Adoption Intention in\nthe Context of E-Commerce: The\nModerating Role of Avatar Familiarity.”\nInternational Journal of Human–Computer Interaction 0 (0):\n1–16. https://doi.org/10.1080/10447318.2022.2121038.\n\n\nSuh, Woong, and Seongjin Ahn. 2022. “Development and\nValidation of a Scale Measuring Student Attitudes\nToward Artificial Intelligence.” SAGE Open 12\n(2): 21582440221100463. https://doi.org/10.1177/21582440221100463.\n\n\nSuppes, Patrick. 1999. Introduction to Logic. Mineola,\nN.Y: Dover Publications.\n\n\nTavakol, Mohsen, and Reg Dennick. 2011. “Making Sense of\nCronbach’s Alpha.” International Journal of\nMedical Education 2 (June): 53–55. https://doi.org/10.5116/ijme.4dfb.8dfd.\n\n\nTheisen, Manuel René. 2021. Wissenschaftliches Arbeiten: erfolgreich\nbei Bachelor- und Masterarbeit. 18., neu bearbeitete und gekürzte\nAuflage. München: Verlag Franz Vahlen.\n\n\nVenkatesh, Viswanath, and Hillol Bala. 2008. “Technology\nAcceptance Model 3 and a Research Agenda on\nInterventions,” May. https://doi.org/10.1111/j.1540-5915.2008.00192.x.\n\n\nWalach, Harald, and Nikolaus von Stillfried. 2013. Psychologie:\nWissenschaftstheorie, philosophische Grundlagen und Geschichte: ein\nLehrbuch. 3., überarb. und erw. Aufl. Stuttgart:\nKohlhammer.\n\n\nWaldorf, M., M. Cordes, S. Vocks, and D. McCreary. 2016.\n“Deutschsprachige Drive for Muscularity Scale (DMS).”\nZusammenstellung sozialwissenschaftlicher Items und Skalen\n(ZIS). https://doi.org/10.6102/ZIS246.\n\n\nWard, Adrian F., Kristen Duke, Ayelet Gneezy, and Maarten W. Bos. 2017.\n“Brain Drain: The Mere Presence of\nOne’s Own Smartphone Reduces Available Cognitive\nCapacity.” Journal of the Association for Consumer\nResearch 2 (2): 140–54. https://doi.org/10.1086/691462.",
    "crumbs": [
      "Fertigstellen",
      "References"
    ]
  }
]