[
  {
    "objectID": "090-Modellieren.html#lernsteuerung",
    "href": "090-Modellieren.html#lernsteuerung",
    "title": "12Â  Auswerten: Modellieren",
    "section": "12.1 Lernsteuerung",
    "text": "12.1 Lernsteuerung\n\n12.1.1 Lernziele\n\nSie kÃ¶nnen die Modellformel Ihrer Forschungsfrage nennen.\nSie kÃ¶nnen Ihre Modellformel (korrekt) in R spezifizieren.\nSie kÃ¶nnen Ihr Modell in R berechnen und die Ausgabe interpretieren.\nSie kÃ¶nnen die GÃ¼ltigkeit bzw. die Grenzen der Aussagen Ihres Modells einschÃ¤tzen.\n\n\n\n12.1.2 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggstatsplot)  # Visualisierung\nlibrary(ggpubr)  # Visualisierung\nlibrary(rstanarm)  # Bayes\n\n\n\n12.1.3 Position im Lernpfad\nSie befinden sich im Abschnitt â€œAuswertenâ€ in AbbildungÂ 1.2. Behalten Sie Ihren Fortschritt im Projektplan im Blick, s. AbbildungÂ 1.3.\n\n\n12.1.4 Grundlagen der statischen Modellierung\nDie Grundlagen der statistischen Modellierung mit einem Fokus auf Bayes-Modellen kÃ¶nnen Sie hier nachlesen.\n\n\n12.1.5 Ãœberblick\nIn diesem Kapitel sind die grundlegenden Verfahren zur Modellierung und inferenzstatistischen Absicherung Ihrer Forschungsfragen angerissen. Die Darstellung zielt auf ein â€œso-gehtâ€™sâ€ ab, nicht auf eine vollstÃ¤ndige Darstellung aller AuswertungsmÃ¶glichkeiten.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#between-variable",
    "href": "090-Modellieren.html#between-variable",
    "title": "12Â  Auswerten: Modellieren",
    "section": "12.2 1 between-Variable",
    "text": "12.2 1 between-Variable\n\n12.2.1 Design\nSauer und Lustig (2023) untersuchten in einer Querschnittsstudie den Effekt des Wirkstoff Bringnixtin auf die fluide Intelligenz. Die Autoren nahmen an, dass der Wirkstoff den individuellen Wert der abhÃ¤ngigen Variable erhÃ¶hen wÃ¼rde.\nDer Ablauf (aus Sicht der Probandis) ist in AbbildungÂ 12.1 dargestellt. Intro fasst die BegrÃ¼ÃŸung der Probandis inkl. Informed Consent sowie Erfassung von soziodemografischen Variablen zusammen. g.0 und g.1 sind die zwei Stufen der UV (g wie Gruppe), wobei g.0 die Kontrollgruppe kodiert (Placebo, also Zuckerpille, kein Wirkstoff,) und g.1 die zweite Stufe, d.h. die Experimentalgruppe (hohe Dosis Bringtnixtin). y2 ist die Messung der AV (d.h. nach Gabe von Bringtnixtin), d.h. ein MaÃŸ der fluiden Intelligenz. outro meint die Verabschiedung der Probanden sowie einige Fragen zu Compliance.\nDie Hypothese lautet: \\(\\mu_{g.2} &gt; \\mu_{g.1}\\).\nIn Worten:\n\nWir erwarten, dass der Mittelwert der Experimentalgruppe hÃ¶her ist als der Mittelwert der Kontrollgruppe.\n\n\n\n\n\n\n\nflowchart LR\n  Intro --&gt; g.0\n  Intro --&gt; g.1\n  g.0 --&gt; y2\n  g.1 --&gt; y2\n  y2 --&gt; outro\n\n\n\n\nAbbildungÂ 12.1: Ablaufdiagramm der Bringtnixtin-Studie\n\n\n\n\n\nDer DAG des Experiments ist in AbbildungÂ 12.2 dargestellt.\n\n\n\n\n\n\n\n\nAbbildungÂ 12.2: DAG fÃ¼r der Bringtnixtin-Studie\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nIm DAG AbbildungÂ 12.2 ist u als Ursache von y2 angegeben. u steht hier stellvertretend fÃ¼r alle weiteren Ursachen von y2, vermutlich sind das sehr viele. Aber sie interessieren uns nicht. Daher kÃ¶nnen Sie u auch aus dem DAG weglassen. Streng genommen sollten Sie es sogar weglassen, denn im DAG zeigt man nur diejenigen Variablen, die fÃ¼r Ihre Hypothese von Belang sind. Da u keine Verbindung zum Pfad g -&gt; y2 hat, brauchen wir es fÃ¼r die Bestimmung des Kausaleffekts nicht zu berÃ¼cksichtigen.\\(\\square\\)\n\n\nDie Daten dieses Experiments sind hier zu beziehen:\n\nd_bringtnixtin_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/fopra/main/data/d_bringtnixtin.csv\"\nd_bringtnixtin &lt;- read_csv(d_bringtnixtin_path)\n\n Download \nDie Autoren der Studie geben an, dass die Daten in z-Einheiten skaliert sind.\n\n\n12.2.2 Deskriptive Analyse\n\nd_bringtnixtin %&gt;% \n  group_by(g) %&gt;% \n  summarise(iq_mw = mean(y2),\n            iq_sd = sd(y2)) \n\n\n\n\n\nTabelleÂ 12.1: Mittlere fluide Intelligenz nach der Bringtnixtin-Intervention in AbhÃ¤ngigkeit der Gruppe\n\n\n\n\n  \n\n\n\n\n\n\nDie deskriptiven Kennwerte sind in AbbildungÂ 12.3 bzw. AbbildungÂ 12.3 visualisiert. Das sieht nicht gerade nach einem groÃŸen Effekt aus â€¦1\n\nMit ggstatsplot\n\n\n\nggbetweenstats(\n  data = d_bringtnixtin,\n  x = g,\n  y = y2,\n  results.subtitle = FALSE  # keine Statistiken zeigen\n)\n\n\n\n\n\n\n\nAbbildungÂ 12.3: Fluide Intelligenz (y2) nach der Bringtnixtin-Intervention. g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)\n\n\n\n\n\n\n12.2.2.1 Mit ggpubr\n\nggboxplot(\n  data = d_bringtnixtin,\n  x = \"g\",\n  y = \"y2\"\n)\n\n\n\n\n\n\n\nAbbildungÂ 12.4: Fluide Intelligenz (y2) nach der Bringtnixtin-Intervention. g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)\n\n\n\n\n\n\n\n\n\nSowohl das R-Paket ggstatsplot als auch das R-Paket ggpubr bieten ansprechende Datenvisualisierung.2\n\n\n12.2.3 Modellierung\nWir berechnen ein lineares Modell mit der Modellformel y2 ~ g. Die Ergebnisse sind in TabelleÂ 13.5 zu sehen.\n\nm_bringtnixtin &lt;- stan_glm(y2 ~ g, data = d_bringtnixtin, refresh = 0, seed = 42)\nparameters(m_bringtnixtin)\n\n\n\nTabelleÂ 12.2: Parameter des Modells m_bringtnixtin\n\n\n\n\n  \n\n\n\n\n\n\nDer Gruppenunterschied wird auf das -0.77 geschÃ¤tzt; das ist der PunktschÃ¤tzer der UV g. Wenn wir nur eine Zahl nennen dÃ¼rften zu unserem Wissen zum Effekt von g, so wÃ¤re das unsere Zahl. Die Grenzen eines 95%-CI fÃ¼r die UV liegen bei -1.56 bzw. 0.02; diese beiden Werten markieren die Grenzen des IntervallschÃ¤tzers. Dieser Bereich enthÃ¤lt die Null, vgl. AbbildungÂ 12.5. Daher kann nicht ausgeschlossen werden, dass Bringtnixtin nix bringt. Anders gesagt: Die Nullhypothese kann nicht verworfen werden.\nDie Punkt- und IntervallschÃ¤tzer (95%-ETI) fÃ¼r Achsenabschnitt und Regressiongewicht von g sind in AbbildungÂ 12.5 visualisiert.\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: Ein PunktschÃ¤tzer schÃ¤tzt einen (unbekannten) Wert in der Population auf einen einzelnen Wert (daher â€œPunktâ€). Ein InterschÃ¤tzer schÃ¤tzt einen Wertebereich fÃ¼r diesen unbekannten Wert. \\(\\square\\)\n\n\n\nparameters(m_bringtnixtin) %&gt;% plot(show_intercept = TRUE)\n\n\n\n\n\n\n\nAbbildungÂ 12.5: Parameter des Modells m_bringtnixtin (95%-ETI)\n\n\n\n\n\n\nğŸ‘¨â€ğŸ« Frau Professor Lustig, wie kann das sein, dass sich die Hypothese nicht bestÃ¤tigt?\n\n\nğŸ‘©â€ğŸ« Herr Professor Sauer, auch ein negatives Ergebnis bringt die Wissenschaft weiter.\n\nMit dem Rope-Verfahren kann man testen, ob ein Bereich um die Null herum, also â€œNull plus-minus ein bisschenâ€ im Hauptbereich im Hauptbereich (95%-KI) enthalten ist.\nTesten wir eine Nullhypothese mit dem ROPE-Verfahren: rope(m_bringtnixtin), s. TabelleÂ 12.3 und AbbildungÂ 12.6.\n\n\n\n\nTabelleÂ 12.3: ROPE fÃ¼r Modell m_bringtnixtin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCI\nROPE_low\nROPE_high\nROPE_Percentage\nEffects\nComponent\n\n\n\n\n(Intercept)\n0.95\n-0.13\n0.13\n0.29\nfixed\nconditional\n\n\ng\n0.95\n-0.13\n0.13\n0.03\nfixed\nconditional\n\n\n\n\n\n\n\n\n\nplot(rope(m_bringtnixtin)) + scale_fill_okabeito()\n\n\n\n\n\n\n\nAbbildungÂ 12.6: ROPE fÃ¼r Modell m_bringtnixtin\n\n\n\n\n\nscale_fill_okabeito() ist eine Funktion aus dem Metapaket {easystats}.3 Das Farbschema nach Okabe und Ito ist gut geeignet, um nominal skalierte Farben zu kodieren (s. Details hier).\nDa sich das 95%-CI mit dem ROPE Ã¼berlappt, kann die Nullhypothese bzw. das ROPE (kein praktisch bedeutsamer Effekt) nicht ausgeschlossen werden.\nEine vergleichbare Information bietet uns die Kennzahl pd, s. TabelleÂ 13.5. Der Wert fÃ¼r g liegt bei ca. 0.97.\n\n\n\n\n\n\nHinweis\n\n\n\npd gibt die Wahrscheinlichkeit (laut Modell) an, dass der Effekt in der Population negativ bzw. positiv ist (d.h. gleich dem Vorzeichen des PunktschÃ¤tzers; in diesem Fall negativ).\\(\\square\\)\n\n\n\n\nDas Modell ist sicher ziemlich sicher, dass der Effekt von g (in der Population) negativ ist. Aber eine kleine Chance, dass der Effekt von g doch (ungefÃ¤hr) Null oder sogar positiv ist, bleibt.\n\nğŸ‘¨â€ğŸ« Frau Professor Lustig, oh je! Unser Wirkstoff Bringtnixtin bringt anscheinend gar nix!\n\n\nğŸ‘©â€ğŸ« Herr Professor Sauer, wir mÃ¼ssen erst einmal in Ruhe die Studie replizieren. Eine Schwalbe macht noch keinen FrÃ¼hling.\n\nBerechnen wir abschlieÃŸend noch eine standardisierte EffektstÃ¤rke, \\(RÂ²\\).\n\nr2(m_bringtnixtin)\n## # Bayesian R2 with Compatibility Interval\n## \n##   Conditional R2: 0.089 (95% CI [4.766e-09, 0.251])\n\nAlso etwa 9% erklÃ¤rte Varianz. Aber ist das viel oder wenig? Fragen wir Herr Cohen, der hat sich dazu mal Gedanken gemacht.\n\ninterpret_r2(.09)\n## [1] \"weak\"\n## (Rules: cohen1988)\n\nNach dieser EinschÃ¤tzung ist der Effekt von g also schwach.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#vorher-nachher-messung-1-between-variable",
    "href": "090-Modellieren.html#vorher-nachher-messung-1-between-variable",
    "title": "12Â  Auswerten: Modellieren",
    "section": "12.3 Vorher-Nachher-Messung, 1 between-Variable",
    "text": "12.3 Vorher-Nachher-Messung, 1 between-Variable\n\n12.3.1 Design\nSauer und Lustig (2023) fiel auf, dass es sinnvoller ist, zuerst die AV mittels eines Vortests zu messen, dann die Intervention anzuwenden, und dann nachher (Posttest) die AV wieder zu messen. Daher haben sie sowohl vor der Intervention (t1) als auch nach der Intervention (Gabe von Bringtnixtin), t2, die AV (y, Behaltensleistung) gemessen.\n\n\n\n\n\n\nHinweis\n\n\n\nEine Vorher-Nachher-Messung hat den Verteil, dass sie - im Gegensatz zur Nur-Nachher-Messung - unterschiedliche Ausgangswerte in der AV herausrechnet. Bei groÃŸen Gruppen wird sich bei einer randomisierten Zuweisung zu den Gruppen der Ausgangswert der AV angleichen. Bei nicht so groÃŸen Gruppen kann aber auch bei Randomisierung ein - mitunter erheblicher - Unterschied zwischen den Gruppen verbleiben. Findet man bei der Post-Messung einen Effekt, so kann es sein, dass dieser nicht auf die Intervention beruht, sondern auf die von vornherein vorhandenen Unterschieden zwischen den Gruppen.\\(\\square\\)\n\n\n\nVergleicht man die Delta-Werte zwischen zwei Gruppen, berechnet man die Differenz zwischen den Gruppen der Delta-Werte. Man spricht daher von einer Difference-in-Difference-Analyse.\\(\\square\\)\n\nAbbildungÂ 12.7 zeigt den Ablaufplan dieses Experiments.\n\n\n\n\n\n\nflowchart LR\n  Intro --&gt; y1\n  y1 --&gt; g.1\n  y1 --&gt; g.2\n  g.1 --&gt; y2\n  g.2 --&gt; y2\n  y2 --&gt; outro\n\n\n\n\nAbbildungÂ 12.7: Ablaufdiagramm der Bringtnixtin-Studie\n\n\n\n\n\nDAG des Experiments ist in AbbildungÂ 12.8 dargestellt.\n\n\n\n\n\n\n\n\nAbbildungÂ 12.8: DAG fÃ¼r der Bringtnixtin-Studie\n\n\n\n\n\n\n\n12.3.2 Deskriptive Analyse\nEine einfache (und sinnvolle) Art, solche Studiendesigns auszuwerten ist die Bildung einer Differenz-Variable4. Diese Differenzvariable gibt die VerÃ¤nderung der fluiden Intelligenz durch die Intervention an. Anders gesagt: Die Differenz ist die IQ-Wert einer Person nach der Intervention minus dem IQ-Wert vor der Intervention: \\(d = y_2 - y_1\\):\n\nd_bringtnixtin &lt;-\n  d_bringtnixtin %&gt;% \n  mutate(d = y2 - y1)\n\nSchauen wir uns die ersten paar d-Werte fÃ¼r jede der beiden Gruppen (g=0 bzw. g=1) an:\n\n\n\n\n\nid\ng\ny1\ny2\nd\n\n\n\n\n1\n0\n1.37\n1.41\n0.04\n\n\n2\n0\n-0.56\n-0.64\n-0.07\n\n\n3\n0\n0.36\n0.51\n0.15\n\n\n21\n1\n-0.31\n-0.71\n-0.41\n\n\n22\n1\n-1.78\n-2.08\n-0.30\n\n\n23\n1\n-0.17\n-0.39\n-0.22\n\n\n\n\n\n\nVielleicht ist es anschaulicher, wenn wir die Gruppe 0 in den Text Kontrollgruppe umbenennen und 1 in Experimentalgruppe:\n\nd_bringtnixtin &lt;-\n  d_bringtnixtin %&gt;% \n  mutate(g_text =\n           case_when(g == 0 ~ \"Kontrollgruppe\",\n                     g == 1 ~ \"Experimentalgruppe\"))\n\nHier sind die Mittelwerte fÃ¼r jede der beiden Gruppen:\n\nd_bringtnixtin %&gt;% \n  group_by(g_text) %&gt;%\n  summarise(d = mean(d))\n\n\n\n\nMittelwerte der VerÃ¤nderung der Behaltensleistung nach Gruppe\n\n\ng_text\nd\n\n\n\n\nExperimentalgruppe\n-0.30\n\n\nKontrollgruppe\n-1.82e-04\n\n\n\n\n\nDie deskriptiven Kennwerte sind in AbbildungÂ 12.9 dargestellt.\n\nggbetweenstats(\n  data = d_bringtnixtin,\n  x = g_text,\n  y = d,\n  results.subtitle = FALSE  # keine Statistiken zeigen\n)\n\n\n\n\n\n\n\nAbbildungÂ 12.9: VerÃ¤nderung der fluiden Intelligenz (d) in AbhÃ¤ngigkeit der Gruppe; g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)\n\n\n\n\n\n\n\n12.3.3 Modellierung\nWir modellieren (in m_bringtnixtin2) jetzt die VerÃ¤nderung d = y2 - y1 als AV; UV ist wieder g, s. TabelleÂ 12.4.\n\nm_bringtnixtin2 &lt;- stan_glm(d ~ g, data = d_bringtnixtin, refresh = 0, seed = 42)\nparameters(m_bringtnixtin2)\n\n\n\n\n\nTabelleÂ 12.4: Parameter von m_bringtnixtin2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-1.34e-03\n(-0.08, 0.08)\n51.42%\n1.000\n3934.00\nNormal (-0.15 +- 0.59)\n\n\ng\n-0.30\n(-0.41, -0.18)\n100%\n0.999\n4181.00\nNormal (0.00 +- 1.17)\n\n\n\n\n\n\n\n\nAbbildungÂ 12.10 zeigt die Parameterwerte fÃ¼r m_bringtnixtin2,\n\nplot(parameters(m_bringtnixtin2))\n\n\n\n\n\n\n\nAbbildungÂ 12.10: Parameterwerte von m_bringtnixtin2 (Intercept ist nicht dargestellt), 95%-ETI; die Null ist nicht enthalten, der Mittelwert ist negativ.\n\n\n\n\n\nWie man den Parameterwerten entnehmen kann, ist sich das Modell sehr sicher, dass der Effekt von Bringtnixtin negativ ist.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#beobachtungsstudien",
    "href": "090-Modellieren.html#beobachtungsstudien",
    "title": "12Â  Auswerten: Modellieren",
    "section": "12.4 Beobachtungsstudien",
    "text": "12.4 Beobachtungsstudien\nGÃ¤ngige Forschungsfragen fÃ¼r Beobachtungsstudien sind hier erlÃ¤utert.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#within-variable",
    "href": "090-Modellieren.html#within-variable",
    "title": "12Â  Auswerten: Modellieren",
    "section": "12.5 1 within-Variable",
    "text": "12.5 1 within-Variable\nEine Studie mit Vorher-Nachher-Messung setzt ein Within-Design um.\n\nBeispiel 12.1 (Statisches Diagramm vs.Â animiertes Diagramm) Ein Forschungsteam untersuch den Effekt der UV Visualisierungsart V (mit den zwei Stufen V.1 animiert und V.2 statisch) auf die Behaltensleistung (y) von Probanden. Nach jeder Bedingung wird die Behaltensleistung gemessen (anhand von 10 Wissensfragen, die jeweils als â€œrichtigâ€ oder â€œfalschâ€ bewertet wurden), mit y1 nach V.1 und y2 fÃ¼r V.2.\\(\\square\\)\n\n\n12.5.1 Design\nForschungsfrage:\n\nHat die Diagrammart einen Einfluss auf die Behaltensleistung? Anders gesagt: Unterscheiden sich die Diagrammarten in ihrem Einfluss auf die mittlere Behaltensleistung?\n\nDie zugehÃ¶rige statistische Hypothese kann man so formulieren: \\(\\bar{d} \\ne 0\\), wobei \\(d = y_1 - y_2\\). \\(d\\) misst also den Unterschied der Behaltensleistung von animierten und statischen Diagrammen, wobei positive Werte zugunsten von statischen Diagrammen sprechen.\nDie Modellformel lautet: d ~ 1, das ist ein Intercept-Modell, also ein Modell ohne PrÃ¤diktor. Uns interessiert, ob die Variable d im Mittelwert ungleich Null ist oder positiv (zugunsten statischer Diagramme) oder negativ (Behaltensleistung hÃ¶her bei animierten Diagrammen).\nDer Ablauf der Studie (aus Sicht der Probandis) ist in AbbildungÂ 12.11 dargestellt.\n\n\n\n\n\n\nflowchart LR\n  V.1 --&gt; y1 --&gt; V.2 --&gt; y2\n\n\n\n\nAbbildungÂ 12.11: Ablauf der Studie zur Behaltensleistung y2 in AbhÃ¤ngigkeit der Visualisierungsart V (Within-Variable)\n\n\n\n\n\nDer DAG des Experiments ist in AbbildungÂ 12.12 dargestellt.\n\n\n\n\n\n\n\n\nAbbildungÂ 12.12: DAG fÃ¼r die Studie zur Behaltensleistung y2 in AbhÃ¤ngigkeit des Visualiserungstyp V\n\n\n\n\n\n\n\n12.5.2 Deskriptive Analyse\nHier sind einige Spieldaten:\n\nd_within &lt;- \n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv\") %&gt;% \n  select(-c(y3, g)) # diese beiden Variablen ignorieren wir fÃ¼r den Augenblick\n\nhead(d_within)\n\n\n  \n\n\n\n Download \nWir berechnen d, was die zentrale Variable der Forschungsfrage ist.\n\nd_within &lt;-\n  d_within %&gt;% \n  mutate(d = y1 - y2)\n\nhead(d_within)\n\n\n  \n\n\n\nEs klingt trivial, aber man muss sich ein Bild von den Daten (hier d) machen, wortwÃ¶rtlich, s. AbbildungÂ 12.13.\n\ngghistostats(d_within,\n             x = d,\n             results.subtitle = FALSE  # verzichte auf zusÃ¤tzliche Statistiken\n             )\n\n\n\n\n\n\n\nAbbildungÂ 12.13: Die Verteilung von d: Die Behaltensleistung ist im Mittel besser fÃ¼r animierte Diagramme (in diesen Daten)\n\n\n\n\n\nDa d im Mittel negativ ist, ist der Mittelwert von y2 (animiert) hÃ¶her als der von y1 (statisch).\nLassen wir uns die deskriptiven Kennwerte ausgeben, s. TabelleÂ 12.5.\n\nd_within %&gt;% \n  describe_distribution(d)\n\n\n\n\n\nTabelleÂ 12.5: Statistiken fÃ¼r d\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nd\n-1.60\n2.63\n4\n(-9.00, 3.00)\n-0.55\n0.30\n40\n0\n\n\n\n\n\n\n\n\nUm die Daten noch anders visualisieren zu kÃ¶nnen, formen wir sie ins â€œlange Formatâ€ um.\n\nd_long &lt;-\n  d_within %&gt;% \n  pivot_longer(cols = c(y1, y2), names_to = \"time\", values_to = \"y\")\n\nHier ist ein Auszug aus der Tabelle:\n\nhead(d_long)\n\n\n  \n\n\n\nVisualisieren wir uns die Daten, s. AbbildungÂ 12.14.\n\nggwithinstats(\n  data = d_long,\n  x = time,\n  y = y,\n  results.subtitle = FALSE  # verzichte auf zusÃ¤tzliche Statistiken\n)\n\n\n\n\n\n\n\nAbbildungÂ 12.14: Der Unterschied in der Behaltensleistung pro Versuchsperson; im Durchschnitt ist der Wert bei y2 hÃ¶her als bei y1\n\n\n\n\n\n\n\n12.5.3 Inferenzanalyse\nWir berechnen das Modell (m_within),s. TabelleÂ 12.6:\n\nm_within &lt;- stan_glm(d ~ 1, data = d_within, refresh = 0, seed = 42)\nparameters(m_within)\n\n\n\n\n\nTabelleÂ 12.6: Modellparameter von m_within\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-1.59\n(-2.46, -0.69)\n100%\n1.000\n2536.00\nNormal (-1.60 +- 6.57)\n\n\n\n\n\n\n\n\nHier ist eine Visualisierung des 95%-ETI des Unterschieds (d) zwischen den beiden Bedingungen (AbbildungÂ 12.15).\n\nparameters(m_within) %&gt;% plot(show_intercept = TRUE)\n\n\n\n\n\n\n\nAbbildungÂ 12.15: 95%-CI fÃ¼r d (Achsenabschnitt mit Modell m_within)\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWenn Sie die parameters plotten und nur einen Intercept haben, mÃ¼ssen Sie mit show_intercept=TRUE einschalten, dass er gezeigt wird. Sonst gibt es eine Fehlermeldung.\\(\\square\\)\n\n\nWie man sieht, ist die Null nicht im CI enthalten. Wir kÃ¶nnen daher resÃ¼mieren, dass es einen Unterschied zwischen den Bedingungen (statisch vs.Â animiert) gibt hinsichtlich y2 (Behaltensleistung). Die Behaltensleistung animierter Diagramme ist der von statischen Diagrammen Ã¼berlegen (laut diesem Modell). Die exakte Nullhypothese ist zu verwerfen. NatÃ¼rlich kÃ¶nnte man jetzt noch ein Rope berechnen.\n\n\n12.5.4 Vertiefung\nIn diesem Blog-Post findet eine kleine Fallstudie zur Analyse von â€œVorher-Nachher-Datenâ€.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#within-variable-1-between-variable",
    "href": "090-Modellieren.html#within-variable-1-between-variable",
    "title": "12Â  Auswerten: Modellieren",
    "section": "12.6 1 within-Variable, 1 between-Variable",
    "text": "12.6 1 within-Variable, 1 between-Variable\n\n12.6.1 Design\nForschungsfrage:\n\nHat die Diagrammart einen Einfluss auf die Behaltensleistung? Anders gesagt: Unterscheiden sich die Diagrammarten in ihrem Einfluss auf die Behaltensleistung? Dabei kontrollieren wir die Reihenfolge.\n\nForschungspraktisch bedeutet das, dass es zwei Gruppen, g1 und g2 in diesem Experiment gibt. Diese beiden Gruppen definieren eine between-Variable, g, die die Reihenfolge der Darbietung kontrolliert, s. AbbildungÂ 12.16. Die Diagrammart D ist auch eine UV, aber als Within-Variable konzipiert.\n\n\n\n\n\n\nflowchart LR\n  subgraph g2\n    direction LR\n    V.1 --&gt; y1 --&gt; V.2 --&gt; y2\n  end\n  subgraph g1\n    direction LR\n    D2[V.2] --&gt; y22[y2] --&gt; D1[V.1] --&gt; y11[y1] \n  end\n\n\n\n\nAbbildungÂ 12.16: Ablaufdiagramm fÃ¼r die Studie mit der Modellgleichung mit einem Within- und einem Between-Faktor\n\n\n\n\n\nDa es zwei UVs gibt, gibt es auch zwei Hypothesen:\n\nH1: \\(\\bar{d} &lt; 0\\), mit \\(d = y_1 - y_2\\): Die mittlere Behaltensleistung ist in der Bedingung animiert hÃ¶her als in der Bedingung statisch.\nH2: \\(\\bar{d}_{g.1} = \\bar{d}_{g.2}\\): Der Unterschied in der Behaltensleistung zwischen den zwei Bedingung unterscheidet sich nicht von der Reihenfolge der Darbietung.\n\nDie Modellformel lautet: y ~ 1 + g. Das kann man synonym so schreiben: y ~ g. y meint die Behaltensleistung; statisch erfassen wir den Effekt auf y anhand des DifferenzmaÃŸes d.\nDer DAG des Experiments ist in AbbildungÂ 12.17 dargestellt.\n\n\n\n\n\n\n\n\nAbbildungÂ 12.17: DAG fÃ¼r die Studie mit der Modellgleichung mit einem Within- und einem Between-Faktor. Es wird kein Effekt fÃ¼r g erwartet (daher kein Pfeil von g auf y), wohl aber ein Effekt fÃ¼r V\n\n\n\n\n\n\n\n12.6.2 Deskriptive Analyse\nHier sind einige Spieldaten:\n\nd_within &lt;- \n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv\") %&gt;% \n  select(-c(y3)) # die  Variable `y3` ignorieren wir fÃ¼r den Augenblick\n\nhead(d_within)\n\n\n  \n\n\n\nWir berechnen d, der Unterschied zwischen den beiden Bedingungen:\n\nd_within &lt;-\n  d_within %&gt;% \n  mutate(d = y1 - y2)\n\nhead(d_within)\n\n\n  \n\n\n\nBetrachten wir den Unterschied von d zwischen den Gruppen (H2), s. AbbildungÂ 12.18.\n\nggbetweenstats(\n  d_within,\n  x = g,\n  y = d,\n  results.subtitle = FALSE\n)\n\n\n\n\n\n\n\nAbbildungÂ 12.18: Der Unterschied der Behaltensleistung (d) in AbhÃ¤ngigkeit von der Reihenfolge der Darbietung\n\n\n\n\n\nEs gibt einen gewissen Unterschied zwischen den beiden Reihenfolgen (A und B) wie AbbildungÂ 12.18 zeigt; die Reihenfolge kÃ¶nnte also einen Einfluss auf d haben. Aber wir mÃ¼ssen inferenzstatistisch prÃ¼fen, wie groÃŸ der Einfluss ist.\n\n\n12.6.3 Inferenzanalyse\nBerechnen wir m_within2, das nicht nur den Intercept prÃ¼ft (wie m_within1), sondern auch zusÃ¤tzlich den Effekt der Reihenfolge (g), vgl. TabelleÂ 12.7.\n\nm_within2 &lt;- stan_glm(d ~ g, data = d_within, refresh = 0, seed = 42)\n\n\n\n\n\nTabelleÂ 12.7: Modellparameter von m_within2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n-1.15\n(-2.33, -8.72e-03)\n97.60%\n0.999\n3902.00\nNormal (-1.60 +- 6.57)\n\n\ngB\n-0.89\n(-2.61, 0.73)\n86.28%\n1.000\n3684.00\nNormal (0.00 +- 12.98)\n\n\n\n\n\n\n\n\nDas CI fÃ¼r die Reihenfolge (Variable gB) beinhaltet die Null; Daher kann ein Nulleffekt der Reihenfolge - also kein Effekt der Reihenfolge - nicht ausgeschlossen werden, g=0 ist also im Bereich der plausiblen Werte.\nDer Effekt fÃ¼r d ((Intercept)) zeigt ein Intervall, das die Null (knapp) enthÃ¤lt. Daher kÃ¶nnen wir wir die Nullhypothese nicht mit hoher Sicherheit ausschlieÃŸen.\nIn Summe:\n\nH1 (HÃ¶here Behaltensleistung von animiert) konnte nicht bestÃ¤tigt werden, aber tendenziell fand sich ein Effekt in erwarteter Richtung (zugunsten einer hÃ¶heren Behaltensleistung von animiert).\nH2 (Reihenfolgeeffekt) konnte nicht bestÃ¤tigt werden.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#vertiefung-1",
    "href": "090-Modellieren.html#vertiefung-1",
    "title": "12Â  Auswerten: Modellieren",
    "section": "12.7 Vertiefung",
    "text": "12.7 Vertiefung\n\n12.7.1 1 within-Variable mit mehr als zwei Stufen\n VERTIEFUNG  - Sie kÃ¶nnen diesen Abschnitt ohne Gefahr ignorieren.\n\n\n12.7.2 Design\nEine Forscherin hat die Gesundheit (y) von Studentis drei Mal (t1, t2, t3) im Zeitraum eines Semesters untersucht.\nIhre Forschungsfrage lautet, ob sich die Gesundheit im Laufe des Semesters substanziell verÃ¤ndert. Ihre Hypothese lautet, dass die Werte Ã¼ber die Zeit hinweg stabil bleiben.\n\n\n12.7.3 Deskriptive Analyse\nHier sind einige Spieldaten:\n\nd_within &lt;- \n  read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv\")\n\nhead(d_within)\n\n\n  \n\n\n\nHier benÃ¶tigen wir die Daten in Langform:\n\nd_long &lt;-\n  d_within %&gt;% \n  pivot_longer(cols = y1:y3, names_to = \"time\", values_to = \"y\")\n\nhead(d_long)\n\n\n  \n\n\n\nEs hilft (wie meistens), sich die Daten zu visualisieren, s. AbbildungÂ 12.19.\np_y123_a &lt;-\n  d_long %&gt;% \n  ggplot(aes(x = time, y = y)) +\n  geom_jitter(width = .2)\n\np_y123_b &lt;-\n  ggwithinstats(d_long, \n                x = time,\n                y = y,\n                results.subtitle = FALSE)\n\np_y123_a\np_y123_b\n\n\n\n\n\n\n\n\n\n\n\n(a) Einfaches Punktediagramm\n\n\n\n\n\n\n\n\n\n\n\n(b) Informationsreiches Punkte-, Boxplot- und Violinendiagramm mit Statistiken der VerÃ¤nderung angereichert\n\n\n\n\n\n\n\nAbbildungÂ 12.19: Messwerte (y) in AbhÃ¤ngigkeit vom Messzeitpunkt (t1, t2, t3)\n\n\n\nBerechnen wir die Mittelwerte von y pro Messzeitpunkte sowie die VerÃ¤nderung von t1 zu t2 bzw. von t2 zu t3, s. TabelleÂ 12.8.\n\nd_long %&gt;% \n  group_by(time) %&gt;% \n  summarise(y_mean = mean(y)) %&gt;% \n  mutate(d = y_mean - lag(y_mean))\n\n\n\n\n\nTabelleÂ 12.8: Mittelwerte von y pro Messzeitpunkte (y_mean) sowie die VerÃ¤nderung von t1 zu t2 bzw. von t2 zu t3 (d)\n\n\n\n\n\n\ntime\ny_mean\nd\n\n\n\n\ny1\n5.45\n\n\n\ny2\n7.05\n1.60\n\n\ny3\n8.97\n1.92\n\n\n\n\n\n\n\n\n\n\n12.7.4 Inferenzanalyse\n\nm_within3 &lt;- stan_lmer(y ~ 1 + (1 | time), data = d_long, refresh = 0)\nsummary(m_within3)\n## \n## Model Info:\n##  function:     stan_lmer\n##  family:       gaussian [identity]\n##  formula:      y ~ 1 + (1 | time)\n##  algorithm:    sampling\n##  sample:       4000 (posterior sample size)\n##  priors:       see help('prior_summary')\n##  observations: 120\n##  groups:       time (3)\n## \n## Estimates:\n##                                       mean   sd   10%   50%   90%\n## (Intercept)                          7.2    1.2  5.8   7.2   8.5 \n## b[(Intercept) time:y1]              -1.7    1.2 -3.0  -1.7  -0.3 \n## b[(Intercept) time:y2]              -0.1    1.2 -1.5  -0.1   1.3 \n## b[(Intercept) time:y3]               1.8    1.2  0.4   1.8   3.2 \n## sigma                                1.5    0.1  1.3   1.4   1.6 \n## Sigma[time:(Intercept),(Intercept)]  4.7    5.1  1.1   3.1  10.2 \n## \n## Fit Diagnostics:\n##            mean   sd   10%   50%   90%\n## mean_PPD 7.2    0.2  6.9   7.2   7.4  \n## \n## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n## \n## MCMC diagnostics\n##                                     mcse Rhat n_eff\n## (Intercept)                         0.0  1.0  1181 \n## b[(Intercept) time:y1]              0.0  1.0  1201 \n## b[(Intercept) time:y2]              0.0  1.0  1225 \n## b[(Intercept) time:y3]              0.0  1.0  1179 \n## sigma                               0.0  1.0  2953 \n## Sigma[time:(Intercept),(Intercept)] 0.1  1.0  1501 \n## mean_PPD                            0.0  1.0  3725 \n## log-posterior                       0.1  1.0  1078 \n## \n## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nDie Schreibweise (1 | time) soll sagen, dass die Messwerte innerhalb von time verschachtelt sind und variieren. Die 1 sagt, dass es sich bei der variierenden GrÃ¶ÃŸe um den Intercept handelt, nicht um eine UV.\nEin â€œfixerâ€ Effekt ist ein Effekt, fÃ¼r den kein Pooling stattfindet, das ist hier der Intercept.\nNur die festen (fixed) Effekte kann man sich so ausgeben lassen:\n\nfixef(m_within3)\n## (Intercept) \n##    7.166984\n\nIm Durchschnitt werden ca. 7.1 Fragen richtig beantwortet (Gesamtmittel); das ist die Information die der PunktschÃ¤tzer des Intercepts bietet.\nNur die Random-Effekte kann man sich so ausgeben lassen:\n\nranef(m_within3)\n## $time\n##    (Intercept)\n## y1   -1.672117\n## y2   -0.123990\n## y3    1.760269\n## \n## with conditional variances for \"time\"\n\nDas sind jeweils die Abweichungen der Gruppenmittelwerte (y1, y2, y3) vom Gesamtmittel. Die Random-Effekte kann man sich visualisieren lassen, s. AbbildungÂ 12.20.\n\nplot(m_within3)\n\n\n\n\n\n\n\nAbbildungÂ 12.20: 95%-CI der Random-Effekte von m_within3\n\n\n\n\n\n\n\n12.7.5 Mediatoranalyse\nHier findet sich eine EinfÃ¼hrung in die Mediationsanalyse. Dieses R-Paket stellt ebenfalls komfortable Funktionen zur VerfÃ¼gung fÃ¼r Mediationsanalysen.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#fazit",
    "href": "090-Modellieren.html#fazit",
    "title": "12Â  Auswerten: Modellieren",
    "section": "12.8 Fazit",
    "text": "12.8 Fazit\nUnter Modellieren versteht man in der Forschungspraxis meist ein Regressionsmodell der Form av ~ uv. Die Inferenzstatistik hilft, die Modellparameter mit SchÃ¤tzwerten fÃ¼r die Population zu versehen.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "090-Modellieren.html#aufgaben",
    "href": "090-Modellieren.html#aufgaben",
    "title": "12Â  Auswerten: Modellieren",
    "section": "12.9 Aufgaben",
    "text": "12.9 Aufgaben\nSchauen Sie sich im Datenwerk die Aufgaben mit folgenden Tags an:\n\nresearch-question - researchdesign \ninference\nbayes\n\n\n\n\n\nSauer, Sebastian, und Ludwilla Lustig. 2023. â€The Effect of Bringtnixtin on Fluid Intelligence: A Randomized, Controlled Trialâ€œ. Journal for Fake Data 42 (1): 271â€“314.",
    "crumbs": [
      "Auswerten",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Auswerten: Modellieren</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#lernsteuerung",
    "href": "100-Statistiken-berichten.html#lernsteuerung",
    "title": "13Â  Auswerten: Berichten von Statistiken",
    "section": "13.1 Lernsteuerung",
    "text": "13.1 Lernsteuerung\n\n13.1.1 Lernziele\n\nSie kÃ¶nnen Ihre Forschungfrage mit Methoden der Inferenzstatistik nach Bayes auswerten.\n\n\n\n13.1.2 Position im Lernpfad\nSie befinden sich im Abschnitt â€œAuswertungâ€ in AbbildungÂ 1.2. Behalten Sie Ihren Fortschritt im Projektplan im Blick, s. AbbildungÂ 1.3.\n\n\n13.1.3 tl;dr\nIn diesem Kapitel wird folgende Frage beantwortet: â€œWie man die Ergebnisse einer Bayes-Analyse berichtetâ€\n\n\n13.1.4 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(rstanarm)\nlibrary(gt)  # optional\nlibrary(gtsummary)  # optional",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#warum-das-berichten-ihrer-analyse-wichtig-ist",
    "href": "100-Statistiken-berichten.html#warum-das-berichten-ihrer-analyse-wichtig-ist",
    "title": "13Â  Auswerten: Berichten von Statistiken",
    "section": "13.2 Warum das Berichten (Ihrer Analyse) wichtig ist",
    "text": "13.2 Warum das Berichten (Ihrer Analyse) wichtig ist\nStatistische Analysen kÃ¶nnen komplex und schwierig zu verstehen sein.1 Die Versuchung ist daher immer gegeben, beim Berichten einer Analyse wichtige Aspekte unerwÃ¤hnt oder unerklÃ¤rt zu lassen. LÃ¤sst man aber wichtige Informationen aus, steigt die Gefahr, dass die Analyse nicht nachvollziehbar ist. Am schÃ¶nsten ist dieses Problem im Cartoon mit den zwei Wissenschaftlern von einer Tafel (von Sidney Harris) dargestellt.\n\n\n\n\n\n\nWichtig\n\n\n\nStellen Sie sicher, dass Ihre Analyse nachvollziehbar ist. Andere Personen sollten Ihre Analyse auch ausfÃ¼hren kÃ¶nnen. Daher ist es wichtig, dass Sie Ihre Analyse zu Ihrer Studie einreichen (auÃŸerdem auch die Daten und Ihr Data-Dictionary).\\(\\square\\)",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#prinzipien-der-berichtlegung-von-bayes-statistik",
    "href": "100-Statistiken-berichten.html#prinzipien-der-berichtlegung-von-bayes-statistik",
    "title": "13Â  Auswerten: Berichten von Statistiken",
    "section": "13.3 Prinzipien der Berichtlegung (von Bayes-Statistik)",
    "text": "13.3 Prinzipien der Berichtlegung (von Bayes-Statistik)\nIm Folgenden sind einige Grundlagen des Berichtens von Statistiken dargestellt. Zwar wird in einigen Teilen auf die Bayes-Methode abgestellt, aber viele Teile gelten fÃ¼r alle statistischen Analysen. Dabei sei hinzugefÃ¼gt, dass Statistik, so nÃ¼chtern sie den geneigten Studenis auch erscheinen mag, durchaus Eitel- und PartikularitÃ¤ten aufweist: Nicht jeder Autor oder Dozent oder jede Richtlinie gibt die gleichen Anweisungen oder Empfehlungen! Die folgenden Hinweise entsprechen der (aktuellen, sich durchaus im Lauf der Zeit Ã¤ndernden) Sicht dieses Dozenten.\nDas erste Prinzip des Berichtlegens lautet â€œso viel wie nÃ¶tig, aber so wenig wie mÃ¶glichâ€. Man will die Lesis nicht Ã¼berfrachten, aber alle nÃ¶tigen Informationen Ã¼bermitteln. Das zweite Prinzip lautet, dass man die Informationen am rechten Ort vermittelt. So wird ei Lesi die ErklÃ¤rung der Zusammensetzung der Stichprobe nicht im Diskussionsteil vermuten und sich zu Recht wundern, im Methodenteil nichts zur Stichprobe zu finden. Das dritte Prinzip lautet, dass man priorisiert. Wichtiges in den Hauptteil, Details in den Anhang (bzw. in ergÃ¤nzende Datein, â€œsupplementary filesâ€). Detaillreiche Statistiken berichtet man eher in Tabellen; geht es um einen Ãœberblick, bietet sich hÃ¤ufig ein Diagramm an. Berichtet man im Text, so schreibt man auf â€œgut Deutschâ€ die Aussage in den Satz, und die Zahlen eher in Klammern dahinter. Das vierte Prinzip lautet, konsistent zu sein. Es gibt viele Wege nach Rom, bzw. viele AnsÃ¤tze, nÃ¼tzlich und effektiv - mithin â€œrichtigâ€ - zu berichten. Wichtiger als die Wahl einer bestimmten Art und Weise, ist es, konsistent zu sein, Ã¤hnlich wie beim Zitieren. Das fÃ¼nfte Prinzip, kÃ¶nnte man sagen, ist so selbstverstÃ¤ndlich, dass es keiner ErwÃ¤hnung bedarfe, aber die RealitÃ¤t lehrt uns leider mitunter das Gegenteil. Es lautet Lauterkeit oder Rechtschaffenheit. Kennzahlen bewusst falsch zu berichten rangiert irgendwo zwischen Straftat und beruflichem Fehlverhalten, je nach Kontext und kann harte Bestrafung verdienen. GÃ¤ngiger sicherlich sind subtilere Arten, dieses Prinzip zu verletzen. Dazu ist als erstes das selektive Berichten zu nennen: Unliebsame Befunde werden verschwiegen, hypothesenkonforme hingegen nach vorne gestellt. Das ist zwar dann nicht gelogen aber die IrrefÃ¼hrung wird bewusst in Kauf genommen.\nDie gute Nachricht fÃ¼r alle Studentis: Es gibt fÃ¼r Sie keinen Anreiz, die Ergebnisse â€œaufzuhÃ¼bschenâ€ (im Gegensatz zu Berufswissenschaftlis). Ihre Note wird nicht daran gemessen, ob Sie einen neuen Expoplaneten entdecken, oder sonstige â€œstarkeâ€ Ergebnisse aufweisen kÃ¶nnen. Nein! Unklare, nicht-bestÃ¤tigende oder unerwartete Ergebnisse sind genauso gut - auch wissenschaftlich Ã¼brigens haben sie die gleiche Daseinsberechtigung, wie die Ergebnisse, die im â€œJournal of Flashy Resultsâ€ fÃ¼r Presseberichte sorgen. FÃ¼r ihre Note ist es unerheblich, wie â€œsignifikantâ€, â€œeffektstarkâ€, â€œprÃ¤ziseâ€ oder â€œhypothesenkonformâ€ ihre Ergebnisse sind.\nEs ist hilfreich, im Sinne des vierten Prinzips (Konsistenz) sich nach einer bekannten, vielleicht sogar verbreiteten Nomenklatur bzw. Vorgehensweise zu richten. FÃ¼r Bayes-Analysen gibt es dazu Richtlinien und Checklisten; die folgenden Hinweise orientieren sich an Kruschke (2021), genannt BARG (Bayesian Analysis Reporting Guidelines); der Volltext ist hier zugÃ¤nglich. Auch die APA (American Psychological Assocation) hat eine Checkliste herausgegeben, wie Bayes-Statistik berichtet werden sollte.\nDie wichtigsten Ergebnisse der BARG sind in dieser Tabelle ausgelegt. Im folgenden wird eine Auswahl der BARG vorgestellt. Das Ziel ist nicht eine umfassende Darstellung mit einer hohen Tiefe der Exposition. Vielmehr soll - angepasst an den Kenntnissstand von Bachelor-Studentis - ein angemessener Ãœberblick ausgewÃ¤hlt werden. Ambitionierte Studentis sind aufgefordert, breite und tiefer als in der folgenden AusfÃ¼hrtung erlÃ¤utert, zu berichten. Die folgende AusfÃ¼hrung orientiert sich an der Standardgliederung wissenschaftlicher Berichte.\nLesis seien verwiesen auf das Buch von Jhangiani, Chiang, und Cuttler (2019), die einen hervorragenden Ãœberblick Ã¼ber die Materie vermitteln.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#allgemeine-richtlinien-zum-berichten-von-statistik",
    "href": "100-Statistiken-berichten.html#allgemeine-richtlinien-zum-berichten-von-statistik",
    "title": "13Â  Auswerten: Berichten von Statistiken",
    "section": "13.4 Allgemeine Richtlinien zum Berichten von Statistik",
    "text": "13.4 Allgemeine Richtlinien zum Berichten von Statistik\nDie APA hat eine Checkliste bzw. Richtlinie herausgegeben zum Berichten von Statistik (vgl. Cooper 2020). Die lesenswerten SchwesterbÃ¼ch von Jan Hendrik Peters und DÃ¶rfler (2019) bzw. Jan H. Peters und DÃ¶rfler (2015) geben nicht nur Formulierungshilfen, sondern erlÃ¤utern, wie man eine sinnvolle Gliederung erstellt und welche Inhalte in welchem Abschnitt gehÃ¶ren.\nGrundlegende Prinzipien des Berichtens von Statistiken sind:\n\nBegrÃ¼ndet: Eine ErlÃ¤uterung, warum ein Vorgehen gewÃ¤hlt wurde, wird gegeben.\nNachvollziehbar: Lesis kÃ¶nnen anhand des Berichts (potenziell) nachvollziehen, wie die Autoren zu einem Ergebnis gelangt sind.\nVon einfach zu komplex: Es ist verbreitet, zunÃ¤chst grundlegende Ergebnisse, dann komplexere Modellanalysen zu prÃ¤sentieren.\nDeskriptiv: Ergebnisse werden berichtet, aber nicht bewertet (das kommt erst im Diskussionsteil).\nLauter: Alle relevanten Ergebnisse werden offengelegt.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#theorieteil",
    "href": "100-Statistiken-berichten.html#theorieteil",
    "title": "13Â  Auswerten: Berichten von Statistiken",
    "section": "13.5 Theorieteil",
    "text": "13.5 Theorieteil\n\n13.5.1 Testen oder SchÃ¤tzen?\nAm Ende des Theorieteils bietet es sich an, die Hypothesen oder die Forschungsfrage zu spezifizieren. Sie kÃ¶nnen sich fÃ¼r eines von beiden entscheiden oder auch beides angehen.\nIn der bisherigen Literatur (in der Psychologie) werden zumeist Hypothesen getestet, nach dem Motto â€œjo, unsere Vermutung scheint zu stimmen!â€ oder â€œnein, das Zeugs taugt nix!â€. Das Problem ist, dass solches Denken etwas simpel ist, Schwarz-WeiÃŸ eben. AuÃŸerdem sind Nullhypothesen streng genommen immer falsch, weswegen es eigentlich keinen Sinn macht, sie zu untersuchen. Aber dafÃ¼r ist das Schwarz-WeiÃŸ-Denken schÃ¶n einfach.\nParameterschÃ¤tzung fragt nicht ob, sondern wieviel. Nicht viel komplizierter, aber viel nuancierter; (eigentlich) besser. AuÃŸerdem enthÃ¤lt das ParameterschÃ¤tzen auch das Hypothesentesten: Ist die Null im SchÃ¤tz-Intervall nicht enthalten, so kann man die Null-Hypothese ausschlieÃŸen.\n\n\n13.5.2 Modell definieren\nEs bietet sich auch an, ein Modell mit einem Pfaddiagramm bzw. DAG zu visualisieren, z.â€‰B. so, s. AbbildungÂ 13.1.\n\nlibrary(dagitty)\n\nmein_dag &lt;- 'dag {\nA [pos=\"-2.200,-1.520\"]\nB [pos=\"1.400,-1.460\"]\nD [outcome,pos=\"1.400,1.621\"]\nE [exposure,pos=\"-2.200,1.597\"]\nZ [pos=\"-0.300,-0.082\"]\nA -&gt; E\nA -&gt; Z [pos=\"-0.791,-1.045\"]\nB -&gt; D\nB -&gt; Z [pos=\"0.680,-0.496\"]\nE -&gt; D\n}'\n\n\nmein_modell &lt;- \"dag{\nlern -&gt; erfolg\nmot -&gt; erfolg\nmot -&gt; lern\n}\"\n\nplot(graphLayout(mein_modell))\n\n\n\n\n\n\n\nAbbildungÂ 13.1: Beispielhafter DAG\n\n\n\n\n\nDabei steht lern fÃ¼r â€œLernzeit in Stundenâ€, mot fÃ¼r â€œMotivationâ€ und lern fÃ¼r â€œLernerfolgâ€. Die Operationalisierung der Variablen sollten im Methodenteil genauer beschrieben sein.\nÃœbrigens: R-Quellcode sollte nicht im Hauptteil eines wissenschaftlichen Berichts stehen, verbannen Sie ihn in den Anhang (es sei denn, der Quellcode bzw. die Entwicklung von Syntax ist Gegenstand der Arbeit).\nAuÃŸerdem macht es Sinn, das Modell formal zu spezifizieren, etwa so:\n\\[\n\\begin{aligned}\n\\text{erfolg} &\\sim N(\\mu_i, \\sigma) \\qquad \\text{Likelihood} \\\\\n\\mu_i &= \\beta_0 + \\beta_1 \\text{lern} + \\beta_2 \\text{mot} \\qquad \\text{lineares Modell} \\\\\n\\beta_0 &\\sim N(0, 2.5)  \\qquad \\text{Prior Achsenabschnitt} \\\\\n\\beta_1 &\\sim N(0, 2.5)  \\qquad \\text{Prior Regressiongewicht lern} \\\\\n\\beta_2 &\\sim N(0, 2.5)  \\qquad \\text{Prior Regressiongewicht mot} \\\\\n\\sigma &\\sim Exp(1) \\qquad \\text{Prior Streuung} \\\\\n\\end{aligned}\n\\]\nWenn Sie das Modell mit STAN berechnen, also vermittelt Ã¼ber z.â€‰B. rstanarm, dann wÃ¤hlt stan_glm() fÃ¼r Sie folgende Priori-Werte:\n\n\\(\\beta\\)s: Normalverteilt mit Mittelwert 0 und SD 2.5\n\\(\\sigma\\): Exponentialverteilt mit Streckung 1\n\nDie \\(\\beta\\)s sind am einfachsten als z-Werte zu verstehen: Grob Ã¼bersetzt sagt rstanarm â€œMei, ich geh davon aus, dass der Effekt vermutlich 2.5-SD-Einheiten um den Mittelwert rum liegt, kÃ¶nnten auch etwas mehr sein, aber mehr als 5-SD-Einheiten sind schon echt unwahrscheinlichâ€. Das nennt man einen â€œschwach informativen Priorâ€: der erlaubt viel, aber den grÃ¶ÃŸten Quatsch schlieÃŸt er aus.\nPraktischerweise mÃ¼ssten sie nicht mal ihre Variablen z-tranformieren (aber Sie kÃ¶nnen ohne Schaden!), denn rstanarm macht das fÃ¼r Sie.\nTipp: Geben Sie an, dass Sie die Standardwerte (Voreinstellung) der von Ihnen verwendeten Software (wie rstanarm) verwendet haben. Zitieren Sie mÃ¶glichst die Software (in der verwendeten Version) und reichen Sie die Syntax ein.\nMehr zu Prioris bei rstanarm findet sich hier.\nMit prior_summary(mein_model) bekommt man einen Ãœberblick Ã¼ber die Prioriwerte, die im Modell mein_modell verwendet wurden.\nEs macht Sinn, zu begrÃ¼nden, warum sie das Modell so gewÃ¤hlt haben, wie sie es gewÃ¤hlt haben. Wenn Sie eine Normalverteilung fÃ¼r die Priori-Verteilungen wÃ¤hlen, haben Sie Argumentationslinien: epistemologisch und ontologisch. Epistemologisch kÃ¶nnen Sie argumentieren, dass die Normalverteilung die Entropie maximiert, also die Verteilung mit den wenigsten Vorannahmen ist, wenn man davon ausgeht, dass die gesuchte Verteilung Ã¼ber eine endliche Varianz und einen endlichen Mittelwert verfÃ¼gt. Ontologisch kÃ¶nnen Sie argumentieren, dass z.â€‰B. KÃ¶rpergrÃ¶ÃŸe (innerhalb eines Geschlechts zumindest) hinreichend normalverteilt ist.\nDie BegrÃ¼ndung fÃ¼r das lineare Modelle erschlieÃŸt sich aus der Theorie, nÃ¤mlich dass z.â€‰B. die gewÃ¤hlten UV den gesuchten Effekt gut beschreiben.\n\n13.5.2.1 Kausal- vs.Â Korrelationsmodell\nSie wollten weiterhin angeben, ob Ihre Forschungsfrage ein kausales Modell annimmt oder ein deskiptives (korrelatives). Bei einem kausalen Modell sollen dann die Pfeile Wirkungsrichtungen, also Ursache-Wirkungs-Beziehungen angeben.\nAuch wenn ihre Studie nicht die â€œKraftâ€ hat, Kausalbeziehungen (in GÃ¤nze) aufzudecken, ist es trotzdem meistens sinnvoll, ein Kausalmodell aufzustellen, da Theorien (und Praxis) meist an Kausalbeziehungen interessiert sind, und an Korrelationsbeziehungen wenig(er).\nViele wissenschaftliche Studien haben ein kausales Erkenntnisziel, nicht ein deskriptives.\n\n\n13.5.2.2 Hypothesen testen\nDas Testen der Hypothese ist eine Umsetzung der Idee, eine Behauptung einer empirisch-rationalen PrÃ¼fung zu unterziehen.\nEs bietet sich an, eine Hypothese zu wÃ¤hlen, wenn der Stand der Theorie dies erlaubt, idealerweise mehr als nur eine Null-Effekt-Hypothese, etwas \\(\\beta=0\\). Dass nÃ¤mlich ein Effekt exakt Null ist, erscheint fÃ¼r die meisten Situationen der Sozialwissenschaften reichlich unplausibel.\nSie sollten die Hypothese zuerst als Aussage formulieren, aber danach mÃ¶glichst mit mathematischen Symbolen prÃ¤zisieren (â€œstatistische Hypothesenâ€).\nHier sind Beispiele fÃ¼r statistische Hypothesen:\n\n\\(H: \\mu &gt; 0\\)\n\\(H: \\mu = 0\\)\n\\(H: \\mu \\ne 0\\)\n\\(H: \\beta &gt; 0\\)\n\\(H: d &gt; 0\\)\n\\(H: R^2 &gt; 0\\)\n\nDabei meint \\(\\beta\\) ein Regressiongewicht, \\(d\\) eine Differenz (zweier Gruppen) und \\(R^2\\) die erklÃ¤rte Varianz eines Modells.\n\\(R^2\\) als Kennzahl einer Hypothese ist interessant, weil es Ihnen erlaubt, ein ganzes Modell als Hypothese zu formulieren. Also â€œVerbundhypothesenâ€ aufzustellen, die mehr als eine oder zwei Variablen umfassen.\nMÃ¶chten Sie eine Hypothese zu einem Parameter testen, der einen Nullwert beinhaltet, bietet sich das ROPE-Verfahren an, vgl. Kruschke (2018).\n\n\n13.5.2.3 ParameterschÃ¤tzung\nBei einer ParameterschÃ¤tzung formulieren Sie ein Modell, genau wie beim Hypothesen testen, nur eben ohne Hypothesen. Es geht Ihnen dann nicht um die Frage, ob irgend ein Sachverhalt der Fall ist (das ist Hypothesen prÃ¼fen). Stattdessen interessieren Sie sich fÃ¼r die Frage, wie sehr etwas der Fall ist:\n\nâ€œWie stark ist der Zusammenhang von Lernzeit und PrÃ¼fungserfolg?â€\nâ€œUm wie viele Sekunden parken Frauen im Schnitt schneller ein als MÃ¤nner?â€\nâ€œWie groÃŸ ist der statistische Effekt eines Sportwagens auf einem mÃ¤nnlichen Profilbild beim Online-Dating?â€\n\nAuch hier ist es erlaubt und sinnvoll, eine sprachliche Frage, die oft vage ist, schon aufgrund der natÃ¼rlichen AmbuitÃ¤t der Sprache, mit Hilfe mathematischer Notation zu prÃ¤zisieren:\n\nâ€œDer Zusammenhang \\(\\beta\\) ist definiert als das Regressiongewicht der Variable lern im Modell m1.\nâ€œOperationalisiert wurde die Einparkgeschwindigkeit als die Dauer der DurchfÃ¼hrung in Sekunden nach Instruktion wie im Abschnitt XYZ beschrieben. Unser Modell (m1) schÃ¤tzte den Parameter s.\nâ€œDer statistische Effekt ist definiert als das Regressiongewicht der experimentellen Bedingung (binÃ¤re Variable group) im Modell m1.\n\nGeben Sie weiter an, welches Intervall Sie berichten, z.â€‰B. â€œDie ParameterschÃ¤tzungen werden anhand eines 95%-HDI berichtetâ€.\nAuch wenn Sie eine Hypothese testen, sollten Sie BereichsschÃ¤tzungen fÃ¼r die Parameter vornehmen, also SchÃ¤tzbereiche aus der Posteriori-Verteilung berichten.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#methodenteil",
    "href": "100-Statistiken-berichten.html#methodenteil",
    "title": "13Â  Auswerten: Berichten von Statistiken",
    "section": "13.6 Methodenteil",
    "text": "13.6 Methodenteil\n\n13.6.1 Analyse\n\n13.6.1.1 Bayes erklÃ¤ren\n\nErklÃ¤ren Sie, warum Sie eine Bayes-Analyse verwenden und nicht eine frequentistische. Eine ehrliche Antwort wÃ¤re zwar, â€œmein Dozent wollte es so, was bleibt mir groÃŸ Ã¼brigâ€, aber es gibt (vermutlich?!) auch fachliche GrÃ¼nde (z.â€‰B.: Eine Priori-Annahme zur Wahrscheinlichkeit eines Parameters wird durch Daten zu einer Wahrscheinlichkeit verschoben). Die sollten sie anfÃ¼hren.\nErklÃ¤ren, was eine Bayes-Analyse ist. (Man bekommt Wahrscheinlichkeiten fÃ¼r Hypothesen, was man beim Frequentismus nicht bekommt.)\nFÃ¼hren Sie an, ob Sie an einer ParameterschÃ¤tzung oder einer Hypothesentestung interessiert sind. Die ParameterschÃ¤tzung ist oft zu bevorzugen, da informationsreicher.\n\nBayes-Statistiken sollten Sie im kurz erlÃ¤utern, da sie vielen Lesis nicht so gut vertraut sein wird.\nSie kÃ¶nnen z.â€‰B. bei Kruschke (2018)â€ die Grundlagen des ROPE-Konzepts nachlesen. Vielleicht findet sich ja auch in Ihrem Statistik-Skript etwas Passendes?\n\n\n13.6.1.2 ROPE\nKurz gesagt wird beim ROPE geprÃ¼ft, welcher Anteil des Posteriori-Intervalls zu einem Bereich â€œvernachlÃ¤ssigbar kleinerâ€ Parameterwerte bewegt. Die folgende Abbildung illustriert ein Rope fÃ¼r die Forschungsfrage â€œWie stark ist der Effekt der Zylinderzahl auf den Spritverbrauch?â€; genauer gesagt ist die Posteriori-Verteilung fÃ¼r den (Regressions-)Effekt, \\(\\beta\\), des Parameters cyl gezeigt. Wie man sieht, ist die Posteriori-Verteilung (glockenfÃ¶rmige Verteilung) komplett auÃŸerhalb des Bereichs â€œsehr kleinerâ€ Werte (ROPE; blaues Rechteck rechts). Wir resÃ¼mieren: â€œEs ist auszuschlieÃŸen, dass der Effekt der Variable Zylinder auf den Spritverbrauch praktisch Null (sehr klein) istâ€.\nWenn man die Null bzw. den Nullbereich (ROPE) eines Parameters ausschlieÃŸt, nennt man das Ergebnis bzw. den Effekt auch â€œsignifikantâ€ (leider ein hÃ¤ufig missbrauchter und missverstandener Begriff). Unser Effekt in diesem Beispiel ist also signifikant (nach dieser Definition). Besser ist es aber, wenn Sie den Begriff vermeiden, und stattdessen davon sprechen, dass Sie einen Effekt gefunden haben (oder nicht oder dass eine unklare Ergebnislage vorliegt). Haben Sie einen Effekt gefunden, so heiÃŸt das synonym, dass die Nullhypothese ausgeschlossen ist (falsifiziert ist), natÃ¼rlich immer auf Basis des vorliegenden Modells bzw. der vorliegenden Daten.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#ergebnisteil",
    "href": "100-Statistiken-berichten.html#ergebnisteil",
    "title": "13Â  Auswerten: Berichten von Statistiken",
    "section": "13.7 Ergebnisteil",
    "text": "13.7 Ergebnisteil\n\n13.7.1 Deskriptive Statistik\n\n13.7.1.1 Was soll ich schreiben?\nBevor Sie die Ergebnisse Ihrer Modellierung zeigen, bietet sich etwas â€œAufwÃ¤rmenâ€ an, vor dem FuÃŸballspiel wÃ¤rmt man sich ja auch erstmal auf. Dazu bieten sich die deskriptiven Statistiken zu Ihren Daten an.\nHÃ¤ufig wird man ein MaÃŸ der zentralen Tendenz (Mittelwert oder Median) sowie ein dazu passendes StreuungsmaÃŸ berichten (z.â€‰B. SD) berichten. Evtl. kann man ein MaÃŸ zur PrÃ¤zision des Mittelwerts angeben (SE). Bei schiefen Verteilungen greift man meist auf robuste Kennwerte zurÃ¼ck; bei normalverteilten Verteilungen ist Mittelwert und SD die Statistik der Wahl. Die StichprobengrÃ¶ÃŸe sollte klar sein; liegen fehlende Werte vor, so sollte pro Kennzahl jeweils die effektive StichprobengrÃ¶ÃŸe berichtet sein. Ansonsten reicht es, die StichprobengrÃ¶ÃŸe an einer Stelle (im Text) anzufÃ¼hren.\nGÃ¤ngige statistische Symbole sollen nicht definiert werden, z.â€‰B. M, SD, F, t, df, N, n, OR. Andere statistischen AbkÃ¼rzungen, die weniger gebrÃ¤uchlich sind, sollten definiert bzw. auf die Definition verwiesen werden, z.â€‰B. pd, ROPE.\nFormulierungsvorschlag\n\nDer mittlere Achtsamkeits-Wert lag in der Stichprobe bei M = 12.23 (SD = 1.23).\n\n\nDie Reaktionszeit in der Experimentalbedingung war hÃ¶her als in der Kontrollbedingung (Experimentalbedingung: M = 2.7, SD = 0.3; Kontrollbedingung: M = 0.1, SD = 0.4).\n\n\nEs fand sich eine starke Korrelation zwischen Achtsamkeit und Lebenszufriedenheit, r(134) = .42, 95% CI [.32, .52].\n\nHat man eine grÃ¶ÃŸere Zahl an Statistiken, so bietet es sich an, die Ergebnisse nicht im FlieÃŸtext, sondern in einer Tabelle zu berichten. Berichtet man Ergebnisse in einer Tabelle, so doppelt man sie nicht im Text.\nEine nÃ¼tzliche ErgÃ¤nzung ist es, zusÃ¤tzlich zu den univariaten Statistiken noch Zusammenhangskoeffizienten (Korrelationen) zu berichten.\n\n\n13.7.1.2 Tabellen mit R\nIm folgenden sind MÃ¶glichkeiten aufgezeigt, wie Sie Tabellen mit R fÃ¼r Ihren Bericht erstellen kÃ¶nnen. Bitte behalten Sie im Blick, dass in einem deutschsprachigen Bericht die Variablen- und Kennzahlennamen in deutscher Sprache erscheinen sollten. Auf â€œtechnischâ€ anmutenden AbkÃ¼rzungen (z.â€‰B. mpg_sd) sollten man verzichten zugunsten â€œsprechendererâ€ Formulierengen (z.â€‰B. SD Spritverbrauch, oder SD MPG, wenn â€œMPGâ€ in der FuÃŸnote der Tabelle definiert ist). Tabellen sollten fÃ¼r sich selber verstÃ¤ndlich sein, ohne Bezug zum Text.\nMit gÃ¤ngigen R-Methoden kann man sich deskriptive Statistiken ausgeben lassen, s. TabelleÂ 13.1.\n\nmtcars %&gt;% \n  summarise(mpg_avg = mean(mpg),\n            mpg_sd = sd(mpg),\n            cor_mpg_hp = cor(mpg, hp)) %&gt;% \n  rename(`MW Spritverbrauch` = mpg_avg,\n         `SD Spritverbrauch`= mpg_sd,\n         `Korrelation Spritverbrauch mit PS-Zahl` = cor_mpg_hp)\n\n\n\nTabelleÂ 13.1: Einfache Tabelle mit deskriptiven Statistiken\n\n\n\n\n  \n\n\n\n\n\n\nAlternativ zu selbsterstellten Tabellen kann â€œStatistik-Fast-Foodâ€ konsumieren und lÃ¤sst sich einen Haufen Zahlen auf einmal ausgeben. R-Pakete wie r_statix, skimr oder easystats helfen dabei, s. als Beispiel TabelleÂ 13.2.\n\nlibrary(easystats)\n\ndescribe_distribution(mtcars) %&gt;% \n  select(-n, -n_Missing) %&gt;% \n  rename(MW = Mean, Schiefe = Skewness)\n\n\n\n\n\nTabelleÂ 13.2: Einfache Tabelle mit describe_distribution aus easystats\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMW\nSD\nIQR\nRange\nSchiefe\nKurtosis\n\n\n\n\nmpg\n20.09\n6.03\n7.53\n(10.40, 33.90)\n0.67\n-0.02\n\n\ncyl\n6.19\n1.79\n4.00\n(4.00, 8.00)\n-0.19\n-1.76\n\n\ndisp\n230.72\n123.94\n221.53\n(71.10, 472.00)\n0.42\n-1.07\n\n\nhp\n146.69\n68.56\n84.50\n(52.00, 335.00)\n0.80\n0.28\n\n\ndrat\n3.60\n0.53\n0.84\n(2.76, 4.93)\n0.29\n-0.45\n\n\nwt\n3.22\n0.98\n1.19\n(1.51, 5.42)\n0.47\n0.42\n\n\nqsec\n17.85\n1.79\n2.02\n(14.50, 22.90)\n0.41\n0.86\n\n\nvs\n0.44\n0.50\n1.00\n(0.00, 1.00)\n0.26\n-2.06\n\n\nam\n0.41\n0.50\n1.00\n(0.00, 1.00)\n0.40\n-1.97\n\n\ngear\n3.69\n0.74\n1.00\n(3.00, 5.00)\n0.58\n-0.90\n\n\ncarb\n2.81\n1.62\n2.00\n(1.00, 8.00)\n1.16\n2.02\n\n\n\n\n\n\n\n\nTabellen mit flextable(), gtsummary oder gt() kann man sich eine schicke Tabelle (im HTML-Format) ausgeben lassen, die man dann per Copy-Paste in Word, d.h. den eigene Forschungsbericht, Ã¼bernehmen kann. s. TabelleÂ 13.3.\n\nlibrary(gt)  # gt wie \"grammer of tables\"\n\nmeine_tab &lt;- \n  describe_distribution(mtcars) %&gt;% \n  gt() %&gt;%  # erzeugt schicke Tabelle\n  fmt_number(where(is.numeric), decimals = 2) # Anzahl der Dezimalstellen\n\nmeine_tab\n\n\n\nTabelleÂ 13.3: Deskriptive Statistiken mit gt\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nmpg\n20.09\n6.03\n7.53\n10.40\n33.90\n0.67\nâˆ’0.02\n32.00\n0.00\n\n\ncyl\n6.19\n1.79\n4.00\n4.00\n8.00\nâˆ’0.19\nâˆ’1.76\n32.00\n0.00\n\n\ndisp\n230.72\n123.94\n221.53\n71.10\n472.00\n0.42\nâˆ’1.07\n32.00\n0.00\n\n\nhp\n146.69\n68.56\n84.50\n52.00\n335.00\n0.80\n0.28\n32.00\n0.00\n\n\ndrat\n3.60\n0.53\n0.84\n2.76\n4.93\n0.29\nâˆ’0.45\n32.00\n0.00\n\n\nwt\n3.22\n0.98\n1.19\n1.51\n5.42\n0.47\n0.42\n32.00\n0.00\n\n\nqsec\n17.85\n1.79\n2.02\n14.50\n22.90\n0.41\n0.86\n32.00\n0.00\n\n\nvs\n0.44\n0.50\n1.00\n0.00\n1.00\n0.26\nâˆ’2.06\n32.00\n0.00\n\n\nam\n0.41\n0.50\n1.00\n0.00\n1.00\n0.40\nâˆ’1.97\n32.00\n0.00\n\n\ngear\n3.69\n0.74\n1.00\n3.00\n5.00\n0.58\nâˆ’0.90\n32.00\n0.00\n\n\ncarb\n2.81\n1.62\n2.00\n1.00\n8.00\n1.16\n2.02\n32.00\n0.00\n\n\n\n\n\n\n\n\n\n\nAus APA-Sicht wÃ¼rde vermutlich MW und SD genÃ¼ge tun (sofern man von normalverteilten Variablen) ausgeht. Allerdings schadet es auch nicht, zusÃ¤tzliche Kennwerte anzugeben. Verzichten sollte man aber vermutlih - in diesem Fall - auf die Spalte n_Missing, da die Spalte keine Information birgt.\nSo sieht eine Tabelle mit gtsummary aus, s. TabelleÂ 13.4. Hier wird die HÃ¤ufigkeitsanalyse gezeigt.\n\nlibrary(gtsummary)\nmtcars %&gt;% \n  select(mpg, cyl) %&gt;% \n  tbl_summary()\n\n\n\nTabelleÂ 13.4: Deskriptive Statistiken mit gtsummary\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 321\n\n\n\n\nmpg\n19.2 (15.4, 22.8)\n\n\ncyl\n\n\n\n\nÂ Â Â Â 4\n11 (34%)\n\n\nÂ Â Â Â 6\n7 (22%)\n\n\nÂ Â Â Â 8\n14 (44%)\n\n\n\n1 Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\n\n\nHier findet sich noch mehr zum Thema Exportieren von Tabellen aus R nach Word.\nEine tidy Korrelationstabelle kann man sich z.â€‰B. (mit easystats, aber es gibt mehrere R-Pakete fÃ¼r diesen Zweck) so ausgeben lassen:\n\nmeine_cor_tab &lt;-\n  mtcars %&gt;% \n  select(mpg, hp, disp) %&gt;% \n  correlation()\n\nmeine_cor_tab %&gt;% print_md()\n\n\nCorrelation Matrix (pearson-method)\n\n\nParameter1\nParameter2\nr\n95% CI\nt(30)\np\n\n\n\n\nmpg\nhp\n-0.78\n(-0.89, -0.59)\n-6.74\n&lt; .001***\n\n\nmpg\ndisp\n-0.85\n(-0.92, -0.71)\n-8.75\n&lt; .001***\n\n\nhp\ndisp\n0.79\n(0.61, 0.89)\n7.08\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 32\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nMit print_md erreicht man, dass die Tabelle in schÃ¶nerem Markdown-Format gedruckt wird. Da Markdown sich problemlos in HTML- oder Word-Format konvertieren lÃ¤sst, kann man auf diese Art schÃ¶ner formatierte Tabellen erhalten (als mit dem Standard von describe_distribution and friends). gt ist allerdings schon von Natur aus schÃ¶n.\\(\\square\\)\n\n\nMÃ¶chte man eine quadratische Korrelationstabelle (was der Ã¼blicheren Berichtsform entspricht) kann man das so bekommen:\n\nsummary(meine_cor_tab) %&gt;% \n  gt() %&gt;%  # machen wir gleich eine schicke HTML-Tabelle\n  fmt_number(where(is.numeric), decimals = 2)\n\n\n\n\n\n\n\nParameter\ndisp\nhp\n\n\n\n\nmpg\nâˆ’0.85\nâˆ’0.78\n\n\nhp\n0.79\nNA\n\n\n\n\n\n\n\nVergessen Sie nicht, das Tabellen (genau wie Abbildungen) im Text zu referenzieren sind.\n\n\n\n13.7.2 Diagramme exportieren\nDiagramme, die Sie mit ggplot erstellt haben, kÃ¶nnen Sie z.â€‰B. mit dem Befehl ggsave in eine Datei speichern (z.â€‰B. im Format PNG oder PDF).\nInteressant kÃ¶nnte fÃ¼r Sie auch das Paket qwraps2 sein, das u.a. einen Formulierungsvorschlag erstellt, wie man Statistiken im FlieÃŸtext anfÃ¼hrt. Betrachten wir ein Beispiel mit mtcars. Sagen wir, wir mÃ¶chten den mittleren Spritverbrauch berichten.\n\nlibrary(qwraps2)\n\nmean_sd(mtcars$mpg)\n## [1] \"20.09 $\\\\pm$ 6.03\"\n\nDas Zeichen $\\\\pm$ steht fÃ¼r â€œPlus-Minusâ€ Â± (im Formelmodus). In Word sollten Sie es hÃ¤ndisch durch den Glyphen (das Zeichen) â€œÂ±â€ ersetzen.2\n\n\n13.7.3 Inferenzstatistik\nEs empfiehlt sich, die Modellgleichung inkl. Prior-Spezifiaktion aufzufÃ¼hren.\n\n13.7.3.1 Posteriori-Verteilung\nFÃ¼r jede Hypothese mÃ¼ssen Sie die zentralen Ergebnisse berichten. Die Hypothesen beziehen sich auf Populationen, also benÃ¶tigen wir Inferenzstatistik. In der frequentistischen Statistik finden hier Statistiken wie der p-Wert und das (frequentistische) Konfidenzintervall Verwendung. In einer Bayes-Analyse ist die Posteriori-Verteilung der Dreh- und Angelpunkt der Ergebnisse.\nDie Post-Verteilung gibt an, wie wahrscheinlich ein bestimmter Parameterwert jetzt ist, nachdem die Daten bekannt sind.\nEin statistisches Modell wird zumeist mit einem Regressionsmodell umgesetzt. Ein Regressionsmodell kann man in R mit lm() (frequentistisch) oder z.â€‰B. stan_glm() (Bayes) berechnen. Die Syntax ist sehr Ã¤hnlich.\n\n\n13.7.3.2 Umsetzung in R\nSie kÃ¶nnen eine Posteriori-Verteilung z.â€‰B. fÃ¼r ihr Modell berechnen:\n\nlibrary(rstanarm)\n\nm1 &lt;- stan_glm(mpg ~ am, data = mtcars, seed = 42)\n\nHier sind die Ergebnisse; noch nicht ganz poliert fÃ¼r einen APA-Bericht, s. TabelleÂ 13.5.\n\nparameters(m1, prob = .95) %&gt;% \n  print_md()\n\n\n\nTabelleÂ 13.5: Parameter fÃ¼r das Modell m1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n17.14\n(14.85, 19.51)\n100%\n0.999\n3739.00\nNormal (20.09 +- 15.07)\n\n\nam\n7.21\n(3.72, 10.70)\n99.95%\n0.999\n3755.00\nNormal (0.00 +- 30.20)\n\n\n\n\n\n\n\n\nWir bekommen ein 95%-Perzentilintervall (PI, kein HDI, ist aber auch ok, allerdings ist das HDI einen Tick besser). Es erlaubt uns zu sagen, dass der Unterschied im Spritverbrauch zwischen 3.6 und 11 Meilen (pro Gallone Sprit) liegt, laut dem Modell. Der Schalter prob erlaubt, andere CI-Breiten, z.â€‰B. 97% zu wÃ¤hlen.\nEin HDI bekommen Sie, wenn Sie bei ci_method den Wert \"hdi wÃ¤hlen; oder wenn Sie gleich den Befehl hdi(m1) ausfÃ¼hren, s. TabelleÂ 13.6.\n\nparameters(m1, prob = .95, ci_method = \"hdi\") %&gt;% print_md()  # oder: hdi(m1)\n\n\n\nTabelleÂ 13.6: Parameter fÃ¼r das Modell m1. Das Intervall ist ein HDI.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\n95% CI\npd\nRhat\nESS\nPrior\n\n\n\n\n(Intercept)\n17.14\n(14.95, 19.59)\n100%\n0.999\n3739.00\nNormal (20.09 +- 15.07)\n\n\nam\n7.21\n(3.67, 10.62)\n99.95%\n0.999\n3755.00\nNormal (0.00 +- 30.20)\n\n\n\n\n\n\n\n\nDie Tabelle kÃ¶nnen Sie natÃ¼rlich auch gleich wieder aufhÃ¼bschen, fÃ¼r Ihren Bericht, s. TabelleÂ 13.7.\n\nhdi(m1) %&gt;% \n  select(Parameter, CI_low, CI_high) %&gt;% \n  gt() %&gt;% \n  fmt_number(where(is.numeric), decimals = 2)\n\n\n\nTabelleÂ 13.7: Parameter fÃ¼r das Modell m1. Das Intervall ist ein HDI.\n\n\n\n\n\n\n\n\n\nParameter\nCI_low\nCI_high\n\n\n\n\n(Intercept)\n14.95\n19.59\n\n\nam\n3.67\n10.62\n\n\n\n\n\n\n\n\n\n\nEin Ã¤hnliches Ergebnis erzielt man mit dem Paket gtsummary, s. TabelleÂ 13.8.\n\ntbl_regression(m1)\n\n\n\nTabelleÂ 13.8: Parameter fÃ¼r das Modell m1.\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\n\n\n\n\nam\n7.2\n3.7, 11\n\n\n\n1 CI = Credible Interval\n\n\n\n\n\n\n\n\n\n\n\nDen PunktschÃ¤tzer (Median) zum Unterschied fÃ¼r die Gruppen (Automatik vs.Â Schaltgetriebe) hat uns die Funktion parameters() auch geliefert. Der Unterschied zwischen den beiden Gruppen liegt laut Modell bei ca. 7.2 Meilen.\nIm Bericht kÃ¶nnte man z.â€‰B. schreiben:\nFormulierungsvorschlag\n\nDer Unterschied im Spritverbrauch zwischen den beiden Gruppen (Automatik vs.Â Schaltgetriebe) wurde auf 7.2 Meilen geschÃ¤tzt, 95% PI [3.7, 11.0].\n\nWeiter macht es Sinn zu Ã¼berlegen, ob Sie den Effekt fÃ¼r â€œkleinâ€ oder â€œgroÃŸâ€ halten. Das ist eine subjektive Frage, die Sie am besten auf Basis theoretischer (nicht statistischer) Ãœberlegungen entscheiden. Am besten Sie erwÃ¤hnen im Methodenteil, was Sie als â€œkleinenâ€ und â€œgroÃŸenâ€ Effekt einschÃ¤tzen. So kÃ¶nnten Sie argumentieren, dass ein Unterschied von 1 Meile â€œkleinâ€ ist und 5 Meilen â€œgroÃŸâ€. Demnach sprechen unsere Ergebnisse deutlich gegen einen kleinen Effekt und sind gut mit einem â€œgroÃŸenâ€ Effekt kompatibel.\nEs bietet sich an, die Parameter-SchÃ¤tzbereiche zu visualisieren. Das kann man z.â€‰B. so machen:\n\nparameters(m1) %&gt;% plot(show_intercept = TRUE)\n\n\n\n\n\n\n\n\nDer Schalter show_intercept regelt, ob der SchÃ¤tzwert fÃ¼r den Achsenabschnitt gezeigt werden soll oder nicht.3\nMÃ¶chte man verschiedenen Regressiongsgewichte vergleichen, bietet es an, diese vorab zu standardisieren mit der z-Transformation.\nMehr zur Analyse mit rstanarm findet sich z.â€‰B. hier oder bei Gelman, Hill, und Vehtari (2021).\nÃœbrigens kann man ein hdi() auch plotten, wenn man mÃ¶chte:\n\nplot(hdi(m1))\n\nSieht auch ganz schick aus; im Hintergrund wird {easystats} zum Plotten verwendet. Praktischerweise ist es ein ggplot-Diagramm, man kann also mit bekannten (ggplot-)Methoden nachpolieren, z.B s. AbbildungÂ 13.2.\n\nplot(hdi(m1)) +\n  labs(title =\"Hier steht mein Titel\",\n       y = \"\",\n       y = \"\",\n       x = \"Parameterwert\") +\n  theme_minimal() +\n  theme(axis.text.y = element_blank())  # keine Achsenlabels auf Y (\"am\" weg)\n\n\n\n\n\n\n\nAbbildungÂ 13.2: Die Postverteilung als Berg visualisiert, nicht als Seil.\n\n\n\n\n\n\n\n\n13.7.4 ROPE\nTesten Sie eine Hypothese, die einen â€œpraktischen Nullwertâ€ ausschlieÃŸen mÃ¶chte, so bietet sich das ROPE-Verfahren an.\nMit ROPE testet man demnach keine â€œExaktnullhypotheseâ€, sondern eine â€œPraktischnullhypotheseâ€, nÃ¤mlich dass ein Effekt so klein ist, dass er praktisch keine Bedeutung hat.\nDiesem Konzept liegt die Ãœberlegung zugrunde, dass es in der freien Wildbahn kaum oder keine Effekte gibt, die exakt Null sind, also â€œ0,0000000000000000000000000 â€¦â€ und so weiter bis alle Unendlichkeit.\nSinnvoller ist es daher zu prÃ¼fen, ob ein Effekt vernachlÃ¤ssigbar klein ist fÃ¼r praktische Belange.\nWie klein ein Effekt sein muss, um â€œklein genugâ€ fÃ¼r â€œvernachlÃ¤ssigbar kleinâ€ zu sein, ist erstmal keine statistische Frage.\nSchauen Sie: Wie groÃŸ muss der Nutzen des Besuchens einer Vorlesung sein, damit Sie sie besuchen? Die Antwort der Frage hÃ¤ngt von mehreren Faktoren ab, und sie ist subjektiv in dem Sinne, dass die Antwort von persÃ¶nlichen PrÃ¤ferenzen abhÃ¤ngt, die letztlich nicht objektiv zu begrÃ¼nden sind.\nSo kann man in R ein ROPE berechnen (lassen):â€š\n\nlibrary(easystats)\n\nrope(m1)\n\n\n  \n\n\n\nDas Ergebnis sagt uns, dass 0% des 95%-HDI innerhalb des ROPE-Bereichs liegen. Die Nullhypothese ist also fÃ¼r praktische Zwecke auszuschlieÃŸen.\nFormulierungsvorschlag &gt; Die Nullhypothese \\(H^1_0\\) ist auszuschlieÃŸen laut Modell m1, 0% ROPE. Der Effekt ist demnach in diesem Sinne signifikant.\nDas kann man sich auch plotten lassen:\n\nplot(rope(m1))\n\n\n\n\n\n\n\n\nDie Hilfeseite von rope sagt uns:\n\nCompute the proportion of the HDI (default to the 89% HDI) of a posterior distribution that lies within a region of practical equivalence.\n\nWeiter steht dort:\nrope(x, range = \"default\", ci = 0.95, ci_method = \"ETI\", verbose = TRUE, ...)\nETI steht fÃ¼r â€œEqual Tail Intervalâ€, das ist ein Perzentilintervall.\nZum Argument range ist zu lesen:\n\nROPEâ€™s lower and higher bounds. Should be â€œdefaultâ€ or depending on the number of outcome variables a vector or a list. In models with one response, range should be a vector of length two (e.g., c(-0.1, 0.1)). In multivariate models, range should be a list with a numeric vectors for each response variable. Vector names should correspond to the name of the response variables. If â€œdefaultâ€ and input is a vector, the range is set to c(-0.1, 0.1). If â€œdefaultâ€ and input is a Bayesian model, rope_range() is used.\n\nUnd rope_range() sagt uns in der Hilfeseite:\n\nKruschke (2018) suggests that the region of practical equivalence could be set, by default, to a range from -0.1 to 0.1 of a standardized parameter (negligible effect size according to Cohen, 1988).\n\nWobei man schon im Methodenteil ROPE definieren sollte, dann mÃ¼sste man das hier nicht mehr tun.\nMerkhilfe zur Entscheidung mit ROPE:\n\nSchneidet ROPE mit dem Berg, dem roten, dann Verwerfen ist verboten!\n\nMit â€œVerwerfenâ€ ist das Verwerfen der â€œPraktischnullhypotheseâ€ gemeint.\nDas ROPE ist eine nette Sache: Man kann eine â€œPraktischnullhypotheseâ€ testen. Besser ist aber die SchÃ¤tzung eines Konfidenzintervalls: Es beinhaltet die Informationen eines ROPE aber noch mehr.\n\n13.7.4.1 Standardisierte EffektstÃ¤rke\nVergleicht man Gruppen und ist z.â€‰B. die AV wenig anschaulich (etwa ein Summenscore), so bietet es sich, standardisierte MaÃŸe des Gruppenunterschieds anzugeben. Man nennt sie auch MaÃŸe der EffektstÃ¤rke.\nBei Gruppenvergleichen ist Cohens d ein bekanntes MaÃŸ. Man kann es sich so ausgeben lassen:\n\nlibrary(easystats)\ncohens_d(mpg ~ am, data = mtcars) %&gt;% print_md()\n\n\n\n\nCohenâ€™s d\n95% CI\n\n\n\n\n-1.48\n[-2.27, -0.67]\n\n\n\nEstimated using pooled SD.\n\n\nMan gibt also die Regressionsformel und die Daten an. Zu beachten ist, dass die AV zweistufig sein muss, sonst ist Cohens d nicht definiert.\nPraktischerweise kann man sich die EffektstÃ¤rke auch gleich interpretieren lassen:\n\ninterpret_cohens_d(-1.48)\n## [1] \"large\"\n## (Rules: cohen1988)\n\nUm \\(R^2\\) in einem Bayes-Modell zu bekommen, bietet sich die Funktion bayes_R2() an:\n\nm1_R2 &lt;- \n  bayes_R2(m1) %&gt;% \n  as_tibble()\n\nhdi(m1_R2) %&gt;% print_md()\n\n\nHighest Density Interval\n\n\nParameter\n95% HDI\n\n\n\n\nvalue\n[0.10, 0.54]\n\n\n\n\n\n\n\n13.7.4.2 R-Paket report\nVielleicht ist das R-Paket report fÃ¼r Sie nÃ¼tzlich. Ich bin nicht ganz sicher, denn das Paket ist noch sehr neu und berichtet recht viel Informationen. Aber vielleicht wollen Sie es ja mal ausprobieren.\n\nlibrary(easystats)\n\nreport lieft z.â€‰B. eine Beschreibung der Stichprobe:\n\nmtcars %&gt;% \n  select(1:3) %&gt;%  # hier nur die Variablen 1 bis 3, der Einfachheit halber\n  report()\n## The data contains 32 observations of the following 3 variables:\n## \n##   - mpg: n = 32, Mean = 20.09, SD = 6.03, Median = 19.20, MAD = 5.41, range:\n## [10.40, 33.90], Skewness = 0.67, Kurtosis = -0.02, 0 missing\n##   - cyl: n = 32, Mean = 6.19, SD = 1.79, Median = 6.00, MAD = 2.97, range: [4,\n## 8], Skewness = -0.19, Kurtosis = -1.76, 0 missing\n##   - disp: n = 32, Mean = 230.72, SD = 123.94, Median = 196.30, MAD = 140.48,\n## range: [71.10, 472], Skewness = 0.42, Kurtosis = -1.07, 0 missing\n\nOder auch fÃ¼r (Bayes-)Regressionsmodelle:\n\nreport(m1)\n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\n## Chain 1: \n## Chain 1: Gradient evaluation took 0.000373 seconds\n## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 3.73 seconds.\n## Chain 1: Adjust your expectations accordingly!\n## Chain 1: \n## Chain 1: \n## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 1: \n## Chain 1:  Elapsed Time: 0.166 seconds (Warm-up)\n## Chain 1:                0.193 seconds (Sampling)\n## Chain 1:                0.359 seconds (Total)\n## Chain 1: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\n## Chain 2: \n## Chain 2: Gradient evaluation took 5e-05 seconds\n## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.5 seconds.\n## Chain 2: Adjust your expectations accordingly!\n## Chain 2: \n## Chain 2: \n## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 2: \n## Chain 2:  Elapsed Time: 0.18 seconds (Warm-up)\n## Chain 2:                0.21 seconds (Sampling)\n## Chain 2:                0.39 seconds (Total)\n## Chain 2: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\n## Chain 3: \n## Chain 3: Gradient evaluation took 4.2e-05 seconds\n## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.42 seconds.\n## Chain 3: Adjust your expectations accordingly!\n## Chain 3: \n## Chain 3: \n## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 3: \n## Chain 3:  Elapsed Time: 0.188 seconds (Warm-up)\n## Chain 3:                0.201 seconds (Sampling)\n## Chain 3:                0.389 seconds (Total)\n## Chain 3: \n## \n## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\n## Chain 4: \n## Chain 4: Gradient evaluation took 4.8e-05 seconds\n## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds.\n## Chain 4: Adjust your expectations accordingly!\n## Chain 4: \n## Chain 4: \n## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 4: \n## Chain 4:  Elapsed Time: 0.163 seconds (Warm-up)\n## Chain 4:                0.213 seconds (Sampling)\n## Chain 4:                0.376 seconds (Total)\n## Chain 4:\n## We fitted a Bayesian linear model (estimated using MCMC sampling with 4 chains\n## of 2000 iterations and a warmup of 1000) to predict mpg with am (formula: mpg ~\n## am). Priors over parameters were set as normal (mean = 0.00, SD = 30.20)\n## distributions. The model's explanatory power is substantial (R2 = 0.35, 95% CI\n## [0.10, 0.54], adj. R2 = 0.29). The model's intercept, corresponding to am = 0,\n## is at 17.14 (95% CI [14.85, 19.51]). Within this model:\n## \n##   - The effect of am (Median = 7.21, 95% CI [3.72, 10.70]) has a 99.95%\n## probability of being positive (&gt; 0), 99.92% of being significant (&gt; 0.30), and\n## 99.72% of being large (&gt; 1.81). The estimation successfully converged (Rhat =\n## 0.999) and the indices are reliable (ESS = 3755)\n## \n## Following the Sequential Effect eXistence and sIgnificance Testing (SEXIT)\n## framework, we report the median of the posterior distribution and its 95% CI\n## (Highest Density Interval), along the probability of direction (pd), the\n## probability of significance and the probability of being large. The thresholds\n## beyond which the effect is considered as significant (i.e., non-negligible) and\n## large are |0.30| and |1.81| (corresponding respectively to 0.05 and 0.30 of the\n## outcome's SD). Convergence and stability of the Bayesian sampling has been\n## assessed using R-hat, which should be below 1.01 (Vehtari et al., 2019), and\n## Effective Sample Size (ESS), which should be greater than 1000 (Burkner, 2017).\n\nreport berichtet Statistiken nach dem sog. SEXIT-Konzept Makowski u.Â a. (2019). Wenn Ihnen einige Statistiken nicht gelÃ¤ufig sind, ignorieren Sie sich einfach oder lesen Sie sie nach.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#diskussion",
    "href": "100-Statistiken-berichten.html#diskussion",
    "title": "13Â  Auswerten: Berichten von Statistiken",
    "section": "13.8 Diskussion",
    "text": "13.8 Diskussion\nIm Diskussionsteil fasst man die zentralen Ergebnisse zusammen und interpretiert sie. Danach schlieÃŸt sich eine Kritik der Ergebnisse (oder vielmehr des Vorgehens) an.\nOb man eine Hypothese â€œannimmtâ€ oder â€œverwirftâ€, sollte nicht von einer einzelnen Zahl abhÃ¤ngig sein. Vielmehr ist es keine Schwarz-WeiÃŸ-, sondern eine Grauton-Entscheidung mit mehreren EinflussgrÃ¶ÃŸen, wie PrÃ¤zision der SchÃ¤tzung, EffektstÃ¤rke, StichprobengrÃ¶ÃŸe, GÃ¼te der Daten, StÃ¤rke des Versuchsplans, Generalisierbarkeit, um nur einige wichtige zu nennen.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "100-Statistiken-berichten.html#reproduzierbarkeit",
    "href": "100-Statistiken-berichten.html#reproduzierbarkeit",
    "title": "13Â  Auswerten: Berichten von Statistiken",
    "section": "13.9 Reproduzierbarkeit",
    "text": "13.9 Reproduzierbarkeit\nDer Geist der Wissenschaft heiÃŸt Transparenz. Also machen Sie ihre Arbeit nachprÃ¼fbar und legen Sie die zentralen Schritte offen:\n\nReichen Sie die Daten ein; legen Sie ein Data-Dictionary (Codebook) bei.\nReichen Sie die Syntax ein.\nReichen Sie die Messinstrumente und Stimuli ein (sofern nicht Ã¶ffentlich einsehbar).\nExplizieren Sie Ihr Vorgehen prÃ¤gnant.\nErlÃ¤utern Sie Ihre theoretischen Argumente nachvollziehbar und unter Bezug auf die Literatur.\nFixieren Sie die Zufallszahlen in Analysen, die mit Zufallszahlen arbeiten (z.â€‰B. stan_glm).\n\nDie Zufallszahlen in stan_glm kÃ¶nnen Sie z.â€‰B. so fixieren:\n\nm1 &lt;- stan_glm(av ~ uv, data = meine_daten, seed = 42)\n\nDie genaue Wert bei seed ist nicht entscheidend; aber ein bestimmter Seed-Wert wird immer die gleichen Zufallszahlen zielen und damit immer die gleichen Parameterwerte im Modell nach sich ziehen.\n\n\n\n\nCooper, Harris. 2020. â€Reporting Standards for Research in Psychology: Why Do We Need Them? What Might They Be?â€œ In Reporting Quantitative Research in Psychology: How to Meet APA Style Journal Article Reporting Standards, 2nd Ed, 3â€“17. Washington, DC, US: American Psychological Association. https://doi.org/10.1037/0000178-001.\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge: Cambridge University Press.\n\n\nJhangiani, Rajiv S, Jhangiani, I-Chant A Chiang, und Dana C Cuttler Leighton. 2019. Research Methods in Psychology.\n\n\nKruschke, John K. 2018. â€Rejecting or Accepting Parameter Values in Bayesian Estimationâ€œ. Advances in Methods and Practices in Psychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nâ€”â€”â€”. 2021. â€Bayesian Analysis Reporting Guidelinesâ€œ. Nature Human Behaviour 5 (10, 10): 1282â€“91. https://doi.org/10.1038/s41562-021-01177-7.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, und Daniel LÃ¼decke. 2019. â€Indices of Effect Existence and Significance in the Bayesian Frameworkâ€œ. Frontiers in Psychology 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767.\n\n\nPeters, Jan H., und Tobias DÃ¶rfler. 2015. Abschlussarbeiten in der Psychologie und den Sozialwissenschaften - Schreiben und Gestalten. PS - Psychologie. Hallbergmoos/Germany: Pearson. https://www.pearson-studium.de/schreiben-und-gestalten-von-abschlussarbeiten-in-der-psychologie-und-den-sozialwissenschaften.html.\n\n\nPeters, Jan Hendrik, und Tobias DÃ¶rfler. 2019. Planen, DurchfÃ¼hren und Auswerten von Abschlussarbeiten in der Psychologie und den Sozialwissenschaften. Pearson. https://www.pearson-studium.de/planen-durchfuehren-und-auswerten-von-abschlussarbeiten-in-der-psychologie-und-den-sozialwissenschaften.html.",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Auswerten: Berichten von Statistiken</span>"
    ]
  },
  {
    "objectID": "120-abschluss.html#beispiele-fÃ¼r-gute-projektarbeiten",
    "href": "120-abschluss.html#beispiele-fÃ¼r-gute-projektarbeiten",
    "title": "14Â  Abschluss",
    "section": "14.1 Beispiele fÃ¼r gute Projektarbeiten",
    "text": "14.1 Beispiele fÃ¼r gute Projektarbeiten\nAuf der Seite der Schriftenreihe des Instituts fÃ¼r Wirtschaftspsychologie (iwp) der FOM Hochschule finden Sie eine Auswahl an insgesamt gut aufbereiteten Berichten zu psychologischen Studien â€“ fast alle aus studentischer Feder. Diese Arbeiten kÃ¶nnen als Vorbilder fÃ¼r Ihren eigenen Bericht dienen.\nInteressant ist z.â€‰B. die Arbeit zum Thema Selbstwirksamkeit, Selbstregulation und Prokrastination â€“ ÃœberprÃ¼fung eines Mediationsmodells von (schuhmacher_selbstwirksamkeit_2022?). Die Arbeit ist frei im Netz verfÃ¼gbar.\n\nLernen Sie von anderen, vergleichbaren Arbeiten und nutzen Sie diese als Vorbild. \\(\\square\\)",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "120-abschluss.html#fertig",
    "href": "120-abschluss.html#fertig",
    "title": "14Â  Abschluss",
    "section": "14.2 Fertig",
    "text": "14.2 Fertig\nSie haben dieses Modul abgeschlossen. Sie mÃ¼ssen Ihren Fortschritt im Projektplan nicht mehr im Blick behalten. ğŸ˜„",
    "crumbs": [
      "Fertigstellen",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "130-references.html",
    "href": "130-references.html",
    "title": "References",
    "section": "",
    "text": "Adler, Mortimer Jerome, and Charles Van Doren. 1972. How to Read a\nBook. Rev. and updated ed. New York: Simon and\nSchuster.\n\n\nAl-Natour, Sameh, Izak Benbasat, and Ronald Cenfetelli. 2011. â€œThe\nAdoption of Online Shopping Assistants:\nPerceived Similarity as an Antecedent to\nEvaluative Beliefs.â€ Journal of the Association\nfor Information Systems 12 (5). https://doi.org/10.17705/1jais.00267.\n\n\nAmelang, M., and Lothar Schmidt-Atzert. 2012. Psychologische\nDiagnostik. https://doi.org/10.1007/978-3-642-17001-0.\n\n\nAmerican Psychological Association. 2019. Publication\nManual of the American Psychological\nAssociation, 7th Edition. Washington,\nDC: American Psychological Association (APA). https://www.amazon.com/Publication-Manual-American-Psychological-Association/dp/1433805618?SubscriptionId=0JYN1NVW651KCA56C102&tag=techkie-20&linkCode=xm2&camp=2025&creative=165953&creativeASIN=1433805618.\n\n\nAriely, Dan. 2012. Die Halbe Wahrheit Ist Die Beste\nLÃ¼ge: Wie Wir Andere TÃ¤uschenâ€“Und Uns Selbst\nAm Meisten. MÃ¼nchen: Droemer.\n\n\nâ€”â€”â€”. 2015. Denken hilft zwar, nÃ¼tzt aber nichts: warum wir immer\nwieder unvernÃ¼nftige Entscheidungen treffen. Translated by Maria\nZybak and Gabrielle Gockel. VollstÃ¤ndige Taschenbuchausgabe. Droemer\n30088. MÃ¼nchen: Droemer.\n\n\nBangor, Aaron, Philip T. Kortum, and James T. Miller. 2008. â€œAn\nEmpirical Evaluation of the System Usability\nScale.â€ International Journal of Humanâ€“Computer\nInteraction 24 (6): 574â€“94. https://doi.org/10.1080/10447310802205776.\n\n\nBortz, JÃ¼rgen, and Nicola DÃ¶ring. 2006. Forschungsmethoden Und\nEvaluation: FÃ¼r Human- Und\nSozialwissenschaftler. 4. Auflage.\nBerlin: Springer. https://link.springer.com/book/10.1007/978-3-540-33306-7.\n\n\nBrembs, BjÃ¶rn. 2018. â€œPrestigious Science Journals\nStruggle to Reach Even Average Reliability.â€\nFrontiers in Human Neuroscience 12 (February). https://doi.org/10.3389/fnhum.2018.00037.\n\n\nBrembs, BjÃ¶rn, Katherine Button, and Marcus MunafÃ². 2013. â€œDeep\nImpact: Unintended Consequences of Journal Rank.â€ Frontiers\nin Human Neuroscience 7. https://doi.org/10.3389/fnhum.2013.00291.\n\n\nBrown, Patricia M., Amanda M. George, and Debra J. Rickwood. 2021.\nâ€œRash Impulsivity, Reward Seeking and Fear of Missing Out as\nPredictors of Texting While Driving: Indirect Effects via\nMobile Phone Involvement.â€ Personality and Individual\nDifferences 171 (March): 110492. https://doi.org/10.1016/j.paid.2020.110492.\n\n\nBÃ¼hner, M. 2011. EinfÃ¼hrung in Die Test- Und\nFragebogenkonstruktion. PS Psychologie.\nHallbergmoos: Pearson Studium. https://books.google.de/books?id=Y4990CfV3wgC.\n\n\nChalmers, Alan F., and Alan F. Chalmers. 2007. Wege der\nWissenschaft: EinfÃ¼hrung in die Wissenschaftstheorie. Edited by\nNiels Bergemann. 6., verb. Aufl. Berlin Heidelberg:\nSpringer.\n\n\nCialdini, Robert B. 2017. Die Psychologie des Ãœberzeugens: wie Sie\nsich selbst und Ihren Mitmenschen auf die Schliche kommen.\nTranslated by Matthias Wengenroth. 8., unverÃ¤nderte Auflage.\nBern: Hogrefe.\n\n\nCohen, J. 1992. â€œA Power Primer.â€ Psychological\nBulletin 112 (1): 155â€“59.\n\n\nCooper, Harris. 2020. â€œReporting Standards for Research in\nPsychology: Why Do We Need Them? What Might\nThey Be?â€ In Reporting Quantitative Research in Psychology:\nHow to Meet APA Style Journal Article Reporting\nStandards, 2nd Ed, 3â€“17. Washington, DC, US:\nAmerican Psychological Association. https://doi.org/10.1037/0000178-001.\n\n\nDienes, Zoltan. 2008. Understanding Psychology as a Science: An\nIntroduction to Scientific and Statistical Inference. New\nYork: Palgrave Macmillan.\n\n\nDobelli, Rolf, and Birgit Lang. 2011. Die Kunst Des\nKlaren Denkens. Hanser.\n\n\nDPGs, BDP und. 2016. â€œBerufsethische\nRichtlinien.â€ Berufsverbandes Deutscher\nPsychologinnen und Psychologen e.V. und der Deutschen Gesellschaft fÃ¼r\nPsychologie e.V. https://www.dgps.de/die-dgps/aufgaben-und-ziele/berufsethische-richtlinien.\n\n\nEid, M, M Gollwitzer, and M Schmitt. 2013. Statistik Und\nForschungsmethoden: Lehrbuch. Mit\nOnline-Materialien. Beltz. http://books.google.de/books?id=bTdHyoIbMSAC.\n\n\nEscalas, Jennifer Edson, and Barbara B. Stern. 2003. â€œSympathy and\nEmpathy: Emotional Responses to\nAdvertising Dramas.â€ Journal of Consumer\nResearch 29 (4): 566â€“78. https://doi.org/10.1086/346251.\n\n\nEtcoff, Nancy L., Shannon Stock, Lauren E. Haley, Sarah a. Vickery, and\nDavid M. House. 2011. â€œCosmetics as a Feature of the Extended\nHuman Phenotype: Modulation of the Perception of\nBiologically Important Facial Signals.â€ PLoS ONE 6 (10):\n1â€“9. https://doi.org/10.1371/journal.pone.0025656.\n\n\nFerreira-Barbosa, Helena, JerÃ³nimo GarcÃ­a-FernÃ¡ndez, and Gabriel\nCepeda-CarriÃ³n. 2023. â€œThe Mediating Role of\ne-Lifestyles to Use the Fitness Center\nApp.â€ International Journal of Humanâ€“Computer\nInteraction 0 (0): 1â€“10. https://doi.org/10.1080/10447318.2023.2204273.\n\n\nFisher, Gwenith G., Russell A. Matthews, and Alyssa Mitchell Gibbons.\n2016. â€œDeveloping and Investigating the Use of Single-Item\nMeasures in Organizational Research.â€ Journal of Occupational\nHealth Psychology 21: 3â€“23. https://doi.org/10.1037/a0039139.\n\n\nGalliker, Mark. 2016. Ist Die Psychologie Eine\nWissenschaft? Ihre Krisen Und\nKontroversen von Den AnfÃ¤ngen Bis Zur\nGegenwart. Wiesbaden:\nSpringer.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research.\nCambridge: Cambridge University Press.\n\n\nGraf, Laura K. M., Stefan Mayer, and Jan R. Landwehr. 2018.\nâ€œMeasuring Processing Fluency: One Versus Five\nItems.â€ Journal of Consumer Psychology 28: 393â€“411. https://doi.org/10.1002/jcpy.1021.\n\n\nGrant, Stan, Tom Aitchison, Esther Henderson, Jim Christie, Sharam Zare,\nJohn Mc Murray, and Henry Dargie. 1999. â€œA Comparison\nof the Reproducibility and the Sensitivity to\nChange of Visual Analogue Scales, Borg\nScales, and Likert Scales in Normal Subjects\nDuring Submaximal Exercise.â€ CHEST 116 (5):\n1208â€“17. https://doi.org/10.1378/chest.116.5.1208.\n\n\nGreenwald, Anthony G, and Mahzarin R Banaji. 1995. â€œImplicit\nSocial Cognition: Attitudes,\nSelf-Esteem, and Stereotypes.â€\nPsychological Review 102 (1): 4â€“27.\n\n\nGrewal, Dhruv, Kent B. Monroe, and R. Krishnan. 1998. â€œThe Effects\nof Price-Comparison Advertising on Buyersâ€™ Perceptions of Acquisition\nValue, Transaction Value, and Behavioral Intentions.â€ Journal\nof Marketing 62: 46â€“59. https://doi.org/10.2307/1252160.\n\n\nGudmundsson, Einar. 2009. â€œGuidelines for Translating and Adapting\nPsychological Instruments.â€ Nordic Psychology 61 (2):\n29â€“45. https://doi.org/10.1027/1901-2276.61.2.29.\n\n\nGulbins, JÃ¼rgen, and Christine Kahrmann. 2000. Mut zur Typographie:\nein Kurs fÃ¼r Desktop-Publishing ; mit 40 Tabellen. 2., Ã¼berarb. und\nerw. Aufl. X.media.press. Berlin: Springer.\n\n\nHayes, Andrew F., and Jacob J. Coutts. 2020. â€œUse Omega\nRather Than Cronbachâ€™s Alpha for\nEstimating Reliability. Butâ€¦.â€\nCommunication Methods and Measures 14 (1): 1â€“24. https://doi.org/10.1080/19312458.2020.1718629.\n\n\nHeesen, Bernd. 2021. Wissenschaftliches Arbeiten: Methodenwissen fÃ¼r\nWirtschafts-, Ingenieur- und Sozialwissenschaftler. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-62548-4.\n\n\nHo, Chin-Chang, and Karl F. MacDorman. 2010. â€œRevisiting the\nUncanny Valley Theory: Developing and Validating an\nAlternative to the Godspeed Indices.â€ Computers\nin Human Behavior, Online Interactivity:\nRole of Technology in Behavior\nChange, 26 (6): 1508â€“18. https://doi.org/10.1016/j.chb.2010.05.015.\n\n\nHofstadter, Douglas R., Susanne Held, and Douglas R. Hofstadter. 2008.\nIch bin eine seltsame Schleife. 2. Aufl.\nStuttgart: Klett-Cotta.\n\n\nHuntington-Klein, Nick. 2022. The Effect: An Introduction to\nResearch Design and Causality. Boca Raton: CRC\nPress, Taylor & Francis Group. https://theeffectbook.net/.\n\n\nJhangiani, Rajiv S, Jhangiani, I-Chant A Chiang, and Dana C Cuttler\nLeighton. 2019. Research Methods in\nPsychology.\n\n\nJonas, Klaus, Wolfgang Stroebe, and Miles Hewstone, eds. 2014.\nSozialpsychologie. Springer-Lehrbuch. Berlin,\nHeidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-41091-8.\n\n\nKahneman, Daniel. 2012. Schnelles Denken, Langsames\nDenken. MÃ¼nchen: Siedler\nVerlag.\n\n\nKornmeier, Martin. 2013. Wissenschaftlich Schreiben Leicht\nGemacht. 6th ed. Bern: Haupt-Verlag.\n\n\nKruschke, John K. 2018. â€œRejecting or Accepting Parameter\nValues in Bayesian Estimation.â€ Advances\nin Methods and Practices in Psychological Science 1 (2): 270â€“80. https://doi.org/10.1177/2515245918771304.\n\n\nâ€”â€”â€”. 2021. â€œBayesian Analysis Reporting\nGuidelines.â€ Nature Human Behaviour 5 (10, 10):\n1282â€“91. https://doi.org/10.1038/s41562-021-01177-7.\n\n\nKurdi, Benedek, Shayn Lozano, and Mahzarin R. Banaji. 2017.\nâ€œIntroducing the Open Affective Standardized Image\nSet (OASIS).â€ Behavior Research\nMethods 49 (2): 457â€“70. https://doi.org/10.3758/s13428-016-0715-3.\n\n\nKwon, Min, Dai-Jin Kim, Hyun Cho, and Soo Yang. 2013. â€œThe\nSmartphone Addiction Scale: Development and Validation of a Short\nVersion for Adolescents.â€ PloS One 8 (12): e83558. https://doi.org/10.1371/journal.pone.0083558.\n\n\nLabovitz, Sanford. 1970. â€œThe Assignment of\nNumbers to Rank Order Categories.â€\nAmerican Sociological Review 35 (3): 515â€“24. https://doi.org/10.2307/2093306.\n\n\nLang, P J, M M Bradley, and B N Cuthbert. 1999. â€œInternational\nAffective Picture System (IAPS): Instruction\nManual and Affective Ratings.â€ NIMH Center for the Study of\nEmotion and Attention.\n\n\nLewis, James R., and Jeff Sauro. 2009. â€œThe Factor\nStructure of the System Usability Scale.â€ In\nHuman Centered Design, edited by Masaaki Kurosu,\n94â€“103. Lecture Notes in Computer Science.\nBerlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-02806-9_12.\n\n\nLienert, Gustav A., and Ulrich Raatz. 1998. Testaufbau und\nTestanalyse. 6. Auflage. Weinheim: Beltz,\nPsychologie Verlags Union.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, S. H. Annabel Chen, and\nDaniel LÃ¼decke. 2019. â€œIndices of Effect Existence\nand Significance in the Bayesian\nFramework.â€ Frontiers in Psychology 10. https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767.\n\n\nMaxham, James G., and Richard G. Netemeyer. 2002. â€œA\nLongitudinal Study of Complaining Customersâ€™\nEvaluations of Multiple Service Failures and\nRecovery Efforts.â€ Journal of Marketing 66\n(4): 57â€“71. https://doi.org/10.1509/jmkg.66.4.57.18512.\n\n\nMichell, J, and C Ernst. 1997. â€œThe Axioms of\nQuantity and the Theory of\nMeasurement.â€ Journal of Mathematical\nPsychology 41 (4): 345â€“56. http://www.ncbi.nlm.nih.gov/pubmed/9473397.\n\n\nMoosbrugger, Helfried, and Augustin Kelava, eds. 2012. Testtheorie\nUnd Fragebogenkonstruktion.\nSpringer-Lehrbuch. Berlin:\nSpringer. https://doi.org/10.1007/978-3-642-20072-4.\n\n\nMueller, Pam A., and Daniel M. Oppenheimer. 2014. â€œThe Pen\nIs Mightier Than the Keyboard:\nAdvantages of Longhand Over Laptop Note\nTaking.â€ Psychological Science 25 (6): 1159â€“68.\nhttps://doi.org/10.1177/0956797614524581.\n\n\nNetemeyer, Richard G., Kelly L. Haws, and William O. Bearden, eds. 2011.\nHandbook of Marketing Scales: Multi-Item Measures for Marketing and\nConsumer Behavior Research. 3rd ed. Los Angeles:\nSAGE.\n\n\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New\nScience of Cause and Effect. First edition. New York:\nBasic Books.\n\n\nPeters, Jan H., and Tobias DÃ¶rfler. 2015. Abschlussarbeiten in der\nPsychologie und den Sozialwissenschaften - Schreiben und Gestalten.\nPS - Psychologie. Hallbergmoos/Germany:\nPearson. https://www.pearson-studium.de/schreiben-und-gestalten-von-abschlussarbeiten-in-der-psychologie-und-den-sozialwissenschaften.html.\n\n\nPeters, Jan H, and Tobias DÃ¶rfler. 2019. Schreiben und Gestalten von\nAbschlussarbeiten in der Psychologie und den Sozialwissenschaften.\nhttps://www.pearson-studium.de/drm/reader/nu/code/uesgvaaidpsy.\n\n\nPeters, Jan Hendrik, and Tobias DÃ¶rfler. 2019. Planen, DurchfÃ¼hren\nund Auswerten von Abschlussarbeiten in der Psychologie und den\nSozialwissenschaften. Pearson. https://www.pearson-studium.de/planen-durchfuehren-und-auswerten-von-abschlussarbeiten-in-der-psychologie-und-den-sozialwissenschaften.html.\n\n\nPopper, Karl. 2013. Logik Der Forschung. Edited by\nHerbert Keuth. Akademie Verlag. https://doi.org/10.1524/9783050063782.\n\n\nPorst, Rolf. 2014. Fragebogen: ein Arbeitsbuch. 4., erweiterte\nAuflage. Studienskripten zur Soziologie. Wiesbaden:\nSpringer.\n\n\nRedondo, Jaime, Isabel Fraga, Isabel PadrÃ³n, and Ana PiÃ±eiro. 2008.\nâ€œAffective Ratings of Sound Stimuli.â€ Behavior Research\nMethods 40 (3): 784â€“90. https://doi.org/10.3758/BRM.40.3.784.\n\n\nReichardt, Charles S. 2019. Quasi-Experimentation: A Guide to Design\nand Analysis. Methodology in the Social Sciences. New York :\nLondon: The Guilford Press.\n\n\nReiÃŸ, Siegbert, and Viktor Sarris. 2012. Experimentelle Psychologie:\nvon der Theorie zur Praxis. Pearson Studium Psychologie.\nMÃ¼nchen: Pearson.\n\n\nSaint-Mont, Uwe. 2015. â€œRandomization Does Not Help\nMuch, Comparability Does.â€ PLoS ONE\n10 (7): e0132102. https://doi.org/10.1371/journal.pone.0132102.\n\n\nSatow, L. 2011. â€œB5T - Psychomeda\nBig-Five-PersÃ¶nlichkeitstest.â€ https://doi.org/10.23668/PSYCHARCHIVES.4530.\n\n\nâ€”â€”â€”. 2020. â€œB5TÂ®. Big-Five-PersÃ¶nlichkeitstest.â€ https://doi.org/10.23668/PSYCHARCHIVES.4611.\n\n\nSauer, Sebastian, and Ludwilla Lustig. 2023. â€œThe Effect of\nBringtnixtin on Fluid Intelligence: A\nRandomized, Controlled Trial.â€ Journal for Fake Data 42\n(1): 271â€“314.\n\n\nSchepman, Astrid, and Paul Rodway. 2022. â€œThe General\nAttitudes Towards Artificial Intelligence Scale\n(GAAIS): Confirmatory Validation and\nAssociations with Personality, Corporate\nDistrust, and General Trust.â€\nInternational Journal of Humanâ€“Computer Interaction 0 (0):\n1â€“18. https://doi.org/10.1080/10447318.2022.2085400.\n\n\nSchÃ¶nbrodt, Felix D, Moritz Heene, Michael Zehetleitner, Markus Maier,\nAnne M Scheel, Caroline Zygar-Hoffmann, Ramona Schoedel, Larissa Sust,\nLena Schiestel, and Malika Ihle. 2023. â€œOpen Science Initiative in\nPsychology @LMU.â€ OSF. osf.io/mgwk8.\n\n\nSchÃ¶nbrodt, Felix D., and Marco Perugini. 2013. â€œAt What Sample\nSize Do Correlations Stabilize?â€ Journal of Research in\nPersonality 47 (5): 609â€“12. https://doi.org/10.1016/j.jrp.2013.05.009.\n\n\nSindermann, Cornelia, Peng Sha, Min Zhou, Jennifer Wernicke, Helena S.\nSchmitt, Mei Li, Rayna Sariyska, Maria Stavrou, Benjamin Becker, and\nChristian Montag. 2021. â€œAssessing the Attitude Towards\nArtificial Intelligence: Introduction of a\nShort Measure in German, Chinese,\nand English Language.â€ KI - KÃ¼nstliche\nIntelligenz 35 (1): 109â€“18. https://doi.org/10.1007/s13218-020-00689-0.\n\n\nSong, Stephen Wonchul, and Mincheol Shin. 2022. â€œUncanny\nValley Effects on Chatbot Trust,\nPurchase Intention, and Adoption Intention in\nthe Context of E-Commerce: The\nModerating Role of Avatar Familiarity.â€\nInternational Journal of Humanâ€“Computer Interaction 0 (0):\n1â€“16. https://doi.org/10.1080/10447318.2022.2121038.\n\n\nSuh, Woong, and Seongjin Ahn. 2022. â€œDevelopment and\nValidation of a Scale Measuring Student Attitudes\nToward Artificial Intelligence.â€ SAGE Open 12\n(2): 21582440221100463. https://doi.org/10.1177/21582440221100463.\n\n\nSuppes, Patrick. 1999. Introduction to Logic. Mineola,\nN.Y: Dover Publications.\n\n\nTavakol, Mohsen, and Reg Dennick. 2011. â€œMaking Sense of\nCronbachâ€™s Alpha.â€ International Journal of\nMedical Education 2 (June): 53â€“55. https://doi.org/10.5116/ijme.4dfb.8dfd.\n\n\nTheisen, Manuel RenÃ©. 2021. Wissenschaftliches Arbeiten: erfolgreich\nbei Bachelor- und Masterarbeit. 18., neu bearbeitete und gekÃ¼rzte\nAuflage. MÃ¼nchen: Verlag Franz Vahlen.\n\n\nVenkatesh, Viswanath, and Hillol Bala. 2008. â€œTechnology\nAcceptance Model 3 and a Research Agenda on\nInterventions,â€ May. https://doi.org/10.1111/j.1540-5915.2008.00192.x.\n\n\nWalach, Harald, and Nikolaus von Stillfried. 2013. Psychologie:\nWissenschaftstheorie, philosophische Grundlagen und Geschichte: ein\nLehrbuch. 3., Ã¼berarb. und erw. Aufl. Stuttgart:\nKohlhammer.\n\n\nWaldorf, M., M. Cordes, S. Vocks, and D. McCreary. 2016.\nâ€œDeutschsprachige Drive for Muscularity Scale (DMS).â€\nZusammenstellung sozialwissenschaftlicher Items und Skalen\n(ZIS). https://doi.org/10.6102/ZIS246.\n\n\nWard, Adrian F., Kristen Duke, Ayelet Gneezy, and Maarten W. Bos. 2017.\nâ€œBrain Drain: The Mere Presence of\nOneâ€™s Own Smartphone Reduces Available Cognitive\nCapacity.â€ Journal of the Association for Consumer\nResearch 2 (2): 140â€“54. https://doi.org/10.1086/691462.",
    "crumbs": [
      "Fertigstellen",
      "References"
    ]
  }
]