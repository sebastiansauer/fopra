{
  "hash": "a9424fee45015bb6f852a85ce9d109c1",
  "result": {
    "engine": "knitr",
    "markdown": "# Auswerten: Grundlagen\n\n\n\n\n\n::: {.cell}\n\n:::\n\n## Lernsteuerung\n\n\n### Lernziele\n\n- Sie k√∂nnen die typischen Schritte einer Datenanalyse (von Forschungsdaten z.B. aus der Psychologie) benennen.\n- Sie k√∂nnen den Unterschied zwischen Deskriptiv- und Inferenzstatistik benennen.\n- Sie k√∂nnen die Relevanz von Reproduzierbarkeit erl√§utern.\n\n\n\n### Position im Lernpfad\n\nSie befinden sich im Abschnitt \"Auswertung\" in @fig-ueberblick.\nBehalten Sie Ihren Fortschritt im Projektplan im Blick, s. @fig-projektplan.\n\n\n\n### Ben√∂tigte R-Pakete und Daten {#sec-dataneeded}\n\nIn diesem Kapitel ben√∂tigen Sie die folgenden R-Pakete:\n\n\n::: {.cell messagen='false'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)  # Visualisierung\n```\n:::\n\n\n\nWir arbeiten mit dem Datensatz `extra`, aus dem Paket [pradadata](https://sebastiansauer.github.io/pradadata/). in dem Datensatz werden Korrelate zum Pers√∂nlichkeitsmerkmal Extraversion untersucht.\nEin Codebook findet sich [hier](https://sebastiansauer.github.io/pradadata/reference/extra.html).\n\n \n::: {.cell}\n\n```{.r .cell-code}\ndata_url <- \"https://raw.githubusercontent.com/sebastiansauer/modar/master/datasets/extra.csv\"\nextra <- data_read(data_url)  # aus `{easystats}`\n```\n:::\n\n\nAnstelle der Funktion `data_read` k√∂nnten Sie auch `read_csv` (Tidyverse) oder `read.csv` (Standard-R) verwenden.\n\n\n## √úberblick zur Datenanalyse\n\n\nM√ºhsam haben Sie Ihre Studie geplant, minuti√∂s den Versuchsplan ausgeheckt, pedantisch die Messinstrumente bestimmt.\nDann! Die Datenerhebung! Versuchspersonen, manche nervig, manche freundlich.\nIst Forschung denn so anstrengend?\nEndlich! Geschafft -- die Daten sind im Sack, sozusagen.\nDie Datenerhebung ist abgeschlossen.\nWas jetzt?\n\n\n### Wozu ist das gut?\n\nW√ºrden Sie einem Medikament trauen, von dem es hei√üt, das Forschungsteam hatten keinen Bock, Statistik ist zu stressig, aber die Typen aus dem Forschungsteam h√§tten da so ein Gef√ºhl, k√∂nnte schon was bringen, die Pille, immer rein damit.\nWas?! Sie z√∂gern sich das Medikament einzuwerfen?\nSie w√ºssten es lieber genauer, sicherer, belastbarer? Es ginge schlie√ülich um ihre Gesundheit?\n\nAlso gut, Sie haben es so gewollt: Gehen Sie geradeaus weiter zur Statistik.\n\n\n\n### √úber 7 Br√ºcken musst du gehen: Die Schritte der Datenanalyse\n\n\n@fig-sieben-bruecken stellt die typischen Schritte (\"Br√ºcken\") der Datenanalyse dar.\n\n:::{#fig-sieben-bruecken fig-align=\"center\"}\n\n \n```{mermaid}\nflowchart TD\n  A[Einlesen und Aufbereiten] --> Z[Zusammenfassen]\n  Z --> V[Visualisieren]\n  V --> M[Modellieren]\n  M --> I[Interpretieren]\n  I --> K[Kritisieren]\n  K --> √ú[Am√ºsieren]\n  √ú --> A\n```\n\nDie sieben ~~Siegel~~ Br√ºcken der Datenanalyse\n\n:::\n\n\n\nIn etwas mehr Detail sieht der Fortgang Ihrer Datenanalyse so aus:\n\n\n1. *Einlesen und Aufbereiten*: Nachdem Sie die Daten in R importiert haben, bereiten Sie sie auf. Das klingt l√§ppisch, langweilig fast und nicht so cool wie Modellieren. Schon richtig. Fakt ist aber, dass dieser Teil der Analyse h√§ufig ein Gro√üteil  der Zeit ben√∂tigt. Wahr ist: Das Daten aufbereiten ist enorm wichtig. Typische Beispiele f√ºr solche T√§tigkeiten sind das Behandeln fehlender Werte, das Umformen von Tabellen und das Z√§hmen von Extremwerten\n\n2. *Zusammenfassen*: Nachdem Sie die in Ordnung gebracht haben, fassen Sie sie zusammen, um zentrale Trends zu verstehen. Praktisch gesprochen berechnen Sie Ma√üe der Lage, der Streuung und des Zusammenhangs.\n\n3. *Visualisieren*: Der Mensch ist halt ein Augentier. So ein sch√∂nes Diagramm macht einfach was her und besticht auch den strengsten Gutachter.\n\n3. *Modellieren*: Ah, hier kommt der Teil, in dem der Connaisseur seine Muskeln spielen lassen kann: Bayes-Inferenz, multiple Regression, Moderation, Mediation, Kausalanalyse... Ich wei√ü, Sie k√∂nnen Ihre Freude kaum noch z√ºgeln, aber geduldigen Sie sich noch einen kleinen Augenblick.\n\n4. *Interpretieren*: So ein Modell bzw. die entsprechende Funktion in R spuckt einige Zahlen aus. Aber was sagt uns das jetzt? Das w√ºrden Sie auch gerne wissen? Prima! Finden wir es zusammen raus.\n\n5. *Kritisieren*: Jetzt m√ºssen Sie stark sein. Keine Analyse ist perfekt. Keine Studie ist abschlie√üend. Niemand hat bislang den goldenen Gral gefunden. Okay, aber bisher haben Sie sich auch noch nicht an der Sache versucht! Jedenfalls bricht niemanden ein Zacken aus der Krone, wenn man aufzeigt, wo noch Forschungsl√ºcken sind, auch nach der eigenen Studie. Oder sogar, welche Schw√§chen die eigene Studie bzw. Analyse hat und was man beim n√§chsten Mal noch besser machen k√∂nnte.\n\n6. *Am√ºsieren*: So, irgendwann ist auch gut. Jetzt belohnen Sie sich mal f√ºr die ganze harte Arbeit des Studierens.\n\n\n\n## Reproduzierbarkeit\n\n\n\n\n\n\n:::{.callout-important}\nTransparenz (vgl. @def-repro) ist ein zentrales oder das zentrale G√ºtema√üe der Wissenschaft.\nDarum sollten Sie alles dran setzen, dass Ihre Studie bzw. die Analyse Ihrer Daten nachvollziehbar ist. $\\square$\n:::\n\nWesentliche Faktoren f√ºr Reproduzierbarkeit sind:\n\n- Sie reichen Ihre *Rohdaten* ein (inkl. Codebook)\n- Sie reichen Ihr *Analyseskript* ein\n- Sie reichen Ihre *Stimuli* ein (sofern nicht √∂ffentlich verf√ºgbar)\n- Sie reichen Ihre *Messinstrumente* ein (sofern nicht √∂ffentlich verf√ºgbar)\n- Sie dokumentieren Ihr *Vorgehen* und reichen es ein\n\n\n\n\n## Codebook\n\nEin Teil der Dokumentation ist ein Codebook (auch Data-Dictionary genannt). Ein Codebook erl√§utert die Namen der Variablen in Ihrer (Roh-)Datentabelle, s. @fig-codebook.\n\n![Beispiel f√ºr ein Codebook](img/codebook.jpg){#fig-codebook}\n\n[Quelle](https://www.psycharchives.org/en/item/8b13c82b-1c31-481a-b4be-0d5779d87033)\n\n\n\n## Wir brauchen brave Daten\n\nWie muss eine Tabelle aufgebaut sein,\ndamit man sie gut in R importieren kann, bzw. gut damit weiterarbeiten kann?\n\n\n\nIm √úberblick sollten Sie auf Folgendes achten:\n\n- Wenn Sie h√§ndisch Daten eintragen, hacken Sie das einfach in Excel o.√Ñ. sein.\n- CSV-Dateien bieten sich als Datenformat an.\n- Alternativ kann man auch Excel-Dateien in R importieren.\n- Es muss genau *eine* Kopfzeile geben.\n- Es darf keine L√ºcken geben (leere Zeilen oder Spalten oder Zellen).\n- Vermeiden Sie Umlaute und Leerzeichen in den Variablennamen.\n- Die Daten sollten dem Prinzip von \"tidy data\" folgen.\n\n\n\n:::{.callout-important}\n### Tidy Data\nBeachten Sie das Prinzip von \"tidy data\":\n\n- In jeder Zeile steht *eine Beobachtung*.\n- In jeder Spalte steht *eine Variable*.\n- In jeder Zelle steht *eine Wert*. $\\square$\n:::\n\n\n[Hier ist eine gute Quelle](https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1375989) f√ºr weitere Erl√§uterung zu diesem Thema.\n\n\n\n\n\n\n\n\n\n\n## Checkliste zur Datenanalyse {#sec-checkdaten}\n\nHier sehen Sie im √úberblick die Schritte, die in vielen F√§llen sinnvoll sind, um Daten auf einem guten Niveau auszuwerten.\n\n\n1. *Vorverarbeitung*\n    1. Importieren\n    2. Aufbereiten (Umkodieren, fehlende Wert versorgen, Transformieren, neue Spalten berechnen)\n2. *Explorative Analyse*\n    1. Daten zusammenfassen (zentrale Tendenz, Streuung, Zusammenhang -- jeweils f√ºr alle UV und AV sowie weiterer potenziell relevanter Variablen)\n    2. Daten visualisieren (Verteilung der UV, AV, gemeinsame Verteilung von UV und AV)\n3. *Modellierung und Inferenzstatistik*\n    1. Modell berechnen (AV ~ UV1 + UV2 + ...)\n    2. Parameter berichten (Punkt- und Intervallsch√§tzer)\n    3. Parameter visualisieren\n    4. Nullhypothesen testen (z.B. ROPE)\n    5. Modellg√ºte berichten (z.B. R-Quadrat)\n\n\n\n## Rostl√∂ser\n\nIhre R-Skills sind etwas eingerostet? Flutscht nicht so?\nKeine Sorge! Es gibt Rostl√∂ser, der Sie schnell wieder in Schwung bringt.\nüß¥\n\n### Grundlagen der Statistik\n\nDas Kursbuch [Statistik1](https://statistik1.netlify.app/) beinhaltet einen √úberblick √ºber Datenaufbereitung und -visualierung  sowie Modellierung mit dem linearen Modell, alles mit R.\n\n### Grundlagen der Inferenzstatistik\n\nDas Kursbuch [Start:Bayes!](https://start-bayes.netlify.app/) stellt einen Einstieg in die Inferenzstatistik mit der Bayes-Statistik bereit.\n\n### Wie man Umfragedaten auswertet\n\n\n[Hier](https://sebastiansauer.github.io/umfragen-auswerten/index.html) finden Sie (m)eine Anleitung zur Auswertung von Umfragedaten.\n\n\n\n## √úberblick zur Statistik {#sec-overview-stats}\n\n### Deskriptiv- vs. Inferenzstatistik\n\n@fig-inf1 und @fig-inf2 geben einen √úberblick zum Unterschied von Deskriptiv- und Inferenzstatistik.\n\n\n\n![Deskriptiv- vs. Inferenzstatistik](img/desk-inf.jpg){#fig-inf1 width=70% fig-align=\"center\"}\n\n\n\n![Inferenzstatistik sch√§tzt die (Un-)Genauigkeit der Kennwerte der Deskriptivstatatistik](img/desk-inf-fans.jpg){#fig-inf2 width=70% fig-align=\"center\"}\n\n\n\n### Deskriptivstatistik\n\nBerechnen Sie die relevanten Kennwerte der Deskriptivstatistik f√ºr alle Variablen Ihrer Hypothesen (bzw. Forschungsfragen).\nDas beinhaltet sowohl *univariate* Analysen (d.h. Kennwerte f√ºr eine einzelne Variable)\nals auch *bivariate* Analysen (d.h. Zusammenh√§nge von zwei Variablen, also deren \"gemeinsame Verteilung\").\n\n\nTypische Kennwerte der Deskriptivstatistik sind:\n\n- Arithmetisches Mittel\n- Standardabweichung\n- Anteil\n- Korrelation\n- Regressionskoeffizienten\n\n\n\n\n@fig-scatter-interactive zeigt interaktive Beispiele f√ºr einen Kennwert des Deskriptivstatistik: (lineare) Korrelation^[Quelle: <https://observablehq.com/d/bb7ad3ecfb1ac2a6>]. \n\n\n\n:::{#fig-scatter-interactive}\n\n::: {.figure-content}\n\n\n\n\n\n```{ojs}\n//| echo: false\n\nviewof cor_type = select({\n  title: \"Correlation type\",\n  options: [\n    \"A perfect linear relationship\",\n    \"A close to linear relationship\",\n    \"A close to linear, but negative, relationship\",\n    \"A weaker relationship\",\n    \"A nonlinear relationship\",\n    \"No relationship\"\n  ],\n  value: \"A perfect linear relationship\"\n})\n```\n\n\n```{ojs}\n//| echo: false\nviewof redo = Inputs.button(\"Redo\")\n```\n\n\n```{ojs}\n//| echo: false\n\npic = (redo, graph_from_type(cor_type))\n```\n\n\n\n```{ojs}\n//| echo: false\n\nfunction graph_from_type(s) {\n  if (s == \"A perfect linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) => a * x + b,\n      (x) => 0,\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) => a * x + b,\n      (x) => jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear, but negative, relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) => -a * x + b,\n      (x) => jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A weaker relationship\") {\n    let a = jstat.uniform.sample(-2 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) => a * x + b,\n      (x) => 4 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A nonlinear relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) => (x - a) * (x - b),\n      (x) => 0.6 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"No relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) => 0,\n      (x) => jstat.uniform.sample(-10, 10),\n      -10,\n      10,\n      100\n    );\n  }\n}\n```\n\n\n\n```{ojs}\n//| echo: false\nfunction make_perturbed_graph(f, r, a, b, n) {\n  let xs = jstat.arange(n).map(() => jstat.uniform.sample(a, b));\n  let ys = xs.map((x) => f(x) + r());\n  let plot = plotter({ width: 500, height: 400, grid: false });\n  jstat.arange(n).forEach((_, i) => plot.point(xs[i], ys[i]));\n\n  let R = jstat.corrcoeff(xs, ys);\n\n  return html`<div style=\"text-align:center; width:500px\">R = ${d3.format(\n    \"0.4f\"\n  )(R)}</div>${plot.node}`;\n}\n```\n\n\n```{ojs}\n//| echo: false\nimport {select} from \"@jashkenas/inputs\"\njstat = require('jstat')\nimport { plotter } from '50dadfdec01c15a8'\nimport { rk4 } from '@mcmcclur/runge-kutta-for-systems-of-odes'\nimport { slider } from \"@jashkenas/inputs\"\n```\n\n\n\n\n\n:::\n\nInteraktives Beispiel f√ºr Zusammenhangsdiagramme.\n\n:::\n\n\n\n### Inferenzstatistik\n\n@fig-samples-for-inference veranschautlicht die Daaseinsberechtigung der Inferenzstatistik: \nEine einzelne Stichprobe sch√§tzt den Mittelwert der Population (mu) ungenau (je kleiner die Stichprobe, desto ungenauer, ceteris paribus). \nDaher brauchen wir eine Angabe, wie (un)genau unser Mittelwert wohl den \"wahren\" Mittelwert der Population (mu) sch√§tzt. \nGenau das macht die Inferenzstatistik!\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Inferenzstatistik veranschaulicht: Einzelne Stichproben sch√§tzen den Mittelwert der Populationswert (mu) nur ungenau. Daher brauchen eine Quantifizierung der Sch√§tz(un)genauigkeit des Mittelwerts der Population.](080-Auswerten_files/figure-html/fig-samples-for-inference-1.png){#fig-samples-for-inference width=672}\n:::\n:::\n\n\n\n\n### Modellieren\n\n\n:::{#def-model}\n### Modell\nEin Modell ist ein vereinfachtes Abbild der Wirklichkeit.$\\square$\n:::\n\nDer Nutzen eines Modells ist, einen (√ºberm√§√üig) komplexen Sachverhalt zu vereinfachen oder √ºberhaupt erst handhabbar zu machen.\nMan versucht zu vereinfachen, ohne Wesentliches wegzulassen. \nDer Speck muss weg, sozusagen. Das Wesentliche bleibt.\n\nAuf die Statistik bezogen hei√üt das,\ndass man einen Datensatz dabei so zusammenfasst,\ndamit man das Wesentliche erkennt.\nWas ist das \"Wesentliche\"? Oft interessiert man sich f√ºr die Ursachen eines Ph√§nomens. \nEtwa: \"Wie kommt es blo√ü, dass ich ohne zu lernen die Klausur so gut bestanden habe?\"^[Das ist nat√ºrlich nur ein fiktives, komplett unrealistisches Beispiel, das auch unklaren Ursachen den Weg auf diese Seite gefunden hat.]\nNoch allgemeiner ist man dabei h√§ufig am Zusammenhang von `X ` und `Y` interessiert, s. @fig-xy, die ein Sinnbild von statistischen Modellen widergibt.\n\n\n\n\n\n:::{#fig-xy fig-align=\"center\"}\n\n\n```{mermaid}\nflowchart LR\nX --> Y\n\n\nX1 --> Y2\nX2 --> Y2\n```\n\noben: Sinnbild eines statistischen Modells; unten: Sinnbild eines statistischen Modells, mit zwei Inputvariablen (\"Ursachen\")\n\n\n:::\n\n\n\n## Skriptbasierte vs. klickbasierte Software zur Datenanalyse\n\n\nMan kann grob zwei Arten von Software-Programmen f√ºr Datenanalyse unterscheiden:\n\n1. *Skriptbasierte*: Man schreibt seine Befehle in einer Programmiersprache (z.B. R)\n2. *Klickbasierte*: Man klickt in einer Gui, um Befehle auszul√∂sen (z.B. Jamovi)\n\nDie g√§ngigen Beispiele f√ºr skriptbasierte Software f√ºr Datenanalyse sind R und Python.\n\n\n\nEinige empfehlenswerte(re) Programme f√ºr die klickbasierte Datenanalyse sind:\n\n\n1. [Jamovi](https://www.jamovi.org/)\n2. [JASP](https://jasp-stats.org/)\n3. [Exploratory](https://exploratory.io/about/)\n\n\n\n\n\nIm Folgenden sind die Vorteile der oben genannten klickbasierten Software-Programmen den Vorteilen der oben genannten skriptbasierten Software-Programmen gegen√ºber gestellt\n\n::::{.columns}\n\n:::{.column}\n### Vorteile klickbasierter Software\n\n![JASP](img/JASP-logo.webp){width=30%} ![Jamovi](img/jamovi-icon.png){width=30%} ![[Exploratory](exploratory.io)](img/exploratory-icon.png){width=30%} \n\n\n- eher kostenlos (es gibt kostenpflichtige Premium-Versionen wie  Jamovi Cloud)\n- aktuell\n- flachere Lernkurve\n- R-Code integriert\n\n*Beispiele*: [JASP](https://jasp-stats.org/), [Jamovi](https://www.jamovi.org/), [Exploratory](https://exploratory.io/)\n:::\n\n:::{.column}\n### Vorteile skriptbasierter Software\n\n![R](img/R-logo.png){width=30%} ![Python](img/python-logo.png){width=50%}\n\n- kostenlos\n- aktueller\n- umfassend (klickbasierte Software kann nicht alles, was man braucht)\n- steilere Lernkurve\n\n*Beispiele:* [R](https://www.r-project.org/), [Python](https://www.python.org/)\n:::\n\n::::\n\n\n\n\n\n## Deskriptivstatistik in der Praxis\n\n:::{.callout-important}\nDie Deskriptivstatistik fasst eine Datenreihe zu einer Kennzahl zusammen. Der Nutzen liegt im √úberblick, den man so gewinnt. \n:::\n\n\nWir analysieren den Datensatz `extra`, s. zu Beginn dieses Kapitels, @sec-dataneeded.\nDamit es einfach bleibt, begrenzen wir uns im Folgenden auf ein paar Variablen. \n\nSagen wir, \ndas sind die Variablen, die uns interessieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra_corr_names <- \nextra %>% \n  select(n_facebook_friends, n_hangover, age, extra_single_item, n_party, extra_mean) %>% \n  names()\n\nextra_corr_names\n## [1] \"n_facebook_friends\" \"n_hangover\"         \"age\"               \n## [4] \"extra_single_item\"  \"n_party\"            \"extra_mean\"\n```\n:::\n\n\n\n\n### Deskriptive Ergebnisse f√ºr metrische Variablen \n\nSie k√∂nnen deskriptive Ergebnisse (Ihrer relevanten Variablen) f√ºr *metrische* Variablen z.B. so darstellen, s. @lst-desk1.\n\n\n:::{#lst-desk1}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra %>% \n  select(any_of(extra_corr_names)) %>% \n  describe_distribution()  # aus `easystats`\n```\n:::\n\n\nDeskriptive Statistik mit Hilfe des R-Pakets `easystats` \n\n:::\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Variable           |   Mean|      SD|   IQR|  Min|   Max| Skewness| Kurtosis|   n| n_Missing|\n|:------------------|------:|-------:|-----:|----:|-----:|--------:|--------:|---:|---------:|\n|n_facebook_friends | 532.61| 3704.48| 300.0|  0.0| 96055|    25.67|   662.76| 671|       155|\n|n_hangover         |   9.47|   30.72|   9.0|  0.0|   738|    17.54|   399.53| 800|        26|\n|age                |  25.50|    5.75|   6.0| 18.0|    54|     1.81|     4.39| 813|        13|\n|extra_single_item  |   2.79|    0.86|   1.0|  1.0|     4|    -0.27|    -0.60| 816|        10|\n|n_party            |  17.38|   19.32|  19.0|  0.0|   150|     3.27|    16.10| 793|        33|\n|extra_mean         |   2.89|    0.45|   0.6|  1.2|     4|    -0.43|    -0.11| 822|         4|\n\n\n:::\n:::\n\n\n\n√úbersetzen wir @lst-desk1 vom Errischen ins Deutsche:\n\n1. Hey R,\n2. nimm die Tabelle `extra` ... und dann\n3. w√§hle jede Variable, die ich im Vektor `extra_corr_names` angegeben habe ... und dann\n4. beschreibe die Verteilung (jeweils, also f√ºr jede Variable) ... und dann\n5. mache aus der dr√∂gen Tabelle eine schicke. Fertig!\n\n\n\n\n\n\n\n`kable()` macht aus dem dr√∂gen Output in der R-Konsole eine schicke HTML-Tabelle^[funktioniert auch mit Word und PDF als Ausgabeformat], wenn man das Quarto-Dokument rendert.\n\nStatt `select(any_of(extra_corr_names))` k√∂nnten Sie nat√ºrlich auch schreiben `select(n_facebook_friends, ...)`, wobei Sie f√ºr die drei Punkte alle Variablen von Interesse nennen w√ºrden.\n\n\nPraktischerweise kann man `describe_distribution` auch f√ºr gruppierte Datens√§tze nutzen, um so gruppierte Verteilungsma√üe zu bekommen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra |> \n  group_by(sex) |> \n  describe_distribution(extra_mean)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"sex\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"Variable\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Mean\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SD\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"IQR\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Min\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Max\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Skewness\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Kurtosis\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[10],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"n_Missing\"],\"name\":[11],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Frau\",\"2\":\"extra_mean\",\"3\":\"2.908705\",\"4\":\"0.4219142\",\"5\":\"0.6\",\"6\":\"1.6\",\"7\":\"3.9\",\"8\":\"-0.3380531\",\"9\":\"-0.1665412\",\"10\":\"529\",\"11\":\"0\"},{\"1\":\"Mann\",\"2\":\"extra_mean\",\"3\":\"2.861772\",\"4\":\"0.4989651\",\"5\":\"0.7\",\"6\":\"1.2\",\"7\":\"4.0\",\"8\":\"-0.4812037\",\"9\":\"-0.2230608\",\"10\":\"286\",\"11\":\"0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n### Visualisierung von metrischen Variablen\n\n\n#### Univariat\n\nMit dem R-Paket `ggpubr` kann man ansprechende Visualisierungen erzeugen,\nund zwar ziemlich einfach.\nMit `help(ggpubr)` bekommen Sie Einblick in die Hilfeseite von [ggpubr](https://rpkgs.datanovia.com/ggpubr/).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngghistogram(extra, x = \"extra_mean\", add = \"mean\") +\n  labs(x = \"Extraversion (Mittelwert)\",\n       y = \"H√§ufigkeit\",\n       caption = \"Die gestrichelte horizontale Linie zeigt den Mittelwert der Verteilung.\")\n```\n\n::: {.cell-output-display}\n![](080-Auswerten_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n#### Gruppenvergleich\n\nVergleicht man die Verteilung einer Variablen unterteilt auf die Stufen (Gruppen) einer zweiten Variablen, so untersucht man die *gemeinsame Verteilung* dieser beiden Variablen.\n\n\n\nEs gibt verschiedene Methoden, Gruppenunterschiede zu verdeutlichen.\nMan k√∂nnte z.B. pro Gruppe ein Histogramm zeigen, das ist recht informationsreich.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra_no_na <-\n  extra |> \n  filter(sex == \"Frau\" | sex == \"Mann\")\n\ngghistogram(extra_no_na, x = \"extra_mean\", add = \"mean\", facet.by = \"sex\") +\n  labs(x = \"Extraversion (Mittelwert)\",\n       y = \"H√§ufigkeit\",\n       caption = \"Die gestrichelte horizontale Linie zeigt den Mittelwert der Verteilung.\")\n```\n\n::: {.cell-output-display}\n![](080-Auswerten_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nGerade bei vielen Gruppen kann aber ein Boxplot √ºbersichtlicher sein.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra_no_na |> \n  ggboxplot(y = \"extra_mean\", x = \"sex\")\n```\n\n::: {.cell-output-display}\n![](080-Auswerten_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\n### Deskriptive Ergebnisse f√ºr nominale Variablen \n\n\n#### Univariate H√§ufigkeiten\n\nLassen wir uns die H√§ufigkeiten f√ºr `sex` und f√ºr `smoker` ausgeben, also f√ºr jede Variable separat (univariat).\n\n\nMit `tidyverse` kann man das in vertrauter Manier bewerkstelligen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra |> \n  count(sex)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"sex\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Frau\",\"2\":\"529\"},{\"1\":\"Mann\",\"2\":\"286\"},{\"1\":\"NA\",\"2\":\"11\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nEtwas schicker sieht es aus mit `data_tabulate` aus `easystats`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra |> \n  select(sex) |> \n  #drop_na() |>  ggf. ohne fehlende Werte\n  data_tabulate() |> \n  print_md()  # erstelle eine schicke HTML-Tabelle\n```\n\n::: {.cell-output-display}\n\n\nTable: sex (sex) (character)\n\n|Value |  N |Raw % | Valid %| Cumulative %|\n|:-----|:---|:-----|-------:|------------:|\n|Frau  |529 |64.04 |   64.91|        64.91|\n|Mann  |286 |34.62 |   35.09|       100.00|\n|(NA)  | 11 | 1.33 |    (NA)|         (NA)|\ntotal N=826 valid N=815\n\n\n\n\n:::\n:::\n\n\nZur Visualisierung von H√§ufigkeiten bieten sich Balkendiagramme an.\nNutzt man `ggpubr` muss man zuerst selber die Anzahl der Werte ausz√§hlen (lassen),\ndas geht z.B. mit `count`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra_no_na |> \n  count(sex)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"sex\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Frau\",\"2\":\"529\"},{\"1\":\"Mann\",\"2\":\"286\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra_no_na |> \n  count(sex) |> \n  ggbarplot(x = \"sex\", y = \"n\")\n```\n\n::: {.cell-output-display}\n![](080-Auswerten_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n\n#### Bivariate H√§ufigkeiten\n\nWir k√∂nnen uns auch die *bi*variaten H√§ufigkeiten ausgeben lassen:\nBetrachten wir die Geschlechtsverteilung bei Menschen, die (nicht) j√ºnger als 20 Jahre sind:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra |> \n  drop_na(sex, age) |>  # fehlende Werte entfernt\n  group_by(age > 20) |> \n  data_tabulate(sex) |> \n  print_md()  # erstelle eine schicke HTML-Tabelel\n```\n:::\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Frequency Table\n\n|Variable |           Group | Value|   N|Raw % | Valid %| Cumulative %|\n|:--------|:----------------|-----:|---:|:-----|-------:|------------:|\n|sex      |age > 20 (FALSE) |  Frau|  89|74.17 |   74.17|        74.17|\n|         |                 |  Mann|  31|25.83 |   25.83|       100.00|\n|         |                 |  (NA)|   0| 0.00 |    (NA)|         (NA)|\n|         |                 |      |    |      |        |             |\n|sex      | age > 20 (TRUE) |  Frau| 437|63.43 |   63.43|        63.43|\n|         |                 |  Mann| 252|36.57 |   36.57|       100.00|\n|         |                 |  (NA)|   0| 0.00 |    (NA)|         (NA)|\n|         |                 |      |    |      |        |             |\n\n\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra |> \n  drop_na(age, sex) |>  # fehlende Werte entfernen\n  count(young = age < 20, sex) |>\n  ggbarplot(x = \"young\", y = \"n\", fill = \"sex\")\n```\n\n::: {.cell-output-display}\n![](080-Auswerten_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nEicht man die H√∂hen der Balken auf 100%,\nso kann man Zusammenh√§nge gut visualisieren.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra |> \n  drop_na(age, sex) |>  # fehlende Werte entfernen\n  count(young = age < 20, sex) |> \n  ggbarplot(x = \"young\", y = \"n\", fill = \"sex\", \n            position = position_fill()) +\n  labs(title = \"Deutlicher Zusammenhang zwischen Geschlecht und Alter\")\n```\n\n::: {.cell-output-display}\n![](080-Auswerten_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra |> \n  drop_na(n_party, sex) |>  # fehlende Werte entfernen\n  count(party_tiger = n_party > 5, sex) |> \n  ggbarplot(x = \"party_tiger\", y = \"n\", fill = \"sex\", \n            position = position_fill()) +\n  labs(title = \"Schwacher Zusammenhang zwischen Geschlecht und 'Party_Tiger'\")\n```\n\n::: {.cell-output-display}\n![](080-Auswerten_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n### Korrelationen darstellen\n\nIn einer Umfrage erhebt man h√§ufig mehrere Variablen, ein Teil davon oft *Konstrukte*.\nEs bietet sich in einem ersten Schritt an, die Korrelationen dieser Variablen untereinander\ndarzustellen.\n\n\n\n#### Korrelationsmatrix\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Parameter          | extra_mean| n_party| extra_single_item|   age| n_hangover|\n|:------------------|----------:|-------:|-----------------:|-----:|----------:|\n|n_facebook_friends |       0.05|    0.08|              0.07| -0.03|       0.13|\n|n_hangover         |       0.06|    0.34|             -0.02| -0.06|         NA|\n|age                |      -0.14|   -0.21|             -0.03|    NA|         NA|\n|extra_single_item  |       0.57|    0.06|                NA|    NA|         NA|\n|n_party            |       0.25|      NA|                NA|    NA|         NA|\n\n\n:::\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra %>% \n  select(any_of(extra_corr_names)) %>%  \n  correlation() %>% \n  summary() \n```\n:::\n\n\n\nSie m√∂chten das Ergebnis als normalen R-Dataframe? \nSie haben keine Lust auf dieses Rumgetue, sondern wollen das lieber als selber geradeziehen.\nAlso gut:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor_results <- \nextra %>% \n  select(any_of(extra_corr_names)) %>%  \n  correlation() %>% \n  summary() |> \n  print_md()  # erstelle schicke HTML-Tabelle\n\ncor_results\n```\n\n::: {.cell-output-display}\n\n\nTable: Correlation Matrix (pearson-method)\n\n|Parameter          | extra_mean |  n_party | extra_single_item |   age | n_hangover |\n|:------------------|:----------:|:--------:|:-----------------:|:-----:|:----------:|\n|n_facebook_friends |       0.05 |     0.08 |              0.07 | -0.03 |      0.13* |\n|n_hangover         |       0.06 |  0.34*** |             -0.02 | -0.06 |            |\n|age                |   -0.14*** | -0.21*** |             -0.03 |       |            |\n|extra_single_item  |    0.57*** |     0.06 |                   |       |            |\n|n_party            |    0.25*** |          |                   |       |            |\np-value adjustment method: Holm (1979)\n\n\n:::\n:::\n\n\n\n\n\nMan kann sich die Korrelationsmatrix auch in der *Bayes-Geschmacksrichtung* ausgeben lassen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra %>% \n  select(any_of(extra_corr_names)) %>%  \n  correlation(bayesian = TRUE) %>% \n  summary() %>% \n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|Parameter          | extra_mean| n_party| extra_single_item|   age| n_hangover|\n|:------------------|----------:|-------:|-----------------:|-----:|----------:|\n|n_facebook_friends |       0.05|    0.08|              0.07| -0.03|       0.13|\n|n_hangover         |       0.06|    0.33|             -0.02| -0.06|         NA|\n|age                |      -0.14|   -0.21|             -0.03|    NA|         NA|\n|extra_single_item  |       0.57|    0.06|                NA|    NA|         NA|\n|n_party            |       0.25|      NA|                NA|    NA|         NA|\n\n\n:::\n:::\n\n\n\n#### Korrelationsmatrizen visualisieren\n\nViele R-Pakete bieten sich an. Nehmen wir `{easystats}`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra %>% \n  select(any_of(extra_corr_names)) %>%  \n  correlation() %>% \n  summary() %>% \n  plot() +\n  labs(title = \"Korrelationsmatrix, boa\")\n```\n\n::: {.cell-output-display}\n![](080-Auswerten_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n## Aufgaben\n\n\nAuf dem [Datenwerk](https://datenwerk.netlify.app/) finden Sie eine Anzahl an Aufgaben zum Thema Datenanalyse.\nSchauen Sie sich mal die folgenden Tags an:\n\n- [eda](https://datenwerk.netlify.app/#category=eda)\n\n\n\n## Fallstudien\n\nFallstudien zur explorativen Datenanalyse (EDA; d.h. deskriptive Statistik und Datenvisualisierung) finden Sie z.B. im [Datenwerk](https://datenwerk.netlify.app/):\n\n- [flights-yacsda-eda](https://datenwerk.netlify.app/posts/flights-yacsda-eda/)\n- [oecd-yacsda](https://datenwerk.netlify.app/posts/oecd-yacsda/)\n- [smartphone1](https://datenwerk.netlify.app/posts/smartphone1/)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}