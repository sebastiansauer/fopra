# Auswerten: Modellieren


```{r}
#| include: false
library(tidyverse)
library(dagitty)
```


```{r}
#| echo: false
library(ggplot2)
theme_set(theme_minimal())
```

## Lernsteuerung


### Lernziele


- Sie k√∂nnen die Modellformel Ihrer Forschungsfrage nennen.
- Sie k√∂nnen Ihre Modellformel (korrekt) in R spezifizieren.
- Sie k√∂nnen Ihr Modell in R berechnen und die Ausgabe interpretieren.
- Sie k√∂nnen die G√ºltigkeit bzw. die Grenzen der Aussagen Ihres Modells einsch√§tzen.


### Ben√∂tigte R-Pakete


```{r}
#| message: false
library(tidyverse)
library(easystats)
library(ggstatsplot)
library(rstanarm)
```



### Position im Lernpfad

Sie befinden sich im Abschnitt "Auswerten" in @fig-ueberblick.






## Metrische AV, between-Design

### 1 between-Variable

#### Design

@sauer_effect_2023 untersuchten in einer Querschnittsstudie den Effekt des Wirkstoff *Bringnixtin* auf die fluide Intelligenz. Die Autoren nahmen an, dass der Wirkstoff den individuellen Wert der abh√§ngigen Variable erh√∂hen w√ºrde.


Der Ablauf (aus Sicht der Probandis) ist in @fig-bringtnixtin-flow dargestellt.
`Intro` fasst die Begr√º√üung der Probandis inkl. Informed Consent sowie Erfassung von soziodemografischen Variablen zusammen.
`g.0` und `g.1` sind die zwei Stufen der UV (*g* wie Gruppe), wobei `g.0` die Kontrollgruppe kodiert (Placebo, also Zuckerpille, kein Wirkstoff,) und `g.1` die *zweite* Stufe, d.h. die Experimentalgruppe (hohe Dosis Bringtnixtin).
`y2` ist die Messung der AV (d.h. nach Gabe von Bringtnixtin), d.h. ein Ma√ü der fluiden Intelligenz.
`outro` meint die Verabschiedung der Probanden sowie einige Fragen zu Compliance.


Die Hypothese lautet: $\mu_{g.2} > \mu_{g.1}$. In Worten:

>  Wir erwarten, dass der Mittelwert der Experimentalgruppe h√∂her ist als der Mittelwert der Kontrollgruppe.



```{mermaid}
%%| label: fig-bringtnixtin-flow
%%| fig-cap: Ablaufdiagramm der Bringtnixtin-Studie

flowchart LR
  Intro --> g.0
  Intro --> g.1
  g.0 --> y2
  g.1 --> y2
  y2 --> outro
```

Der DAG des Experiments ist in @fig-bringtnixtin-dag dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-bringtnixtin-dag
#| fig-cap: "DAG f√ºr der Bringtnixtin-Studie"
#| echo: false

mein_modell <- "dag{
g -> y2
u -> y2
}"

plot(graphLayout(mein_modell))
```



```{r d_bringtnixtin}
#| echo: false
#| eval: true
n_bringtnixtin <- 40

set.seed(42)
d_bringtnixtin <-
  tibble(id = 1:n_bringtnixtin,
         g = c(rep(0, n_bringtnixtin/2), rep(1, n_bringtnixtin/2)),
         y1 = rnorm(n_bringtnixtin),
         y2 = y1 + rnorm(n_bringtnixtin, mean = 0, sd = .2) - g/3,
         d = y2 - y1
  )

#write_csv(d_bringtnixtin, "data/d_bringtnixtin.csv")
```


Die Daten dieses Experiments sind hier zu beziehen:

```{r}
#| message: false
#| eval: false
d_bringtnixtin_path <- "https://raw.githubusercontent.com/sebastiansauer/fopra/main/data/d_bringtnixtin.csv"
d_bringtnixtin <- read_csv(d_bringtnixtin_path)
```


{{< downloadthis data/d_bringtnixtin.csv >}}

Die Autoren der Studie geben an, dass die Daten in z-Einheiten skaliert sind.


#### Deskriptive Analyse


```{r}
d_bringtnixtin %>% 
  group_by(g) %>% 
  summarise(iq_mw = mean(y2),
            iq_sd = sd(y2)) 
```

Die deskiptiven Kennwerte sind in @fig-bringtnixtin-desk dargestellt.
Das sieht nicht gerade nach einem gro√üen Effekt aus ...^[Die Mittelwerte der beiden Gruppen sind praktisch identisch.]


```{r}
#| label: fig-bringtnixtin-desk
#| fig-cap: "Fluide Intelligenz (y2) nach der Bringtnixtin-Intervention. g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)"
ggbetweenstats(
  data = d_bringtnixtin,
  x = g,
  y = y2,
  results.subtitle = FALSE  # keine Statistiken zeigen
)
```



#### Modellierung


Wir berechnen ein lineares Modell mit der Modellformel `y2 ~ g`. 
Die Ergebnisse sind in @tbl-m1-params zu sehen.

```{r}
#| label: tbl-m1-params
#| tbl-cap: Parameter des Modells m_bringtnixtin
m_bringtnixtin <- stan_glm(y2 ~ g, data = d_bringtnixtin, refresh = 0)
parameters(m_bringtnixtin)
```

Die Punkt- und Intervallsch√§tzer (95%-ETI) sind in @fig-m1-params dargestellt.

```{r}
#| label: fig-m1-params
#| fig-cap: "Parameter des Modells `m_bringtnixtin (95%-ETI)`"
parameters(m_bringtnixtin) %>% plot(show_intercept = TRUE)
```


```{r}
#| echo: false
m_bringtnixtin_hdi <- hdi(m_bringtnixtin)

m1_lo_ci <- m_bringtnixtin_hdi %>% filter(Parameter == "g") %>% pull(CI_low) %>% round(2)
m1_high_ci <- m_bringtnixtin_hdi %>% filter(Parameter == "g") %>% pull(CI_high) %>% round(2)
```



Der Gruppenunterschied wird auf `r round(coef(m_bringtnixtin), 2)` gesch√§tzt;
das ist der Punktsch√§tzer der UV `g`.
Die Grenzen eines 95%-CI f√ºr die UV liegen bei `r m1_lo_ci` bzw. `r m1_high_ci`.
Dieser Bereich enth√§lt die Null, vgl. @fig-m1-params.
Daher kann nicht ausgeschlossen werden,
dass Bringtnixtin nix bringt.

>   üë®‚Äçüè´ Frau Professor Lustig, wie kann das sein, dass sich die Hypothese nicht best√§tigt?

>   üë©‚Äçüè´ Herr Professor Sauer, auch ein negatives Ergebnis bringt die Wissenschaft weiter.


Testen wir eine Nullhypothese mit dem ROPE-Verfahren, s. @tbl-m1-rope und @fig-m1-rope.

```{r}
#| label: tbl-m1-rope
#| tbl-cap: ROPE f√ºr Modell m_bringtnixtin
rope(m_bringtnixtin)
```

```{r}
#| label: fig-m1-rope
#| fig-cap: ROPE f√ºr MOdell m_bringtnixtin

rope(m_bringtnixtin) %>% plot()
```


Da sich das 95%-CI mit dem ROPE √ºberlappt, kann die Nullhypothese bzw. das ROPE (kein praktisch bedeutsamer Effekt) *nicht* ausgeschlossen werden.

```{r}
#| echo: false

m1_pd <- pd(m_bringtnixtin)$pd[2] %>% round(2)
```



Eine vergleichbare Information bietet uns die Kennzahl `pd`, s. @tbl-m1-params.
Der Wert f√ºr `g` liegt bei ca. `r m1_pd`.

:::{#callout-note}
`pd` gibt die Wahrscheinlichkeit (laut Modell) an, dass der Effekt in der Population negativ bzw. positiv ist (d.h. gleich dem Vorzeichen des Punktsch√§tzers; in diesem Fall negativ).$\square$
:::

<!-- Das Modell ist sich nicht sehr sicher, in welche Richtung der Effekt von Bringtnixtin zeigt. -->
<!-- Das Modell neigt eher zur Meinung, dass der Effekt von `g` (in der Population) *negativ* ist. Ganz sicher ist sich aber das Modell nicht. -->
Das Modell ist sicher ziemlich sicher, dass der Effekt von `g` (in der Population) *negativ* ist. 

>   üë®‚Äçüè´ Frau Professor Lustig, oh je!

>   üë©‚Äçüè´ Herr Professor Sauer, wir m√ºssen erst einmal in Ruhe die Studie replizieren. Eine Schwalbe macht noch keinen Fr√ºhling.



### Vorher-Nachher-Messung, 1 between-Variable


#### Design

@sauer_effect_2023 fiel auf, dass es sinnvoller ist, zuerst die AV mittels eines Vortests zu messen, dann die Intervention anzuwenden, und dann nachher (Posttest) die AV wieder zu messen.
Daher haben sie sowohl vor der Intervention (`y1`) als auch nach der Intervention (Gabe von Bringtnixtin), `y2` die AV gemesessen.


:::{#callout-note}
Eine Vorher-Nachher-Messung hat den Verteil, dass sie - im Gegensatz zur Nur-Nachher-Messung - unterschiedliche Ausgangswerte in der AV herausrechnet. 
Bei gro√üen Gruppen wird sich bei einer randomisierten Zuweisung zu den Gruppen der Ausgangswert der AV angleichen. Bei nicht so gro√üen Gruppen kann aber auch bei Randomisierung ein - mitunter erheblicher - Unterschied zwischen den Gruppen verbleiben.
Findet man bei der Post-Messung einen Effekt, so kann es sein, dass dieser nicht auf die Intervention beruht, sondern auf die von vornherein vorhandenen Unterschieden zwischen den Gruppen.$\square$
:::


:::{#callout-note}
Vergleicht man die Delta-Werte zwischen zwei Gruppen,
berechnet man die Differenz zwischen den Gruppen der Delta-Werte.
Man spricht daher von einer *Difference-in-Difference-Analyse*.$\square$
:::



@fig-bringtnixtin-flow2 zeigt den Ablaufplan dieses Experiments.

```{mermaid}
%%| label: fig-bringtnixtin-flow2
%%| fig-cap: Ablaufdiagramm der Bringtnixtin-Studie

flowchart LR
  Intro --> y1
  y1 --> g.1
  y1 --> g.2
  g.1 --> y2
  g.2 --> y2
  y2 --> outro
```

DAG des Experiments ist in @fig-bringtnixtin-dag2 dargestellt.


```{r out.width = "100%", fig.asp = .5}
#| label: fig-bringtnixtin-dag2
#| fig-cap: "DAG f√ºr der Bringtnixtin-Studie"
#| echo: false

mein_modell <- "dag{
g -> d
u -> d
}"

plot(graphLayout(mein_modell))
```
#### Deskriptive Analyse

Eine einfache (und sinnvolle) Art, solche Studiendesigns auszuwerten ist die Bildung einer Differenz-Variable^[auch Delta-Veriable genannt].
Diese Differenzvariable gibt die Ver√§nderung der fluiden Intelligenz durch die Intervention an.
Anders gesagt: Die Differenz ist die IQ-Wert einer Person *nach* der Intervention minus dem IQ-Wert *vor* der Intervention: $d = y_2 - y_1$:

```{r}
d_bringtnixtin <-
  d_bringtnixtin %>% 
  mutate(d = y2 - y1)
```

Schauen wir uns die ersten paar d-Werte f√ºr jede der beiden Gruppen (`g=0?  bzw. `g=1`) an.

```{r}
d_bringtnixtin %>% 
  group_by(g) %>% 
  slice_head(n = 5)
```


<!-- Puh! Das Bringtnixtin scheint die IQ zu *verringern*, zumindest in einigen F√§llen. -->




Vielleicht ist es anschaulicher, wenn wir die Gruppe `0` in den Text `Kontrollgruppe` umbenennen und `1` in `Experimentalgruppe`:


```{r}
d_bringtnixtin <-
  d_bringtnixtin %>% 
  mutate(g_text =
           case_when(g == 0 ~ "Kontrollgruppe",
                     g == 1 ~ "Experimentalgruppe"))
```

Hier sind die Mittelwerte f√ºr jede der beiden Gruppen:


```{r}
d_bringtnixtin %>% 
  group_by(g_text) %>%
  summarise(d = mean(d))
```

Die deskiptiven Kennwerte sind in @fig-bringtnixtin-desk2 dargestellt.


```{r}
#| label: fig-bringtnixtin-desk2
#| fig-cap: "Ver√§nderung der fluiden Intelligenz (d) in Abh√§ngigkeit der Gruppe; g=0: Kontrollgruppe (Placebo), g=1: Experimentalgruppe (hohe Dosis)"
ggbetweenstats(
  data = d_bringtnixtin,
  x = g_text,
  y = d,
  results.subtitle = FALSE  # keine Statistiken zeigen
)
```



#### Modellierung

Wir modellieren (in `m_bringtnixtin2`) jetzt die Ver√§nderung `d = y2 - y1` als AV; UV ist wieder `g`.

```{r}
m_bringtnixtin2 <- stan_glm(d ~ g, data = d_bringtnixtin, refresh = 0)
parameters(m_bringtnixtin2)
```
@fig-bringtnixtin2-params zeigt die Parameterwerte f√ºr `m_bringtnixtin2`,

```{r}
#| fig-cap: "Parameterwerte von m_bringtnixtin2 (Intercept ist nicht dargestellt), 95%-ETI"
#| label: fig-bringtnixtin2-params
plot(parameters(m_bringtnixtin2))
```


Wie man den Parameterwerten entnehmen kann,
ist sich das Modell sehr sicher, dass der Effekt von Bringtnixtin *negativ* ist.
<!-- ist sich das Modell nicht sicher, welche Richtung der Effekt von Bringtnixtin hat. -->


### Weitere Beispiele

G√§ngige Forschungsfragen dieser Art sind [hier](https://start-bayes.netlify.app/https://start-bayes.netlify.app/1000-metrische-av) erl√§utert.



## Metrische AV, within-Design


### 1 within-Variable


Eine Studie mit Vorher-Nachher-Messung setzt ein Within-Design um.


:::{#exm-within1}
### Statisches Diagramm vs. animiertes Diagramm
Ein Forschungsteam untersuch den Effekt der UV *Diagrammart* `D` (mit den zwei Stufen `D.1` *animiert* und `D.2` *statisch*) auf die Behaltensleistung (`y`) von Probanden.
Nach jeder Bedingung wird die Behaltensleistung gemessen (anhand von 10 Wissensfragen, die jeweils als "richtig" oder "falsch" bewertet wurden), mit `y1` nach `D.1` und `y2` f√ºr `D.2`.
:::



#### Design


Forschungsfrage:

>    Hat die Diagrammart einen Einfluss auf die Behaltensleistung? Anders gesagt: Unterscheiden sich die Diagrammarten in ihrem Einfluss auf die Behaltensleistung?


Die zugeh√∂rige Hypothese kann man so formulieren: $d \ne 0$, wobei $d = y_1 - y_2$.

Die Modellformel lautet: `d ~ 1`,
das ist ein *Interceptmodell*, also ein Modell ohne Pr√§diktor. 
Uns interessiert, ob die Variable `d` im Mittelwert ungleich Null ist.

```{mermaid}
flowchart LR
  D.1 --> y1 --> D.2 --> y2
```


#### Deskriptive Analyse

Hier sind einige Spieldaten:

```{r}
#| message: false
d_within <- 
  read_csv("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv") %>% 
  select(-c(y3, g)) # diese beiden Variablen ignorieren wir f√ºr den Augenblick

head(d_within)
```

{{< downloadthis data/withindesign.csv >}}

Wir berechnen `d`:

```{r}
d_within <-
  d_within %>% 
  mutate(d = y1 - y2)

head(d_within)
```


```{r}
gghistostats(d_within,
             x = d,
             results.subtitle = FALSE  # verzichte auf zus√§tzliche Statistiken
             )
```

Da `d` im Mittel negativ ist, ist der Mittelwert von `y2` h√∂her als der von `y1`.


```{r}
d_within %>% 
  describe_distribution(d)
```


Um die Daten noch anders  visualisieren zu k√∂nnen, formen wir sie ins "lange Format" um.

```{r}
d_long <-
  d_within %>% 
  pivot_longer(cols = c(y1, y2), names_to = "time", values_to = "y")

head(d_long)
```


Visualisieren wir uns die Daten:

```{r}
ggwithinstats(
  data = d_long,
  x = time,
  y = y,
  results.subtitle = FALSE  # verzichte auf zus√§tzliche Statistiken
)
```


#### Inferenzanalyse

Wir berechnen das Modell:

```{r}
m_within <- stan_glm(d ~ 1, data = d_within, refresh = 0)
parameters(m_within)
```

Hier ist eine Visualisierung des 95%-ETI des Unterschieds (`d`) zwischen den Bedingungen:

```{r}
parameters(m_within) %>% plot(show_intercept = TRUE)
```


### 1 within-Variable, 1 between-Variable




>    Hat die Diagrammart einen Einfluss auf die Behaltensleistung? Anders gesagt: Unterscheiden sich die Diagrammarten in ihrem Einfluss auf die Behaltensleistung? Dabei kontrollieren wir die Reihenfolge.


Die zugeh√∂rige Hypothese kann man so formulieren: $d \ne 0$, wobei $d = y_1 - y_2$.

Die Modellformel lautet: `d ~ 1 + g`.
Das kann man synonym so schreiben: `d ~ g`.
Uns interessiert, ob die Variable `d` im Mittelwert ungleich Null ist.



```{mermaid}
flowchart LR
  subgraph g2
    direction LR
    D.1 --> y1 --> D.2 --> y2
  end
  subgraph g1
    direction LR
    D2[D.2] --> y22[y2] --> D1[D.1] --> y11[y1] 
  end
```


#### Deskriptive Analyse

Hier sind einige Spieldaten:

```{r}
#| message: false
d_within <- 
  read_csv("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv") %>% 
  select(-c(y3)) # die  Variable `y3` ignorieren wir f√ºr den Augenblick

head(d_within)
```



Wir berechnen `d`:

```{r}
d_within <-
  d_within %>% 
  mutate(d = y1 - y2)

head(d_within)
```


```{r}
ggbetweenstats(
  d_within,
  x = g,
  y = d,
  results.subtitle = FALSE
)
```

Es gibt einen gewissen Unterschied zwischen den Bedingungen;
die Reihenfolge k√∂nnte einen Einfluss haben.
Aber wir m√ºssen inferenzstatistisch pr√ºfen, wie gro√ü der Einfluss ist.



#### Inferenzanalyse



```{r}
m_within2 <- stan_glm(d ~ g, data = d_within, refresh = 0)
parameters(m_within2)
```

Das CI f√ºr die Reihenfolge (Variable `gB`) beinhaltet die Null nicht;
der Koeffizient `pd` gibt knapp 90% Wahrscheinlichkeit f√ºr einen (negativen Effekt) an.
Damit haben wir einige Evidenz f√ºr einen Reihenfolgeneffekt.

Der Effekt f√ºr `d` (`(Intercept)`) zeigt ein Intervall, das die Null nicht enth√§lt.
Daher haben wir auch hier wieder Evidenz gegen die Nullhypothese.



### 1 within-Variable mit mehr als zwei Stufen

{{< fa dumbbell >}} VERTIEFUNG {{< fa dumbbell >}}


#### Deskriptive Analyse

Hier sind einige Spieldaten:

```{r}
#| message: false
d_within <- 
  read_csv("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/withindesign.csv")

head(d_within)
```

Hier ben√∂tigen wir die Daten in Langform:


```{r}
d_long <-
  d_within %>% 
  pivot_longer(cols = y1:y3, names_to = "time", values_to = "y")

head(d_long)
```


#### Inferenzanalyse



```{r}
m_within3 <- stan_lmer(y ~ 1 + (1 | time), data = d_long, refresh = 0)
summary(m_within3)
```

Nur die festen (fixed) Effekte kann man sich so ausgeben lassen:

```{r}
fixef(m_within3)
```


Im Durchschnitt werden ca. 7.1 Fragen richtig beantwortet (Gesamtmittel).


Nur die Random-Effekte kann man sich so ausgeben lassen:

```{r}
ranef(m_within3)
```

Das sind jeweils die Abweichungen der Gruppenmittelwerte (y1, y2, y3) vom Gesamtmittel.

```{r}
plot(m_within3)
```



## Aufgaben


S. bei [Datenwerk]() die Aufgaben mit dem Tag [research-question](https://datenwerk.netlify.app/#category=research-question) und [researchdesign](https://datenwerk.netlify.app/#category=researchdesign)


- [within-design-analysis1](https://datenwerk.netlify.app/posts/within-design-analysis1/within-design-analysis1.html)
